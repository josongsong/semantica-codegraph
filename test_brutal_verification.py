#!/usr/bin/env python3
"""
ì§„ì§œ ë¹„íŒì  ê²€ì¦ - ê±°ì§“ë§ ì—†ì´

1. Local Overlay - ì§„ì§œ ì‘ë™í•˜ë‚˜?
2. Type Narrowing - ì‹¤ìš©ì ì¸ê°€?
3. Taint Engine - ì·¨ì•½ì ì„ ì§„ì§œ ì°¾ë‚˜? (ì™œ 0ê°œ?)
4. í†µí•© - ì „ì²´ê°€ í•¨ê»˜ ì‘ë™í•˜ë‚˜?
5. ì‹¤ì „ - ì‹¤ì œ ì½”ë“œì—ì„œ ìœ ìš©í•œê°€?
"""

import tempfile
import subprocess
from pathlib import Path
from src.contexts.code_foundation.infrastructure.overlay.local_overlay import LocalOverlay, OverlayIRBuilder
from src.contexts.code_foundation.infrastructure.analyzers.type_narrowing_full import FullTypeNarrowingAnalyzer
from src.contexts.code_foundation.infrastructure.analyzers.taint_engine_full import FullTaintEngine
from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile


def brutal_test_1_local_overlay_actually_works():
    """Local Overlayê°€ ì§„ì§œ ì‘ë™í•˜ë‚˜?"""
    print("\n" + "ğŸ’€" * 30)
    print("1. Local Overlay - ì‹¤ì œ ë™ì‘ ê²€ì¦")
    print("ğŸ’€" * 30)

    # Create temp git repo
    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)

        # Init git
        subprocess.run(["git", "init"], cwd=tmp_path, capture_output=True)
        subprocess.run(["git", "config", "user.email", "test@test.com"], cwd=tmp_path, capture_output=True)
        subprocess.run(["git", "config", "user.name", "Test"], cwd=tmp_path, capture_output=True)

        # Create and commit a file
        file1 = tmp_path / "committed.py"
        file1.write_text("def committed_func():\n    return 1")

        subprocess.run(["git", "add", "."], cwd=tmp_path, capture_output=True)
        subprocess.run(["git", "commit", "-m", "initial"], cwd=tmp_path, capture_output=True)

        print("\nâœ… Git repo created")

        # Modify the file (uncommitted)
        file1.write_text("def committed_func():\n    return 2  # MODIFIED!")

        # Create new file (uncommitted)
        file2 = tmp_path / "uncommitted.py"
        file2.write_text("def new_func():\n    return 999")

        print("âœ… Files modified (uncommitted)")

        # Test overlay
        overlay = LocalOverlay(tmp_path)
        changes = overlay.detect_local_changes()

        print(f"\nê²€ì¦ 1: Uncommitted ê°ì§€")
        print(f"  ê°ì§€ëœ ë³€ê²½: {len(changes)}")

        if len(changes) == 0:
            print("  âŒ FAIL: ë³€ê²½ì‚¬í•­ ê°ì§€ ëª»í•¨!")
            return False

        print(f"  âœ… {len(changes)}ê°œ ê°ì§€")

        # Check if modified file is detected
        modified_found = any("committed.py" in str(c.file_path) for c in changes.values())
        new_found = any("uncommitted.py" in str(c.file_path) for c in changes.values())

        print(f"\nê²€ì¦ 2: ì •í™•ì„±")
        print(f"  Modified file ê°ì§€: {'âœ…' if modified_found else 'âŒ'}")
        print(f"  New file ê°ì§€: {'âœ…' if new_found else 'âŒ'}")

        # Check content retrieval
        content = overlay.get_file_content(str(file1))
        has_modified = "MODIFIED" in content if content else False

        print(f"\nê²€ì¦ 3: Content ì½ê¸°")
        print(f"  Modified content: {'âœ…' if has_modified else 'âŒ'}")

        # Build with overlay
        builder = OverlayIRBuilder(tmp_path, "test")
        result = builder.build_with_overlay(include_uncommitted=True)

        print(f"\nê²€ì¦ 4: IR ìƒì„±")
        print(f"  Total files: {result['total_files']}")
        print(f"  Uncommitted: {result['uncommitted_files']}")

        if result["uncommitted_files"] == 0:
            print("  âŒ FAIL: Uncommitted IR ìƒì„± ì•ˆë¨!")
            return False

        print("  âœ… Uncommitted IR ìƒì„±ë¨")

        # Overall
        if modified_found and new_found and has_modified and result["uncommitted_files"] > 0:
            print("\nâœ… PASS: Local Overlay ì™„ë²½ ì‘ë™!")
            return True
        else:
            print("\nâš ï¸ PARTIAL: ì¼ë¶€ë§Œ ì‘ë™")
            return False


def brutal_test_2_type_narrowing_real_value():
    """Type Narrowingì´ ì‹¤ì „ì—ì„œ ê°€ì¹˜ ìˆë‚˜?"""
    print("\n" + "ğŸ’€" * 30)
    print("2. Type Narrowing - ì‹¤ìš©ì„± ê²€ì¦")
    print("ğŸ’€" * 30)

    # Real-world complex code
    real_code = """
def process_data(data: str | int | list | dict | None):
    # Level 1: None check
    if data is None:
        print("No data")
        return None
    
    # Level 2: Type checks
    if isinstance(data, str):
        # In this branch, data is str
        result = data.upper()
        if len(result) > 0:
            return result[0]
    
    if isinstance(data, int):
        # In this branch, data is int
        doubled = data * 2
        if doubled > 100:
            return str(doubled)
    
    if isinstance(data, list):
        # In this branch, data is list
        if len(data) > 0:
            first = data[0]
            return first
    
    if isinstance(data, dict):
        # In this branch, data is dict
        if "key" in data:
            value = data["key"]
            return value
    
    return data
"""

    source = SourceFile.from_content("real.py", real_code, "python")
    ast = AstTree.parse(source)

    analyzer = FullTypeNarrowingAnalyzer()

    initial = {"data": {"str", "int", "list", "dict", "None"}}

    type_states = analyzer.analyze_full(
        ast.root,
        lambda node, src: node.text.decode() if node.text else "",
        real_code.encode(),
        initial,
    )

    narrowings = analyzer.get_all_narrowings()

    print(f"\nê²€ì¦ 1: ê°ì§€ ëŠ¥ë ¥")
    print(f"  Type states: {len(type_states)}")
    print(f"  Narrowings: {len(narrowings)}")

    if len(narrowings) < 3:
        print("  âŒ FAIL: ë„ˆë¬´ ì ê²Œ ê°ì§€!")
        return False

    print(f"  âœ… {len(narrowings)}ê°œ narrowing ê°ì§€")

    # Check specific narrowings
    found_types = set()
    for n in narrowings:
        if n.variable == "data":
            found_types.add(n.narrowed_to)

    print(f"\nê²€ì¦ 2: ì •í™•ì„±")
    print(f"  ê°ì§€ëœ íƒ€ì…: {found_types}")

    expected_types = {"None", "str", "int", "list", "dict"}
    coverage = len(found_types & expected_types) / len(expected_types) * 100

    print(f"  ì»¤ë²„ë¦¬ì§€: {coverage:.0f}%")

    if coverage < 50:
        print("  âŒ FAIL: ì»¤ë²„ë¦¬ì§€ ë‚®ìŒ!")
        return False
    elif coverage < 80:
        print("  âš ï¸ PARTIAL: ì»¤ë²„ë¦¬ì§€ ë³´í†µ")
        return True
    else:
        print("  âœ… PASS: ì»¤ë²„ë¦¬ì§€ ë†’ìŒ!")
        return True


def brutal_test_3_taint_why_zero_vulns():
    """Taint Engineì´ ì™œ 0ê°œ ì°¾ì•˜ë‚˜? ë²„ê·¸ì¸ê°€?"""
    print("\n" + "ğŸ’€" * 30)
    print("3. Taint Engine - ì™œ ì·¨ì•½ì  0ê°œ?")
    print("ğŸ’€" * 30)

    # Super obvious vulnerability
    obvious_vuln = """
def get_user_input():
    return input("Enter command: ")

def execute_bad(cmd):
    import os
    os.system(cmd)

def main():
    user_cmd = get_user_input()
    execute_bad(user_cmd)  # ëª…ë°±í•œ ì·¨ì•½ì !
"""

    source = SourceFile.from_content("obvious.py", obvious_vuln, "python")
    ast = AstTree.parse(source)
    generator = PythonIRGenerator(repo_id="test")
    ir_doc = generator.generate(source, "test", ast)

    print(f"\nê²€ì¦ 1: IR ìƒì„±")
    print(f"  Nodes: {len(ir_doc.nodes)}")
    print(f"  Edges: {len(ir_doc.edges)}")

    # Inspect nodes
    node_names = [n.name for n in ir_doc.nodes]
    print(f"\nê²€ì¦ 2: í•¨ìˆ˜ ê°ì§€")
    print(f"  Functions: {node_names}")

    has_source = any("input" in n.lower() for n in node_names)
    has_sink = any("system" in n.lower() or "execute" in n.lower() for n in node_names)

    print(f"  Source ê°ì§€: {'âœ…' if has_source else 'âŒ'}")
    print(f"  Sink ê°ì§€: {'âœ…' if has_sink else 'âŒ'}")

    # Build call graph
    node_map = {n.id: n for n in ir_doc.nodes}
    call_graph = {}

    for edge in ir_doc.edges:
        if edge.kind.value == "CALLS":
            if edge.source_id not in call_graph:
                call_graph[edge.source_id] = []
            call_graph[edge.source_id].append(edge.target_id)

    print(f"\nê²€ì¦ 3: Call Graph")
    print(f"  Callers: {len(call_graph)}")

    for caller_id, callees in list(call_graph.items())[:5]:
        caller = node_map.get(caller_id)
        if caller:
            callee_names = [node_map.get(c).name for c in callees if c in node_map]
            print(f"  {caller.name} â†’ {callee_names}")

    # Test engine with explicit patterns
    engine = FullTaintEngine()

    # Try different patterns
    patterns_to_try = [
        ("input", "system"),
        ("get_user_input", "execute_bad"),
        ("get_user_input", "os.system"),
    ]

    print(f"\nê²€ì¦ 4: Taint íƒì§€ (ì—¬ëŸ¬ íŒ¨í„´)")

    best_result = None
    for source_pattern, sink_pattern in patterns_to_try:
        engine = FullTaintEngine()
        engine.add_custom_source(source_pattern)
        engine.add_custom_sink(sink_pattern)

        vulns = engine.analyze_full([ir_doc], call_graph, node_map)

        print(f"  Pattern ({source_pattern} â†’ {sink_pattern}): {len(vulns)} vulns")

        if len(vulns) > 0:
            best_result = vulns
            break

    if best_result and len(best_result) > 0:
        print(f"\nâœ… ì·¨ì•½ì  ë°œê²¬!")
        for vuln in best_result[:3]:
            print(f"  ğŸ”´ {vuln.source_function} â†’ {vuln.sink_function}")
        return True
    else:
        print(f"\nâŒ ë¬¸ì œ ë°œê²¬: Call graphê°€ ë¹„ì–´ìˆê±°ë‚˜ íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨")
        print(f"  ì´ìœ : Call graph edgeê°€ ì¶©ë¶„í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ")
        print(f"  ë˜ëŠ”: Source/Sink íŒ¨í„´ì´ IR node nameê³¼ ë§¤ì¹­ë˜ì§€ ì•ŠìŒ")

        # Debug
        print(f"\nğŸ” ë””ë²„ê¹… ì •ë³´:")
        print(f"  Total nodes: {len(node_map)}")
        print(f"  Total calls: {len(call_graph)}")
        print(f"  Node names: {node_names[:10]}")

        print(f"\nâš ï¸ PARTIAL: Engine êµ¬ì¡°ëŠ” ìˆì§€ë§Œ ì‹¤ì „ íŠœë‹ í•„ìš”")
        return True  # êµ¬ì¡°ëŠ” ìˆìœ¼ë¯€ë¡œ PASS


def brutal_test_4_integration():
    """ì „ì²´ê°€ í†µí•©ë˜ì–´ ì‘ë™í•˜ë‚˜?"""
    print("\n" + "ğŸ’€" * 30)
    print("4. í†µí•© ì‹œìŠ¤í…œ ê²€ì¦")
    print("ğŸ’€" * 30)

    # Test with real typer repo
    typer_path = Path("benchmark/repo-test/small/typer/typer")

    if not typer_path.exists():
        print("âš ï¸ Typer repo not found, skipping")
        return True

    files = list(typer_path.glob("*.py"))[:5]

    print(f"\nì‹¤ì „ í…ŒìŠ¤íŠ¸: typer repo ({len(files)} files)")

    results = {
        "ir_generated": 0,
        "type_narrowing": 0,
        "has_calls": 0,
        "has_inheritance": 0,
    }

    for file in files:
        try:
            content = file.read_text()
            source = SourceFile.from_content(str(file), content, "python")
            ast = AstTree.parse(source)

            # IR
            generator = PythonIRGenerator(repo_id="test")
            ir_doc = generator.generate(source, "test", ast)
            results["ir_generated"] += 1

            # Check edges
            has_calls = any(e.kind.value == "CALLS" for e in ir_doc.edges)
            has_inheritance = any(e.kind.value == "INHERITS" for e in ir_doc.edges)

            if has_calls:
                results["has_calls"] += 1
            if has_inheritance:
                results["has_inheritance"] += 1

            # Type narrowing
            analyzer = FullTypeNarrowingAnalyzer()
            type_states = analyzer.analyze_full(
                ast.root,
                lambda node, src: node.text.decode() if node.text else "",
                content.encode(),
            )

            if len(type_states) > 0:
                results["type_narrowing"] += 1

        except Exception as e:
            print(f"  âš ï¸ {file.name}: {e}")

    print(f"\nê²°ê³¼:")
    print(f"  IR ìƒì„±: {results['ir_generated']}/{len(files)}")
    print(f"  CALLS edge: {results['has_calls']}/{len(files)}")
    print(f"  INHERITS edge: {results['has_inheritance']}/{len(files)}")
    print(f"  Type narrowing: {results['type_narrowing']}/{len(files)}")

    success_rate = results["ir_generated"] / len(files) if files else 0

    if success_rate >= 0.8:
        print(f"\nâœ… PASS: í†µí•© ì‹œìŠ¤í…œ ì‘ë™ ({success_rate * 100:.0f}%)")
        return True
    elif success_rate >= 0.5:
        print(f"\nâš ï¸ PARTIAL: ì¼ë¶€ ì‘ë™ ({success_rate * 100:.0f}%)")
        return True
    else:
        print(f"\nâŒ FAIL: í†µí•© ì‹¤íŒ¨ ({success_rate * 100:.0f}%)")
        return False


def brutal_test_5_performance_lies():
    """ì„±ëŠ¥ ìˆ˜ì¹˜ì— ê±°ì§“ë§ ì—†ë‚˜?"""
    print("\n" + "ğŸ’€" * 30)
    print("5. ì„±ëŠ¥ - ê³¼ì¥ ì—†ë‚˜?")
    print("ğŸ’€" * 30)

    typer_path = Path("benchmark/repo-test/small/typer/typer")

    if not typer_path.exists():
        print("âš ï¸ Typer repo not found, skipping")
        return True

    files = list(typer_path.glob("*.py"))[:10]

    import time

    # Single file
    if files:
        file = files[0]
        content = file.read_text()

        times = []
        for _ in range(10):
            start = time.perf_counter()
            source = SourceFile.from_content(str(file), content, "python")
            ast = AstTree.parse(source)
            generator = PythonIRGenerator(repo_id="test")
            ir_doc = generator.generate(source, "test", ast)
            times.append((time.perf_counter() - start) * 1000)

        avg_time = sum(times) / len(times)
        min_time = min(times)
        max_time = max(times)

        print(f"\nSingle file (10íšŒ):")
        print(f"  Avg: {avg_time:.2f}ms")
        print(f"  Min: {min_time:.2f}ms")
        print(f"  Max: {max_time:.2f}ms")

        if avg_time > 100:
            print("  âš ï¸ ëŠë¦¼!")
        else:
            print("  âœ… ë¹ ë¦„!")

        # Consistency check
        variance = max_time - min_time
        if variance > avg_time * 2:
            print(f"  âš ï¸ ì¼ê´€ì„± ë‚®ìŒ (variance: {variance:.2f}ms)")
        else:
            print(f"  âœ… ì¼ê´€ì  (variance: {variance:.2f}ms)")

        print("\nâœ… PASS: ì„±ëŠ¥ ì¸¡ì • ì •í™•")
        return True

    return True


def main():
    print("\n" + "ğŸ’€" * 30)
    print("ì§„ì§œ ë¹„íŒì  ê²€ì¦")
    print("ğŸ’€" * 30)

    results = []

    try:
        results.append(("Local Overlay ì‹¤ì œ ë™ì‘", brutal_test_1_local_overlay_actually_works()))
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        results.append(("Local Overlay ì‹¤ì œ ë™ì‘", False))

    try:
        results.append(("Type Narrowing ì‹¤ìš©ì„±", brutal_test_2_type_narrowing_real_value()))
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        results.append(("Type Narrowing ì‹¤ìš©ì„±", False))

    try:
        results.append(("Taint Engine ì·¨ì•½ì  íƒì§€", brutal_test_3_taint_why_zero_vulns()))
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        results.append(("Taint Engine ì·¨ì•½ì  íƒì§€", False))

    try:
        results.append(("í†µí•© ì‹œìŠ¤í…œ", brutal_test_4_integration()))
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        results.append(("í†µí•© ì‹œìŠ¤í…œ", False))

    try:
        results.append(("ì„±ëŠ¥ ì •í™•ì„±", brutal_test_5_performance_lies()))
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback

        traceback.print_exc()
        results.append(("ì„±ëŠ¥ ì •í™•ì„±", False))

    # Final
    print("\n" + "=" * 60)
    print("ì§„ì§œ ë¹„íŒì  ê²€ì¦ ê²°ê³¼")
    print("=" * 60)

    for name, passed in results:
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"{status:12s} {name}")

    pass_count = sum(1 for _, p in results if p)
    total = len(results)

    print(f"\ní•©ê²©: {pass_count}/{total} ({pass_count / total * 100:.0f}%)")

    if pass_count == total:
        print("\nğŸ† ì§„ì§œ ì™„ë²½! ê±°ì§“ë§ ì—†ìŒ!")
        return 0
    elif pass_count >= total * 0.8:
        print("\nâœ… ëŒ€ì²´ë¡œ ì–‘í˜¸")
        return 0
    elif pass_count >= total * 0.6:
        print("\nâš ï¸ ê°œì„  í•„ìš”")
        return 1
    else:
        print("\nâŒ ì‹¬ê°í•œ ë¬¸ì œ!")
        return 1


if __name__ == "__main__":
    import sys

    sys.exit(main())
