#!/usr/bin/env python3
"""
SOTA IR í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ - Typer ë ˆí¬ì§€í† ë¦¬

IRì˜ ë³¸ì§ˆì  ê¸°ëŠ¥ë§Œ í…ŒìŠ¤íŠ¸:
1. Call Graph (í•¨ìˆ˜ í˜¸ì¶œ ê´€ê³„)
2. Class Hierarchy (ìƒì† ê´€ê³„)
3. Import/Dependency Graph
4. Definition-Use Chain (ë³€ìˆ˜ ì‚¬ìš©)
5. Type Resolution
6. Scope Chain
7. Edge ì¢…ë¥˜ë³„ ê²€ì¦
8. FQN ì •í™•ë„
"""

import asyncio
from pathlib import Path
from typing import List, Dict, Set
from collections import defaultdict


TYPER_REPO = Path("/Users/songmin/Documents/code-jo/semantica-v2/codegraph/benchmark/repo-test/small/typer")


def load_typer_ir():
    """Typer ë ˆí¬ì§€í† ë¦¬ IR ë¡œë“œ"""
    from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
    from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile

    typer_pkg = TYPER_REPO / "typer"
    python_files = list(typer_pkg.glob("**/*.py"))[:20]  # ì²˜ìŒ 20ê°œë§Œ

    print(f"Loading {len(python_files)} Python files...")

    generator = PythonIRGenerator(repo_id="typer")
    ir_docs = []

    for py_file in python_files:
        try:
            content = py_file.read_text(encoding="utf-8")
            source = SourceFile.from_content(str(py_file), content, "python")
            ast = AstTree.parse(source)
            ir_doc = generator.generate(source, "typer", ast)
            ir_docs.append(ir_doc)
        except Exception as e:
            print(f"  âš ï¸ Failed {py_file.name}: {e}")

    print(f"âœ… Loaded {len(ir_docs)} IR documents")
    return ir_docs


async def test_1_call_graph(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 1: Call Graph (í•¨ìˆ˜ í˜¸ì¶œ ê´€ê³„)"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 1: Call Graph (í•¨ìˆ˜ í˜¸ì¶œ ê´€ê³„)")
    print("=" * 60)

    # Edge kindê°€ CALLSì¸ ê²ƒë“¤ ì¶”ì¶œ
    call_edges = []
    for doc in ir_docs:
        for edge in doc.edges:
            if edge.kind.value == "CALLS":
                call_edges.append((doc, edge))

    print(f"\nCALLS edges: {len(call_edges)}ê°œ")

    if len(call_edges) == 0:
        print("âŒ CRITICAL: No CALLS edges found!")
        return False

    # ìƒ˜í”Œ call graph ì¶œë ¥
    print("\nìƒ˜í”Œ í•¨ìˆ˜ í˜¸ì¶œ:")
    node_by_id = {}
    for doc in ir_docs:
        for node in doc.nodes:
            node_by_id[node.id] = node

    for i, (doc, edge) in enumerate(call_edges[:10], 1):
        source_node = node_by_id.get(edge.source_id)
        target_node = node_by_id.get(edge.target_id)

        if source_node and target_node:
            source_name = source_node.name or source_node.id.split(":")[-1]
            target_name = target_node.name or target_node.id.split(":")[-1]
            print(f"  {i}. {source_name} â†’ calls â†’ {target_name}")

    # Call graph í†µê³„
    call_counts = defaultdict(int)
    for doc, edge in call_edges:
        source_node = node_by_id.get(edge.source_id)
        if source_node:
            call_counts[source_node.id] += 1

    top_callers = sorted(call_counts.items(), key=lambda x: x[1], reverse=True)[:5]
    print(f"\nTop callers (í˜¸ì¶œì„ ë§ì´ í•˜ëŠ” í•¨ìˆ˜):")
    for node_id, count in top_callers:
        node = node_by_id.get(node_id)
        name = node.name if node else node_id
        print(f"  - {name}: {count}ë²ˆ í˜¸ì¶œ")

    print(f"\nâœ… Call Graph ë™ì‘: {len(call_edges)}ê°œ í˜¸ì¶œ ê´€ê³„")
    return True


async def test_2_class_hierarchy(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 2: Class Hierarchy (ìƒì† ê´€ê³„)"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 2: Class Hierarchy (ìƒì† ê´€ê³„)")
    print("=" * 60)

    # INHERITS edge ì°¾ê¸°
    inherit_edges = []
    for doc in ir_docs:
        for edge in doc.edges:
            if edge.kind.value == "INHERITS":
                inherit_edges.append((doc, edge))

    print(f"\nINHERITS edges: {len(inherit_edges)}ê°œ")

    if len(inherit_edges) == 0:
        print("âš ï¸ No inheritance found (may be ok for some repos)")
        return True

    # ìƒì† ê´€ê³„ ì¶œë ¥
    node_by_id = {}
    for doc in ir_docs:
        for node in doc.nodes:
            node_by_id[node.id] = node

    print("\nìƒì† ê´€ê³„:")
    for i, (doc, edge) in enumerate(inherit_edges[:10], 1):
        child = node_by_id.get(edge.source_id)
        parent = node_by_id.get(edge.target_id)

        if child and parent:
            child_name = child.name or child.id.split(":")[-1]
            parent_name = parent.name or parent.id.split(":")[-1]
            print(f"  {i}. {child_name} extends {parent_name}")

    print(f"\nâœ… Class Hierarchy: {len(inherit_edges)}ê°œ ìƒì† ê´€ê³„")
    return True


async def test_3_import_dependencies(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 3: Import/Dependency ê´€ê³„"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 3: Import/Dependency ê´€ê³„")
    print("=" * 60)

    # IMPORTS edge ì°¾ê¸°
    import_edges = []
    for doc in ir_docs:
        for edge in doc.edges:
            if edge.kind.value == "IMPORTS":
                import_edges.append((doc, edge))

    print(f"\nIMPORTS edges: {len(import_edges)}ê°œ")

    if len(import_edges) == 0:
        print("âŒ CRITICAL: No IMPORTS edges found!")
        return False

    # Import ê´€ê³„ ì¶œë ¥
    node_by_id = {}
    for doc in ir_docs:
        for node in doc.nodes:
            node_by_id[node.id] = node

    print("\nìƒ˜í”Œ Import ê´€ê³„:")
    for i, (doc, edge) in enumerate(import_edges[:10], 1):
        importer = node_by_id.get(edge.source_id)
        imported = node_by_id.get(edge.target_id)

        if importer and imported:
            importer_file = importer.file_path.split("/")[-1]
            imported_name = imported.name or imported.id.split(":")[-1]
            print(f"  {i}. {importer_file} imports {imported_name}")

    # íŒŒì¼ë³„ import í†µê³„
    imports_by_file = defaultdict(set)
    for doc, edge in import_edges:
        source = node_by_id.get(edge.source_id)
        target = node_by_id.get(edge.target_id)
        if source and target:
            imports_by_file[source.file_path].add(target.name or target.id)

    print(f"\níŒŒì¼ë³„ Import í†µê³„:")
    for file_path, imports in sorted(imports_by_file.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
        file_name = file_path.split("/")[-1]
        print(f"  - {file_name}: {len(imports)} imports")

    print(f"\nâœ… Import Dependencies: {len(import_edges)}ê°œ")
    return True


async def test_4_definition_use_chain(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 4: Definition-Use Chain (ë³€ìˆ˜ ì •ì˜/ì‚¬ìš©)"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 4: Definition-Use Chain")
    print("=" * 60)

    # READS, WRITES edge ì°¾ê¸°
    read_edges = []
    write_edges = []

    for doc in ir_docs:
        for edge in doc.edges:
            if edge.kind.value == "READS":
                read_edges.append((doc, edge))
            elif edge.kind.value == "WRITES":
                write_edges.append((doc, edge))

    print(f"\nREADS edges: {len(read_edges)}ê°œ")
    print(f"WRITES edges: {len(write_edges)}ê°œ")

    total_def_use = len(read_edges) + len(write_edges)

    if total_def_use == 0:
        print("âš ï¸ No READS/WRITES edges (may need improvement)")
        return True

    # ìƒ˜í”Œ ì¶œë ¥
    node_by_id = {}
    for doc in ir_docs:
        for node in doc.nodes:
            node_by_id[node.id] = node

    if read_edges:
        print("\nìƒ˜í”Œ READS:")
        for i, (doc, edge) in enumerate(read_edges[:5], 1):
            reader = node_by_id.get(edge.source_id)
            variable = node_by_id.get(edge.target_id)
            if reader and variable:
                print(f"  {i}. {reader.name} reads {variable.name}")

    if write_edges:
        print("\nìƒ˜í”Œ WRITES:")
        for i, (doc, edge) in enumerate(write_edges[:5], 1):
            writer = node_by_id.get(edge.source_id)
            variable = node_by_id.get(edge.target_id)
            if writer and variable:
                print(f"  {i}. {writer.name} writes {variable.name}")

    print(f"\nâœ… Definition-Use Chain: {total_def_use}ê°œ")
    return True


async def test_5_contains_hierarchy(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 5: CONTAINS ê³„ì¸µ êµ¬ì¡°"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 5: CONTAINS ê³„ì¸µ êµ¬ì¡° (Scope)")
    print("=" * 60)

    contains_edges = []
    for doc in ir_docs:
        for edge in doc.edges:
            if edge.kind.value == "CONTAINS":
                contains_edges.append((doc, edge))

    print(f"\nCONTAINS edges: {len(contains_edges)}ê°œ")

    if len(contains_edges) == 0:
        print("âŒ CRITICAL: No CONTAINS edges!")
        return False

    # Build containment tree for one file
    node_by_id = {}
    for doc in ir_docs:
        for node in doc.nodes:
            node_by_id[node.id] = node

    # ìƒ˜í”Œ ê³„ì¸µ êµ¬ì¡°
    print("\nìƒ˜í”Œ CONTAINS ê³„ì¸µ:")
    shown = 0
    for doc, edge in contains_edges[:20]:
        parent = node_by_id.get(edge.source_id)
        child = node_by_id.get(edge.target_id)

        if parent and child and parent.kind.value == "Class":
            print(f"  Class {parent.name} contains:")
            # Find all children
            children = [e for d, e in contains_edges if e.source_id == parent.id]
            for child_edge in children[:5]:
                child_node = node_by_id.get(child_edge.target_id)
                if child_node:
                    print(f"    - {child_node.kind.value}: {child_node.name}")
            shown += 1
            if shown >= 3:
                break

    print(f"\nâœ… CONTAINS hierarchy: {len(contains_edges)}ê°œ")
    return True


async def test_6_edge_kind_coverage(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 6: Edge ì¢…ë¥˜ë³„ ì»¤ë²„ë¦¬ì§€"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 6: Edge Kind ì»¤ë²„ë¦¬ì§€")
    print("=" * 60)

    edge_kinds = defaultdict(int)
    for doc in ir_docs:
        for edge in doc.edges:
            edge_kinds[edge.kind.value] += 1

    total_edges = sum(edge_kinds.values())

    print(f"\nì´ Edges: {total_edges}ê°œ")
    print(f"Edge Kind ì¢…ë¥˜: {len(edge_kinds)}ê°œ")

    print("\nEdge Kind ë¶„í¬:")
    for kind, count in sorted(edge_kinds.items(), key=lambda x: x[1], reverse=True):
        pct = (count / total_edges) * 100 if total_edges > 0 else 0
        print(f"  {kind:20s}: {count:6,} ({pct:5.1f}%)")

    # í•„ìˆ˜ edge kinds ì²´í¬
    required_edges = ["CONTAINS", "CALLS", "IMPORTS"]
    missing = []
    for req in required_edges:
        if req not in edge_kinds:
            missing.append(req)

    if missing:
        print(f"\nâŒ Missing required edges: {missing}")
        return False
    else:
        print(f"\nâœ… All required edges present")

    return True


async def test_7_node_kind_coverage(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 7: Node ì¢…ë¥˜ë³„ ì»¤ë²„ë¦¬ì§€"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 7: Node Kind ì»¤ë²„ë¦¬ì§€")
    print("=" * 60)

    node_kinds = defaultdict(int)
    for doc in ir_docs:
        for node in doc.nodes:
            node_kinds[node.kind.value] += 1

    total_nodes = sum(node_kinds.values())

    print(f"\nì´ Nodes: {total_nodes}ê°œ")
    print(f"Node Kind ì¢…ë¥˜: {len(node_kinds)}ê°œ")

    print("\nNode Kind ë¶„í¬:")
    for kind, count in sorted(node_kinds.items(), key=lambda x: x[1], reverse=True):
        pct = (count / total_nodes) * 100 if total_nodes > 0 else 0
        print(f"  {kind:20s}: {count:6,} ({pct:5.1f}%)")

    # í•„ìˆ˜ node kinds ì²´í¬
    required_nodes = ["Class", "Function", "Method"]
    missing = []
    for req in required_nodes:
        if req not in node_kinds:
            missing.append(req)

    if missing:
        print(f"\nâš ï¸ Missing some node kinds: {missing}")
    else:
        print(f"\nâœ… All required nodes present")

    return True


async def test_8_fqn_quality(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 8: FQN í’ˆì§ˆ"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 8: FQN (Fully Qualified Name) í’ˆì§ˆ")
    print("=" * 60)

    all_fqns = []
    nodes_without_fqn = 0

    for doc in ir_docs:
        for node in doc.nodes:
            if node.fqn:
                all_fqns.append((node.kind.value, node.name, node.fqn))
            else:
                nodes_without_fqn += 1

    total_nodes = sum(len(doc.nodes) for doc in ir_docs)

    print(f"\nì´ Nodes: {total_nodes}")
    print(f"FQN ìˆìŒ: {len(all_fqns)} ({len(all_fqns) / total_nodes * 100:.1f}%)")
    print(f"FQN ì—†ìŒ: {nodes_without_fqn} ({nodes_without_fqn / total_nodes * 100:.1f}%)")

    # FQN ìƒ˜í”Œ
    print("\nìƒ˜í”Œ FQNs:")
    for i, (kind, name, fqn) in enumerate(all_fqns[:10], 1):
        # Shorten FQN for display
        fqn_display = fqn if len(fqn) < 80 else fqn[:77] + "..."
        print(f"  {i}. {kind:10s} {name:20s}")
        print(f"     â†’ {fqn_display}")

    # FQN ìœ ë‹ˆí¬ì„± ì²´í¬
    fqn_only = [fqn for _, _, fqn in all_fqns]
    unique_fqns = set(fqn_only)
    duplicates = len(fqn_only) - len(unique_fqns)

    print(f"\nFQN ìœ ë‹ˆí¬ì„±:")
    print(f"  - Total: {len(fqn_only)}")
    print(f"  - Unique: {len(unique_fqns)}")
    print(f"  - Duplicates: {duplicates}")

    if duplicates > 0:
        print(f"  âš ï¸ {duplicates} duplicate FQNs (may be ok for overloads)")
    else:
        print(f"  âœ… All FQNs unique")

    return True


async def test_9_span_accuracy(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 9: Span ì •í™•ë„"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 9: Span (ìœ„ì¹˜ ì •ë³´) ì •í™•ë„")
    print("=" * 60)

    invalid_spans = []
    valid_spans = 0

    for doc in ir_docs:
        for node in doc.nodes:
            if node.span.start_line > node.span.end_line:
                invalid_spans.append((node.name, node.span))
            elif node.span.start_line < 0:
                invalid_spans.append((node.name, node.span))
            else:
                valid_spans += 1

    total = valid_spans + len(invalid_spans)

    print(f"\nì´ Spans: {total}")
    print(f"Valid: {valid_spans} ({valid_spans / total * 100:.1f}%)")
    print(f"Invalid: {len(invalid_spans)} ({len(invalid_spans) / total * 100:.1f}%)")

    if invalid_spans:
        print("\nâš ï¸ Invalid spans:")
        for name, span in invalid_spans[:5]:
            print(f"  - {name}: {span.start_line}-{span.end_line}")
        return False
    else:
        print("\nâœ… All spans valid")
        return True


async def test_10_docstring_extraction(ir_docs: List):
    """í…ŒìŠ¤íŠ¸ 10: Docstring ì¶”ì¶œ"""
    print("\n" + "=" * 60)
    print("í…ŒìŠ¤íŠ¸ 10: Docstring ì¶”ì¶œ")
    print("=" * 60)

    with_docstring = 0
    without_docstring = 0

    docstring_samples = []

    for doc in ir_docs:
        for node in doc.nodes:
            # Class, Function, Methodë§Œ ì²´í¬
            if node.kind.value in ["Class", "Function", "Method"]:
                if node.docstring:
                    with_docstring += 1
                    if len(docstring_samples) < 5:
                        docstring_samples.append((node.kind.value, node.name, node.docstring))
                else:
                    without_docstring += 1

    total = with_docstring + without_docstring

    print(f"\nì´ í•¨ìˆ˜/í´ë˜ìŠ¤: {total}")
    print(f"Docstring ìˆìŒ: {with_docstring} ({with_docstring / total * 100:.1f}%)")
    print(f"Docstring ì—†ìŒ: {without_docstring} ({without_docstring / total * 100:.1f}%)")

    print("\nìƒ˜í”Œ Docstrings:")
    for kind, name, docstring in docstring_samples:
        doc_preview = docstring[:60] + "..." if len(docstring) > 60 else docstring
        print(f"  {kind} {name}:")
        print(f'    "{doc_preview}"')

    if with_docstring > 0:
        print(f"\nâœ… Docstring extraction working")
    else:
        print(f"\nâš ï¸ No docstrings found (may be repo issue)")

    return True


async def main():
    """ì „ì²´ IR í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸"""
    print("\n" + "ğŸ”¬" + "=" * 58 + "ğŸ”¬")
    print("   SOTA IR í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("   Call Graph, Class Hierarchy, Dependencies, etc.")
    print("ğŸ”¬" + "=" * 58 + "ğŸ”¬")

    # Load IR
    ir_docs = load_typer_ir()

    if not ir_docs:
        print("\nâŒ Failed to load IR documents")
        return 1

    # Run tests
    tests = [
        ("Call Graph", test_1_call_graph),
        ("Class Hierarchy", test_2_class_hierarchy),
        ("Import Dependencies", test_3_import_dependencies),
        ("Definition-Use Chain", test_4_definition_use_chain),
        ("CONTAINS Hierarchy", test_5_contains_hierarchy),
        ("Edge Kind Coverage", test_6_edge_kind_coverage),
        ("Node Kind Coverage", test_7_node_kind_coverage),
        ("FQN Quality", test_8_fqn_quality),
        ("Span Accuracy", test_9_span_accuracy),
        ("Docstring Extraction", test_10_docstring_extraction),
    ]

    results = []

    for test_name, test_func in tests:
        try:
            passed = await test_func(ir_docs)
            results.append((test_name, passed))
        except Exception as e:
            results.append((test_name, False))
            print(f"\nâŒ Exception: {e}")
            import traceback

            traceback.print_exc()

    # Summary
    print("\n" + "=" * 60)
    print("IR í•µì‹¬ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼")
    print("=" * 60)

    for test_name, passed in results:
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"{status} {test_name}")

    passed_count = sum(1 for _, p in results if p)
    total_count = len(results)

    print("=" * 60)
    print(f"ê²°ê³¼: {passed_count}/{total_count} í…ŒìŠ¤íŠ¸ í†µê³¼ ({passed_count / total_count * 100:.0f}%)")

    if passed_count == total_count:
        print("\nğŸ‰ ëª¨ë“  IR í•µì‹¬ ê¸°ëŠ¥ ë™ì‘!")
        return 0
    else:
        print(f"\nâš ï¸ {total_count - passed_count}ê°œ ê¸°ëŠ¥ ê°œì„  í•„ìš”")
        return 1


if __name__ == "__main__":
    import sys

    sys.exit(asyncio.run(main()))
