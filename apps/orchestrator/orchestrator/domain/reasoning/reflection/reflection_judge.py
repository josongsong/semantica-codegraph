"""
Self-Reflection Judge (v8.1)

SOTA: Graph Stability + Execution Trace Analysis
"""

import logging

from .reflection_models import (
    ReflectionInput,
    ReflectionOutput,
    ReflectionRules,
    ReflectionVerdict,
    StabilityLevel,
)

logger = logging.getLogger(__name__)


class SelfReflectionJudge:
    """
    Self-Reflection Judge (Domain Service)

    ì±…ì„:
    - Graph Impact ë¶„ì„
    - Execution Trace ê²€ì¦
    - Accept/Revise/Rollback íŒì •

    SOTA ê¸°ë²•:
    - Multi-Criteria Decision Making
    - Graph Stability Analysis (CFG/DFG/PDG)
    - Regression Detection
    """

    def __init__(self, weights: dict[str, float] | None = None):
        """
        Args:
            weights: ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ (Optional)
        """
        self.weights = weights or ReflectionRules.get_weights()

        # ê°€ì¤‘ì¹˜ ê²€ì¦
        total = sum(self.weights.values())
        if abs(total - 1.0) > 0.001:
            raise ValueError(f"Weights must sum to 1.0, got {total}")

        logger.info(f"Self-Reflection Judge initialized with weights: {self.weights}")

    def judge(self, input: ReflectionInput) -> ReflectionOutput:
        """
        íŒì • (í•µì‹¬ ë¹„ì¦ˆë‹ˆìŠ¤ ë¡œì§)

        Decision Flow:
        1. Critical Issues Check (ì¦‰ì‹œ ê±°ë¶€)
        2. Graph Stability Analysis
        3. Execution Trace Validation
        4. Multi-Criteria Scoring
        5. Verdict ê²°ì •

        Args:
            input: ReflectionInput

        Returns:
            ReflectionOutput
        """
        logger.info(f"Judging strategy: {input.strategy_id}")

        # Step 1: Critical Issues (Fast Fail)
        critical_issues = self._check_critical_issues(input)
        if critical_issues:
            return self._create_rollback_output(input, critical_issues, "Critical issues detected - immediate rollback")

        # Step 2: Graph Stability
        input.graph_impact.impact_score = input.graph_impact.calculate_impact_score()
        input.graph_impact.stability_level = input.graph_impact.determine_stability()

        if input.graph_impact.stability_level == StabilityLevel.CRITICAL:
            return self._create_rollback_output(
                input, ["Graph stability critical"], "Massive graph changes - rollback recommended"
            )

        # Step 3: Execution Trace
        if input.execution_trace.has_regressions():
            return self._create_revise_output(
                input, ["Regressions detected in execution trace"], "Performance or coverage degraded"
            )

        # Step 4: Multi-Criteria Scoring
        score = self._calculate_confidence_score(input)

        # Step 5: Verdict
        verdict = self._determine_verdict(input, score)

        # Build Output
        return self._create_output(input, verdict, score)

    # ========================================================================
    # Critical Checks
    # ========================================================================

    def _check_critical_issues(self, input: ReflectionInput) -> list[str]:
        """
        ì¹˜ëª…ì  ì´ìŠˆ í™•ì¸

        Returns:
            List of critical issues (empty if none)
        """
        issues = []

        # Execution Failure
        if not input.execution_success:
            issues.append("Execution failed")

        # Test Pass Rate Too Low
        if input.test_pass_rate < ReflectionRules.MIN_TEST_PASS_RATE:
            issues.append(f"Test pass rate {input.test_pass_rate:.0%} < {ReflectionRules.MIN_TEST_PASS_RATE:.0%}")

        # New Exceptions
        if len(input.execution_trace.new_exceptions) > 0:
            issues.append(f"New exceptions: {', '.join(input.execution_trace.new_exceptions[:3])}")

        return issues

    # ========================================================================
    # Scoring
    # ========================================================================

    def _calculate_confidence_score(self, input: ReflectionInput) -> float:
        """
        ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (Multi-Criteria)

        Returns:
            0.0 ~ 1.0
        """
        # 1. Execution Score
        exec_score = input.test_pass_rate  # 0.0 ~ 1.0

        # 2. Graph Score (ë‚®ì€ impact = ë†’ì€ ì ìˆ˜)
        graph_score = 1.0 - input.graph_impact.impact_score

        # 3. Trace Score
        trace_score = self._score_execution_trace(input.execution_trace)

        # 4. Historical Score
        historical_score = self._score_historical(input)

        # Weighted Sum
        total_score = (
            exec_score * self.weights["execution"]
            + graph_score * self.weights["graph"]
            + trace_score * self.weights["trace"]
            + historical_score * self.weights["historical"]
        )

        logger.debug(
            f"Confidence: exec={exec_score:.2f}, graph={graph_score:.2f}, "
            f"trace={trace_score:.2f}, hist={historical_score:.2f} "
            f"â†’ total={total_score:.2f}"
        )

        return min(total_score, 1.0)

    def _score_execution_trace(self, trace) -> float:
        """ì‹¤í–‰ ì¶”ì  ì ìˆ˜"""
        score = 1.0

        # Coverage ì¦ê°€ëŠ” ë³´ë„ˆìŠ¤
        coverage_delta = trace.coverage_after - trace.coverage_before
        if coverage_delta > 0:
            score += min(coverage_delta, 0.1)  # max +0.1
        elif coverage_delta < -0.05:
            score -= 0.2  # 5% ì´ìƒ ê°ì†ŒëŠ” í˜ë„í‹°

        # Performance ê°œì„ ì€ ë³´ë„ˆìŠ¤
        if trace.execution_time_delta < 0:  # ë¹¨ë¼ì§
            score += 0.05
        elif trace.execution_time_delta > 1.0:  # 1ì´ˆ ì´ìƒ ëŠë ¤ì§
            score -= 0.1

        # Exception ìˆ˜ì •ì€ ë³´ë„ˆìŠ¤
        if len(trace.fixed_exceptions) > 0:
            score += min(len(trace.fixed_exceptions) * 0.05, 0.15)

        return max(min(score, 1.0), 0.0)

    def _score_historical(self, input: ReflectionInput) -> float:
        """ê³¼ê±° ì„±ê³µë¥  ì ìˆ˜"""
        # ìœ ì‚¬ ì‹¤íŒ¨ê°€ ë§ìœ¼ë©´ ë‚®ì€ ì ìˆ˜
        if input.similar_failures_count > 5:
            return 0.3
        elif input.similar_failures_count > 2:
            return 0.6
        else:
            return 0.9

    # ========================================================================
    # Verdict Decision
    # ========================================================================

    def _determine_verdict(self, input: ReflectionInput, score: float) -> ReflectionVerdict:
        """
        Verdict ê²°ì • (Business Rule)

        Logic:
        - score >= 0.8 AND stable â†’ ACCEPT
        - score >= 0.6 AND moderate â†’ REVISE
        - score < 0.6 OR unstable â†’ RETRY
        - critical â†’ ROLLBACK
        """
        stability = input.graph_impact.stability_level

        # High Confidence + Stable â†’ Accept
        if score >= 0.8 and stability == StabilityLevel.STABLE:
            return ReflectionVerdict.ACCEPT

        # Medium Confidence + Moderate â†’ Revise
        if score >= 0.6 and stability in (StabilityLevel.STABLE, StabilityLevel.MODERATE):
            return ReflectionVerdict.REVISE

        # Unstable â†’ Retry
        if stability == StabilityLevel.UNSTABLE:
            return ReflectionVerdict.RETRY

        # Low Confidence â†’ Retry
        if score < 0.5:
            return ReflectionVerdict.RETRY

        # Default: Revise
        return ReflectionVerdict.REVISE

    # ========================================================================
    # Output Builders
    # ========================================================================

    def _create_output(self, input: ReflectionInput, verdict: ReflectionVerdict, score: float) -> ReflectionOutput:
        """ì¼ë°˜ Output ìƒì„±"""

        # Warnings
        warnings = []
        if input.graph_impact.stability_level == StabilityLevel.MODERATE:
            warnings.append("Moderate graph changes - review carefully")

        if input.execution_trace.execution_time_delta > 0.5:
            warnings.append(f"Performance degradation: +{input.execution_trace.execution_time_delta:.1f}s")

        # Suggestions
        suggestions = self._generate_suggestions(input, verdict)

        # Reasoning
        reasoning = self._generate_reasoning(input, verdict, score)

        return ReflectionOutput(
            verdict=verdict,
            confidence=score,
            reasoning=reasoning,
            graph_stability=input.graph_impact.stability_level,
            impact_score=input.graph_impact.impact_score,
            warnings=warnings,
            suggested_fixes=suggestions,
        )

    def _create_rollback_output(self, input: ReflectionInput, issues: list[str], reasoning: str) -> ReflectionOutput:
        """Rollback Output"""
        return ReflectionOutput(
            verdict=ReflectionVerdict.ROLLBACK,
            confidence=0.0,
            reasoning=reasoning,
            graph_stability=input.graph_impact.stability_level,
            impact_score=input.graph_impact.impact_score,
            critical_issues=issues,
            suggested_fixes=["Rollback to previous version", "Investigate root cause"],
        )

    def _create_revise_output(self, input: ReflectionInput, warnings: list[str], reasoning: str) -> ReflectionOutput:
        """Revise Output"""
        score = self._calculate_confidence_score(input)

        return ReflectionOutput(
            verdict=ReflectionVerdict.REVISE,
            confidence=score,
            reasoning=reasoning,
            graph_stability=input.graph_impact.stability_level,
            impact_score=input.graph_impact.impact_score,
            warnings=warnings,
            suggested_fixes=self._generate_suggestions(input, ReflectionVerdict.REVISE),
        )

    # ========================================================================
    # Helpers
    # ========================================================================

    def _generate_suggestions(self, input: ReflectionInput, verdict: ReflectionVerdict) -> list[str]:
        """ì œì•ˆ ìƒì„±"""
        suggestions = []

        if verdict == ReflectionVerdict.REVISE:
            if input.test_pass_rate < 0.9:
                suggestions.append("Add more test coverage")

            if input.graph_impact.impact_score > 0.4:
                suggestions.append("Reduce graph impact - smaller changes")

            if len(input.execution_trace.new_exceptions) > 0:
                suggestions.append("Fix new exceptions before proceeding")

        elif verdict == ReflectionVerdict.RETRY:
            suggestions.append("Try alternative strategy")
            suggestions.append("Break into smaller changes")

        return suggestions

    def _generate_reasoning(self, input: ReflectionInput, verdict: ReflectionVerdict, score: float) -> str:
        """íŒì • ê·¼ê±° ìƒì„±"""
        stability = input.graph_impact.stability_level.value

        if verdict == ReflectionVerdict.ACCEPT:
            return (
                f"âœ… ACCEPT (confidence={score:.2f})\n"
                f"  - Test pass rate: {input.test_pass_rate:.0%}\n"
                f"  - Graph stability: {stability}\n"
                f"  - Impact: {input.graph_impact.impact_score:.2f}\n"
                f"  â†’ Safe to proceed"
            )

        elif verdict == ReflectionVerdict.REVISE:
            return (
                f"âš ï¸ REVISE (confidence={score:.2f})\n"
                f"  - Needs improvement before acceptance\n"
                f"  - Review warnings and fix suggested issues"
            )

        elif verdict == ReflectionVerdict.RETRY:
            return f"ğŸ”„ RETRY (confidence={score:.2f})\n  - Current approach not optimal\n  - Try alternative strategy"

        else:  # ROLLBACK
            return "âŒ ROLLBACK\n  - Critical issues detected\n  - Immediate rollback recommended"
