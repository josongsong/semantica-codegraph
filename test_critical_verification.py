#!/usr/bin/env python3
"""
ë¹„íŒì  ê²€ì¦ - ì‹¤ì œë¡œ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸

í…ŒìŠ¤íŠ¸ í†µê³¼ëŠ” í–ˆì§€ë§Œ:
1. ë°ì´í„°ê°€ ì •í™•í•œê°€?
2. ë¹ˆ ê²°ê³¼ê°€ ì•„ë‹Œê°€?
3. ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•œê°€?
4. ì„±ëŠ¥ì€ ê´œì°®ì€ê°€?
"""

import asyncio
import tempfile
import time
from pathlib import Path
from textwrap import dedent


def create_real_project(tmp_path: Path):
    """ì‹¤ì œ ë ˆí¬ì§€í† ë¦¬ì™€ ìœ ì‚¬í•œ í”„ë¡œì íŠ¸ ìƒì„±"""

    # src/models.py
    models_py = tmp_path / "src" / "models.py"
    models_py.parent.mkdir(parents=True)
    models_py.write_text(
        dedent("""
        '''Data models'''
        from typing import List, Optional
        
        class User:
            '''User model'''
            def __init__(self, name: str, email: str):
                self.name = name
                self.email = email
                self.posts: List['Post'] = []
            
            def add_post(self, post: 'Post'):
                '''Add a post to user'''
                self.posts.append(post)
                post.author = self
            
            def get_posts(self) -> List['Post']:
                '''Get all user posts'''
                return self.posts
        
        class Post:
            '''Post model'''
            def __init__(self, title: str, content: str):
                self.title = title
                self.content = content
                self.author: Optional[User] = None
            
            def set_author(self, user: User):
                '''Set post author'''
                self.author = user
    """).strip()
    )

    # src/service.py
    service_py = tmp_path / "src" / "service.py"
    service_py.write_text(
        dedent("""
        '''Business logic'''
        from models import User, Post
        
        class UserService:
            '''User service'''
            def __init__(self):
                self.users: dict[str, User] = {}
            
            def create_user(self, name: str, email: str) -> User:
                '''Create a new user'''
                user = User(name, email)
                self.users[email] = user
                return user
            
            def get_user(self, email: str) -> User | None:
                '''Get user by email'''
                return self.users.get(email)
            
            def create_post(self, email: str, title: str, content: str) -> Post:
                '''Create a post for user'''
                user = self.get_user(email)
                if not user:
                    raise ValueError(f"User not found: {email}")
                
                post = Post(title, content)
                user.add_post(post)
                return post
    """).strip()
    )

    # src/main.py
    main_py = tmp_path / "src" / "main.py"
    main_py.write_text(
        dedent("""
        '''Main application'''
        from service import UserService
        
        def main():
            '''Run application'''
            service = UserService()
            
            # Create users
            alice = service.create_user("Alice", "alice@example.com")
            bob = service.create_user("Bob", "bob@example.com")
            
            # Create posts
            post1 = service.create_post("alice@example.com", "Hello", "First post")
            post2 = service.create_post("bob@example.com", "Hi", "Second post")
            
            # Print results
            print(f"Alice has {len(alice.get_posts())} posts")
            print(f"Bob has {len(bob.get_posts())} posts")
        
        if __name__ == "__main__":
            main()
    """).strip()
    )

    return tmp_path


async def critical_test_1_data_quality():
    """ë¹„íŒì  ê²€ì¦ 1: ìƒì„±ëœ ë°ì´í„° í’ˆì§ˆ"""
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ 1: ë°ì´í„° í’ˆì§ˆ")
    print("=" * 60)

    with tempfile.TemporaryDirectory() as tmpdir:
        test_proj = create_real_project(Path(tmpdir))

        from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
        from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile

        # models.py ìƒì„±
        models_file = test_proj / "src" / "models.py"
        content = models_file.read_text()
        source = SourceFile.from_content(str(models_file), content, "python")
        ast = AstTree.parse(source)
        generator = PythonIRGenerator(repo_id="test_repo")
        ir_doc = generator.generate(source, "test", ast)

        # ê²€ì¦ 1: í´ë˜ìŠ¤ê°€ ì œëŒ€ë¡œ ì¸ì‹ë˜ì—ˆëŠ”ê°€?
        classes = [n for n in ir_doc.nodes if n.kind.value == "Class"]
        print(f"âœ“ Classes found: {len(classes)}")
        assert len(classes) == 2, f"Expected 2 classes, found {len(classes)}"

        class_names = [c.name for c in classes]
        assert "User" in class_names, "User class not found!"
        assert "Post" in class_names, "Post class not found!"
        print(f"  - {class_names}")

        # ê²€ì¦ 2: ë©”ì†Œë“œê°€ ì œëŒ€ë¡œ ì¸ì‹ë˜ì—ˆëŠ”ê°€?
        methods = [n for n in ir_doc.nodes if n.kind.value == "Method"]
        print(f"âœ“ Methods found: {len(methods)}")

        method_names = [m.name for m in methods]
        assert "__init__" in method_names, "__init__ not found!"
        assert "add_post" in method_names, "add_post not found!"
        assert "get_posts" in method_names, "get_posts not found!"
        print(f"  - Sample: {method_names[:5]}")

        # ê²€ì¦ 3: Docstringì´ ì œëŒ€ë¡œ ì¶”ì¶œë˜ì—ˆëŠ”ê°€?
        user_class = [c for c in classes if c.name == "User"][0]
        assert user_class.docstring, "User class docstring missing!"
        print(f"âœ“ Docstrings: User = '{user_class.docstring}'")

        # ê²€ì¦ 4: FQNì´ ì œëŒ€ë¡œ ìƒì„±ë˜ì—ˆëŠ”ê°€?
        assert user_class.fqn, "User class FQN missing!"
        print(f"âœ“ FQN: {user_class.fqn}")

        # ê²€ì¦ 5: Edgesê°€ ì˜ë¯¸ìˆê²Œ ìƒì„±ë˜ì—ˆëŠ”ê°€?
        contains_edges = [e for e in ir_doc.edges if e.kind.value == "CONTAINS"]
        print(f"âœ“ CONTAINS edges: {len(contains_edges)}")
        assert len(contains_edges) > 0, "No CONTAINS edges!"

        return True


async def critical_test_2_occurrence_accuracy():
    """ë¹„íŒì  ê²€ì¦ 2: Occurrence ì •í™•ë„"""
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ 2: Occurrence ì •í™•ë„")
    print("=" * 60)

    with tempfile.TemporaryDirectory() as tmpdir:
        test_proj = create_real_project(Path(tmpdir))

        from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
        from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile
        from src.contexts.code_foundation.infrastructure.ir.occurrence_generator import OccurrenceGenerator

        # service.py ìƒì„± (imports User, Post)
        service_file = test_proj / "src" / "service.py"
        content = service_file.read_text()
        source = SourceFile.from_content(str(service_file), content, "python")
        ast = AstTree.parse(source)
        generator = PythonIRGenerator(repo_id="test_repo")
        ir_doc = generator.generate(source, "test", ast)

        # Occurrence ìƒì„±
        occ_gen = OccurrenceGenerator()
        occurrences, occ_index = occ_gen.generate(ir_doc)

        # ê²€ì¦ 1: Definition vs Reference ë¹„ìœ¨ì´ í•©ë¦¬ì ì¸ê°€?
        definitions = [o for o in occurrences if o.is_definition()]
        references = [o for o in occurrences if o.is_reference()]

        print(f"âœ“ Definitions: {len(definitions)}")
        print(f"âœ“ References: {len(references)}")

        # Referenceê°€ ìˆì–´ì•¼ í•¨ (UserServiceëŠ” User, Postë¥¼ ì‚¬ìš©)
        # í•˜ì§€ë§Œ í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” referenceê°€ ì ì„ ìˆ˜ ìˆìŒ
        print(f"  - Ratio: {len(definitions)}:{len(references)}")

        # ê²€ì¦ 2: íŠ¹ì • ì‹¬ë³¼ì˜ occurrenceë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ”ê°€?
        # UserService í´ë˜ìŠ¤ë¥¼ ì°¾ê¸°
        user_service_defs = [o for o in definitions if "UserService" in o.symbol_id]

        if user_service_defs:
            print(f"âœ“ UserService definitions: {len(user_service_defs)}")
            print(f"  - Symbol ID: {user_service_defs[0].symbol_id}")
            print(f"  - Roles: {user_service_defs[0].roles}")
        else:
            print("âš  UserService definition not found in occurrences")

        # ê²€ì¦ 3: Indexê°€ ì œëŒ€ë¡œ ë™ì‘í•˜ëŠ”ê°€?
        stats = occ_index.get_stats()
        print(f"âœ“ Index stats: {stats}")
        assert stats["total_occurrences"] > 0, "Index is empty!"

        # ê²€ì¦ 4: File-based queryê°€ ë™ì‘í•˜ëŠ”ê°€?
        file_occs = occ_index.get_file_occurrences(str(service_file))

        # CRITICAL: External symbols (imports) have file_path='<external>'
        # They shouldn't be included in file-specific queries
        local_occs = [o for o in occurrences if o.file_path == str(service_file)]
        external_occs = [o for o in occurrences if o.file_path == "<external>"]

        print(f"âœ“ File occurrences: {len(file_occs)}")
        print(f"  - Local: {len(local_occs)}, External: {len(external_occs)}")

        # File query should return only local occurrences, NOT external ones
        assert len(file_occs) == len(local_occs), (
            f"File index mismatch! Expected {len(local_occs)} local, got {len(file_occs)}"
        )

        return True


async def critical_test_3_cross_file_accuracy():
    """ë¹„íŒì  ê²€ì¦ 3: Cross-file resolution ì •í™•ë„"""
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ 3: Cross-file Resolution ì •í™•ë„")
    print("=" * 60)

    with tempfile.TemporaryDirectory() as tmpdir:
        test_proj = create_real_project(Path(tmpdir))

        from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
        from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile
        from src.contexts.code_foundation.infrastructure.ir.cross_file_resolver import CrossFileResolver

        # 3ê°œ íŒŒì¼ ëª¨ë‘ ìƒì„±
        files = [
            test_proj / "src" / "models.py",
            test_proj / "src" / "service.py",
            test_proj / "src" / "main.py",
        ]

        ir_docs = []
        for file_path in files:
            content = file_path.read_text()
            source = SourceFile.from_content(str(file_path), content, "python")
            ast = AstTree.parse(source)
            generator = PythonIRGenerator(repo_id="test_repo")
            ir_doc = generator.generate(source, "test", ast)
            ir_docs.append(ir_doc)

        # Cross-file resolution
        resolver = CrossFileResolver()
        global_ctx = resolver.resolve(ir_docs)

        # ê²€ì¦ 1: ëª¨ë“  íŒŒì¼ì˜ ì‹¬ë³¼ì´ ë“±ë¡ë˜ì—ˆëŠ”ê°€?
        print(f"âœ“ Total symbols: {global_ctx.total_symbols}")
        assert global_ctx.total_symbols > 0, "No symbols registered!"

        # ê° íŒŒì¼ì˜ ë…¸ë“œ ìˆ˜ í™•ì¸
        for ir_doc in ir_docs:
            if ir_doc.nodes:
                print(f"  - {ir_doc.nodes[0].file_path}: {len(ir_doc.nodes)} nodes")

        expected_min_symbols = sum(len(doc.nodes) for doc in ir_docs)
        print(f"  - Expected minimum: {expected_min_symbols}")

        # ê²€ì¦ 2: íŠ¹ì • ì‹¬ë³¼ì„ ì°¾ì„ ìˆ˜ ìˆëŠ”ê°€?
        # User í´ë˜ìŠ¤ ì°¾ê¸°
        user_symbols = [
            (fqn, node)
            for fqn, (node, _) in global_ctx.symbol_table.items()
            if "User" in fqn and node.kind.value == "Class"
        ]

        if user_symbols:
            print(f"âœ“ Found User symbols: {len(user_symbols)}")
            for fqn, node in user_symbols[:3]:
                print(f"  - {fqn}")
        else:
            print("âš  User class not found in global symbol table")

        # ê²€ì¦ 3: Import ê´€ê³„ê°€ íŒŒì•…ë˜ì—ˆëŠ”ê°€?
        # service.pyëŠ” models.pyë¥¼ import
        service_file = str(test_proj / "src" / "service.py")
        models_file = str(test_proj / "src" / "models.py")

        service_deps = global_ctx.get_dependencies(service_file)
        print(f"âœ“ service.py dependencies: {len(service_deps)}")
        if service_deps:
            print(f"  - {service_deps}")

        # ê²€ì¦ 4: Statsê°€ í•©ë¦¬ì ì¸ê°€?
        stats = global_ctx.get_stats()
        print(f"âœ“ Global context stats:")
        for key, value in stats.items():
            print(f"  - {key}: {value}")

        return True


async def critical_test_4_performance():
    """ë¹„íŒì  ê²€ì¦ 4: ì„±ëŠ¥"""
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ 4: ì„±ëŠ¥")
    print("=" * 60)

    with tempfile.TemporaryDirectory() as tmpdir:
        test_proj = create_real_project(Path(tmpdir))

        from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
        from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile
        from src.contexts.code_foundation.infrastructure.ir.occurrence_generator import OccurrenceGenerator
        from src.contexts.code_foundation.infrastructure.ir.cross_file_resolver import CrossFileResolver
        from src.contexts.code_foundation.infrastructure.ir.retrieval_index import RetrievalOptimizedIndex

        # íƒ€ì´ë° ì¸¡ì •
        timings = {}

        # 1. IR Generation
        start = time.perf_counter()
        ir_docs = []
        for file_path in [
            test_proj / "src" / "models.py",
            test_proj / "src" / "service.py",
            test_proj / "src" / "main.py",
        ]:
            content = file_path.read_text()
            source = SourceFile.from_content(str(file_path), content, "python")
            ast = AstTree.parse(source)
            generator = PythonIRGenerator(repo_id="test_repo")
            ir_doc = generator.generate(source, "test", ast)
            ir_docs.append(ir_doc)
        timings["ir_generation"] = (time.perf_counter() - start) * 1000

        # 2. Occurrence Generation
        start = time.perf_counter()
        occ_gen = OccurrenceGenerator()
        for ir_doc in ir_docs:
            occ_gen.generate(ir_doc)
        timings["occurrence_generation"] = (time.perf_counter() - start) * 1000

        # 3. Cross-file Resolution
        start = time.perf_counter()
        resolver = CrossFileResolver()
        global_ctx = resolver.resolve(ir_docs)
        timings["cross_file_resolution"] = (time.perf_counter() - start) * 1000

        # 4. Index Building
        start = time.perf_counter()
        index = RetrievalOptimizedIndex()
        for ir_doc in ir_docs:
            index.index_ir_document(ir_doc)
        timings["index_building"] = (time.perf_counter() - start) * 1000

        # 5. Search Query
        start = time.perf_counter()
        results = index.search_symbol("User", fuzzy=True, limit=10)
        timings["fuzzy_search"] = (time.perf_counter() - start) * 1000

        # ê²°ê³¼
        total_time = sum(timings.values())
        print(f"âœ“ Performance Results (3 files):")
        for operation, time_ms in timings.items():
            pct = (time_ms / total_time) * 100 if total_time > 0 else 0
            status = "âœ“" if time_ms < 100 else "âš "
            print(f"  {status} {operation:25s}: {time_ms:7.2f}ms ({pct:5.1f}%)")
        print(f"  âœ“ Total: {total_time:.2f}ms")

        # ì„±ëŠ¥ ëª©í‘œ ê²€ì¦
        assert timings["ir_generation"] < 1000, f"IR generation too slow: {timings['ir_generation']:.2f}ms"
        assert timings["fuzzy_search"] < 100, f"Fuzzy search too slow: {timings['fuzzy_search']:.2f}ms"

        return True


async def critical_test_5_real_usage():
    """ë¹„íŒì  ê²€ì¦ 5: ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤"""
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ 5: ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤")
    print("=" * 60)

    with tempfile.TemporaryDirectory() as tmpdir:
        test_proj = create_real_project(Path(tmpdir))

        from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
        from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile
        from src.contexts.code_foundation.infrastructure.ir.occurrence_generator import OccurrenceGenerator
        from src.contexts.code_foundation.infrastructure.ir.retrieval_index import RetrievalOptimizedIndex

        # ì „ì²´ íŒŒì´í”„ë¼ì¸
        ir_docs = []
        for file_path in [test_proj / "src" / "models.py", test_proj / "src" / "service.py"]:
            content = file_path.read_text()
            source = SourceFile.from_content(str(file_path), content, "python")
            ast = AstTree.parse(source)
            generator = PythonIRGenerator(repo_id="test_repo")
            ir_doc = generator.generate(source, "test", ast)

            # Occurrences
            occ_gen = OccurrenceGenerator()
            occurrences, occ_index = occ_gen.generate(ir_doc)
            ir_doc.occurrences = occurrences

            ir_docs.append(ir_doc)

        # Index
        index = RetrievalOptimizedIndex()
        for ir_doc in ir_docs:
            index.index_ir_document(ir_doc)

        # ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ 1: "User í´ë˜ìŠ¤ ì°¾ê¸°"
        print("\nì‹œë‚˜ë¦¬ì˜¤ 1: User í´ë˜ìŠ¤ ì°¾ê¸°")
        results = index.search_symbol("User", fuzzy=False, limit=5)
        print(f"  âœ“ Found {len(results)} results")
        if results:
            node, score = results[0]
            print(f"  âœ“ Best match: {node.name} (score: {score:.2f})")
            print(f"  âœ“ FQN: {node.fqn}")
            print(f"  âœ“ Location: {node.file_path}:{node.span.start_line}")

        # ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ 2: "create_user ë©”ì†Œë“œ ì°¾ê¸°"
        print("\nì‹œë‚˜ë¦¬ì˜¤ 2: create_user ë©”ì†Œë“œ ì°¾ê¸°")
        results = index.search_symbol("create_user", fuzzy=False, limit=5)
        print(f"  âœ“ Found {len(results)} results")
        if results:
            node, score = results[0]
            print(f"  âœ“ Best match: {node.name} (score: {score:.2f})")

        # ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ 3: "Fuzzy search: 'usr'"
        print("\nì‹œë‚˜ë¦¬ì˜¤ 3: Fuzzy search 'usr'")
        results = index.search_symbol("usr", fuzzy=True, limit=5)
        print(f"  âœ“ Found {len(results)} results")
        for i, (node, score) in enumerate(results[:3], 1):
            print(f"    {i}. {node.name} (score: {score:.2f})")

        # ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ 4: "íŒŒì¼ì˜ ëª¨ë“  ì •ì˜ ê°€ì ¸ì˜¤ê¸°"
        print("\nì‹œë‚˜ë¦¬ì˜¤ 4: models.pyì˜ ëª¨ë“  ì •ì˜")
        models_ir = ir_docs[0]
        definitions = [o for o in models_ir.occurrences if o.is_definition()]
        print(f"  âœ“ Found {len(definitions)} definitions")
        for i, occ in enumerate(definitions[:5], 1):
            symbol_name = occ.symbol_id.split("::")[-1] if "::" in occ.symbol_id else occ.symbol_id
            print(f"    {i}. {symbol_name} @ line {occ.span.start_line}")

        return True


async def main():
    """ëª¨ë“  ë¹„íŒì  ê²€ì¦ ì‹¤í–‰"""
    print("\n" + "ğŸ”" + "=" * 58 + "ğŸ”")
    print("   SOTA IR ë¹„íŒì  ê²€ì¦")
    print("ğŸ”" + "=" * 58 + "ğŸ”")

    tests = [
        ("ë°ì´í„° í’ˆì§ˆ", critical_test_1_data_quality),
        ("Occurrence ì •í™•ë„", critical_test_2_occurrence_accuracy),
        ("Cross-file ì •í™•ë„", critical_test_3_cross_file_accuracy),
        ("ì„±ëŠ¥", critical_test_4_performance),
        ("ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤", critical_test_5_real_usage),
    ]

    results = []

    for test_name, test_func in tests:
        try:
            await test_func()
            results.append((test_name, True, None))
        except Exception as e:
            results.append((test_name, False, str(e)))
            print(f"âŒ FAILED: {e}")
            import traceback

            traceback.print_exc()

    # Summary
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ ê²°ê³¼")
    print("=" * 60)

    for test_name, passed, error in results:
        if passed:
            print(f"âœ… {test_name:25s}: PASSED")
        else:
            print(f"âŒ {test_name:25s}: FAILED - {error}")

    print("=" * 60)

    passed_count = sum(1 for _, passed, _ in results if passed)
    total_count = len(results)

    if passed_count == total_count:
        print(f"\nğŸ‰ ëª¨ë“  {total_count}ê°œ ê²€ì¦ í†µê³¼!")
        print("\nâœ… SOTA IRì´ ì‹¤ì œë¡œ ì œëŒ€ë¡œ ë™ì‘í•©ë‹ˆë‹¤!")
        print("âœ… ë°ì´í„° í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤!")
        print("âœ… ì„±ëŠ¥ì´ ì–‘í˜¸í•©ë‹ˆë‹¤!")
        print("âœ… ì‹¤ì œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤!")
        return 0
    else:
        print(f"\nâŒ {total_count - passed_count}/{total_count} ê²€ì¦ ì‹¤íŒ¨")
        return 1


if __name__ == "__main__":
    import sys

    sys.exit(asyncio.run(main()))
