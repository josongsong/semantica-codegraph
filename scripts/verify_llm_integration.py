#!/usr/bin/env python3
"""
LLM Integration ê²€ì¦

OpenAIë¡œ ì‹¤ì œ ì „ëµ ìƒì„±
"""

import asyncio
import sys

sys.path.insert(0, ".")

from src.agent.adapters.llm.strategy_generator import (
    StrategyGeneratorLLM,
    StrategyGeneratorFactory,
)
from src.agent.domain.reasoning import StrategyType
from src.container import Container


async def test_strategy_generator():
    """Strategy Generator í…ŒìŠ¤íŠ¸"""
    print("=" * 80)
    print("LLM Integration: Strategy Generator")
    print("=" * 80)

    # Generator ìƒì„±
    generator = StrategyGeneratorFactory.create(use_llm=True)

    print(f"\nâœ… Generator created")
    print(f"   Model: {generator.model}")
    print(f"   Has API Key: {bool(generator.api_key)}")
    print(f"   Has Client: {bool(generator.client)}")

    # ì „ëµ ìƒì„±
    problem = "Fix NullPointerException in UserService.login() method"
    context = {
        "code": """
def login(user):
    return user.name.upper()
""",
        "files": ["src/user/service.py"],
    }

    print(f"\nğŸ“ Problem: {problem}")
    print(f"   Code: {context['code'][:50]}...")

    # Direct Fix Strategy
    print(f"\nğŸ¤– Generating strategy (direct_fix)...")

    strategy = await generator.generate_strategy(
        problem=problem,
        context=context,
        strategy_type=StrategyType.DIRECT_FIX,
        index=0,
    )

    print(f"\nâœ… Strategy generated:")
    print(f"   ID: {strategy.strategy_id}")
    print(f"   Type: {strategy.strategy_type.value}")
    print(f"   Title: {strategy.title}")
    print(f"   Description: {strategy.description[:80]}...")
    print(f"   Rationale: {strategy.rationale[:80]}...")
    print(f"   Confidence: {strategy.llm_confidence:.2f}")

    assert len(strategy.title) > 0, "Should have title"
    assert strategy.llm_confidence > 0, "Should have confidence"
    print("\nâœ… PASS")


async def test_tot_with_llm():
    """ToT + LLM í†µí•© í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 80)
    print("ToT + LLM Integration")
    print("=" * 80)

    container = Container()
    use_case = container.v8_execute_tot

    print(f"\nâœ… ExecuteToT UseCase from Container")

    # LLMìœ¼ë¡œ ì „ëµ ìƒì„±
    result = await use_case.execute(
        problem="Add null check to prevent NullPointerException",
        context={
            "code": "def process(user): return user.name",
            "files": ["service.py"],
        },
        strategy_count=2,  # 2ê°œë§Œ (ë¹ ë¥´ê²Œ)
        top_k=1,
    )

    print(f"\nğŸ“Š ToT Results (with LLM):")
    print(f"  Generated: {result.total_generated}")
    print(f"  Executed: {result.total_executed}")
    print(f"  Best Score: {result.best_score:.2f}")
    print(f"  Time: {result.total_time:.2f}s")

    # Best Strategy
    if result.best_strategy_id:
        strategy = next((s for s in result.all_strategies if s.strategy_id == result.best_strategy_id), None)

        if strategy:
            print(f"\nğŸ† Best Strategy (LLM-generated):")
            print(f"  Title: {strategy.title}")
            print(f"  Type: {strategy.strategy_type.value}")
            print(f"  Confidence: {strategy.llm_confidence:.2f}")

    assert result.total_executed >= 1, "Should execute"
    print("\nâœ… PASS")


async def test_fallback_mode():
    """Fallback ëª¨ë“œ í…ŒìŠ¤íŠ¸ (API Key ì—†ì´)"""
    print("\n" + "=" * 80)
    print("Fallback Mode (No API Key)")
    print("=" * 80)

    # No API Key
    generator = StrategyGeneratorLLM(api_key=None)

    print(f"\nâœ… Generator (Fallback mode)")
    print(f"   Has Client: {bool(generator.client)}")

    strategy = await generator.generate_strategy(
        problem="Test problem",
        context={},
        strategy_type=StrategyType.TEST_DRIVEN,
        index=0,
    )

    print(f"\nâœ… Fallback strategy:")
    print(f"   ID: {strategy.strategy_id}")
    print(f"   Type: {strategy.strategy_type.value}")

    assert "fallback" in strategy.strategy_id, "Should use fallback"
    print("\nâœ… PASS (Fallback works)")


async def main():
    """Main"""
    try:
        await test_strategy_generator()
        await test_tot_with_llm()
        await test_fallback_mode()

        print("\n" + "=" * 80)
        print("ğŸ‰ LLM Integration ê²€ì¦ ì™„ë£Œ!")
        print("=" * 80)
        print("\nì„±ê³µ:")
        print("  âœ… Strategy Generator (OpenAI)")
        print("  âœ… LLMìœ¼ë¡œ ì „ëµ ìƒì„±")
        print("  âœ… ToT Executor í†µí•©")
        print("  âœ… Fallback ëª¨ë“œ")
        print("\nLLM í™œìš©:")
        print("  ğŸ¤– ë¬¸ì œ ë¶„ì„ â†’ ì „ëµ ìƒì„±")
        print("  ğŸ¤– Context ê¸°ë°˜ ë§ì¶¤í˜•")
        print("  ğŸ¤– Confidence ì ìˆ˜")
        print("\nì „ì²´ íŒŒì´í”„ë¼ì¸:")
        print("  User Problem")
        print("    â†“")
        print("  Router â†’ System 1/2")
        print("    â†“")
        print("  LLM â†’ 3-5 Strategies")
        print("    â†“")
        print("  Sandbox â†’ Execute")
        print("    â†“")
        print("  Scorer â†’ Multi-Criteria")
        print("    â†“")
        print("  Reflection â†’ ACCEPT/REVISE")
        print("    â†“")
        print("  Experience â†’ Save")
        print("\nğŸ”¥ v8.1 COMPLETE!")

        return 0

    except Exception as e:
        print(f"\nâŒ ê²€ì¦ ì‹¤íŒ¨: {e}")
        import traceback

        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(asyncio.run(main()))
