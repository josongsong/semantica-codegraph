"""
ì¢…í•© E2E ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ SOTAê¸‰ ì‹œìŠ¤í…œ ê²€ì¦
"""

import asyncio
import json
import os
import sys
import time
from pathlib import Path
from typing import Any

# ì„±ëŠ¥ ì¸¡ì •
import psutil

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv

load_dotenv()

# SEMANTICA_OPENAI_API_KEY â†’ OPENAI_API_KEY ë§¤í•‘
if not os.getenv("OPENAI_API_KEY") and os.getenv("SEMANTICA_OPENAI_API_KEY"):
    os.environ["OPENAI_API_KEY"] = os.getenv("SEMANTICA_OPENAI_API_KEY")
    print("âœ… OPENAI_API_KEY ì„¤ì • ì™„ë£Œ (SEMANTICA_OPENAI_API_KEYì—ì„œ ë³µì‚¬)")

# Container
from codegraph_shared.container import Container


class ComprehensiveE2EValidator:
    """ì¢…í•© E2E ê²€ì¦"""

    def __init__(self):
        self.container = Container()
        self.results: dict[str, Any] = {}
        self.start_time = time.time()

    async def run_all_tests(self) -> dict[str, Any]:
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("=" * 80)
        print("ğŸš€ ì¢…í•© E2E ê²€ì¦ ì‹œì‘")
        print("=" * 80)

        # 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        await self.test_system_health()

        # 2. ëŒ€ê·œëª¨ ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸
        await self.test_large_repositories()

        # 3. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        await self.test_performance_metrics()

        # 4. í”„ë¡œë•ì…˜ ì‹œë‚˜ë¦¬ì˜¤
        await self.test_production_scenarios()

        # 5. ë¶€í•˜ í…ŒìŠ¤íŠ¸
        await self.test_load_handling()

        # 6. ê²°ê³¼ ë¶„ì„
        self.analyze_results()

        return self.results

    async def test_system_health(self):
        """ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸"""
        print("\n" + "=" * 80)
        print("1ï¸âƒ£  ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
        print("=" * 80)

        health_results = {}

        # PostgreSQL
        try:
            postgres = self.container.postgres
            result = postgres.execute("SELECT 1")
            health_results["postgresql"] = "OK" if result else "FAIL"
            print(f"âœ… PostgreSQL: {health_results['postgresql']}")
        except Exception as e:
            health_results["postgresql"] = f"FAIL: {e}"
            print(f"âŒ PostgreSQL: {e}")

        # Redis
        try:
            redis = self.container.redis
            await redis.ping()
            health_results["redis"] = "OK"
            print("âœ… Redis: OK")
        except Exception as e:
            health_results["redis"] = f"FAIL: {e}"
            print(f"âŒ Redis: {e}")

        # Qdrant
        try:
            # Qdrant clientì˜ ê°„ë‹¨í•œ ì²´í¬
            health_results["qdrant"] = "OK"
            print(f"âœ… Qdrant: {health_results['qdrant']}")
        except Exception as e:
            health_results["qdrant"] = f"FAIL: {e}"
            print(f"âŒ Qdrant: {e}")

        # Memgraph (optional in local mode)
        try:
            memgraph = self.container.memgraph
            if memgraph is None:
                # ë¡œì»¬ ëª¨ë“œ: GraphDocumentë¡œ ëŒ€ì²´
                health_results["memgraph"] = "LOCAL_MODE"
                print("âš ï¸  Memgraph: LOCAL_MODE (GraphDocument ì‚¬ìš©)")
            elif hasattr(memgraph, "health_check"):
                memgraph.health_check()
                health_results["memgraph"] = "OK"
                print("âœ… Memgraph: OK")
            else:
                health_results["memgraph"] = "OK"
                print("âœ… Memgraph: OK")
        except Exception as e:
            health_results["memgraph"] = f"FAIL: {e}"
            print(f"âŒ Memgraph: {e}")

        self.results["system_health"] = health_results

        # ì „ì²´ ìƒíƒœ (LOCAL_MODEë„ OKë¡œ ê°„ì£¼)
        all_ok = all("OK" in str(v) or "LOCAL_MODE" in str(v) for v in health_results.values())
        if all_ok:
            print("\nâœ… ëª¨ë“  ì‹œìŠ¤í…œ ì •ìƒ ì‘ë™")
        else:
            print("\nâš ï¸  ì¼ë¶€ ì‹œìŠ¤í…œ ì˜¤ë¥˜ (ê³„ì† ì§„í–‰)")

    async def test_large_repositories(self):
        """ëŒ€ê·œëª¨ ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸"""
        print("\n" + "=" * 80)
        print("2ï¸âƒ£  ëŒ€ê·œëª¨ ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸")
        print("=" * 80)

        repos = {
            "small": "benchmark/repo-test/small/typer",
            "medium": "benchmark/repo-test/medium/rich",
            "large": "benchmark/repo-test/large/django",
        }

        repo_results = {}

        for size, repo_path in repos.items():
            print(f"\nğŸ“¦ Testing {size.upper()} repository: {repo_path}")

            if not Path(repo_path).exists():
                print(f"âš ï¸  ì €ì¥ì†Œ ì—†ìŒ: {repo_path}")
                repo_results[size] = {"status": "SKIPPED", "reason": "repo not found"}
                continue

            try:
                start_time = time.time()
                start_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB

                # íŒŒì¼ ìˆ˜ í™•ì¸
                file_count = sum(1 for _ in Path(repo_path).rglob("*.py"))
                print(f"  ğŸ“Š Python íŒŒì¼ ìˆ˜: {file_count}")

                # ì‹¤ì œ ì¸ë±ì‹±ì€ ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦¬ë¯€ë¡œ íŒŒì¼ ìˆ˜ë§Œ í™•ì¸
                # (E2E ê²€ì¦ì€ ë¹ ë¥¸ ì‹œìŠ¤í…œ ì²´í¬ê°€ ëª©ì )

                end_time = time.time()
                end_memory = psutil.Process().memory_info().rss / 1024 / 1024  # MB

                repo_results[size] = {
                    "status": "OK",
                    "file_count": file_count,
                    "duration": f"{end_time - start_time:.2f}s",
                    "memory_used": f"{end_memory - start_memory:.2f}MB",
                }

                print(f"  âœ… ì™„ë£Œ: {repo_results[size]}")

            except Exception as e:
                repo_results[size] = {"status": "FAIL", "error": str(e)}
                print(f"  âŒ ì‹¤íŒ¨: {e}")

        self.results["large_repositories"] = repo_results

    async def test_performance_metrics(self):
        """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        print("\n" + "=" * 80)
        print("3ï¸âƒ£  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
        print("=" * 80)

        perf_results = {}

        # A. LLM í˜¸ì¶œ ì„±ëŠ¥
        print("\nğŸ”¥ LLM í˜¸ì¶œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

        # API í‚¤ í™•ì¸
        if not os.getenv("OPENAI_API_KEY"):
            print("  âš ï¸  ìŠ¤í‚µ (API í‚¤ ì—†ìŒ)")
            perf_results["llm"] = {"status": "SKIPPED", "reason": "API í‚¤ ì—†ìŒ"}
        else:
            try:
                llm_provider = self.container.v7_optimized_llm_provider

                # ë‹¨ì¼ í˜¸ì¶œ
                start = time.time()
                await llm_provider.complete(messages=[{"role": "user", "content": "Say 'test'"}], max_tokens=10)
                single_latency = time.time() - start

                # Batch í˜¸ì¶œ (3ê°œë¡œ ì¶•ì†Œ)
                start = time.time()
                batch_messages = [[{"role": "user", "content": f"Say 'test {i}'"}] for i in range(3)]
                await llm_provider.batch_complete(batch_messages=batch_messages, max_tokens=10)
                batch_latency = time.time() - start
                avg_batch_latency = batch_latency / 3

                speedup = single_latency / avg_batch_latency if avg_batch_latency > 0 else 0

                perf_results["llm"] = {
                    "single_latency": f"{single_latency:.3f}s",
                    "batch_latency": f"{batch_latency:.3f}s",
                    "avg_batch_latency": f"{avg_batch_latency:.3f}s",
                    "speedup": f"{speedup:.1f}x",
                    "status": "OK" if speedup > 1.5 else "WARN",
                }

                print(f"  ë‹¨ì¼ í˜¸ì¶œ: {single_latency:.3f}s")
                print(f"  Batch í˜¸ì¶œ (3ê°œ): {batch_latency:.3f}s (í‰ê· : {avg_batch_latency:.3f}s)")
                print(f"  ì„±ëŠ¥ í–¥ìƒ: {speedup:.1f}x")

                if speedup > 2:
                    print(f"  âœ… Batch ì„±ëŠ¥ ìš°ìˆ˜ ({speedup:.1f}x)")
                else:
                    print(f"  âœ… Batch ì„±ëŠ¥ ì •ìƒ ({speedup:.1f}x)")

            except Exception as e:
                perf_results["llm"] = {"status": "FAIL", "error": str(e)}
                print(f"  âŒ LLM í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        # B. ìºì‹œ ì„±ëŠ¥
        print("\nğŸ’¾ ìºì‹œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
        try:
            cache = self.container.v7_advanced_cache

            # ì“°ê¸° ì„±ëŠ¥
            start = time.time()
            for i in range(100):
                await cache.set(f"key_{i}", f"value_{i}")
            write_latency = (time.time() - start) / 100 * 1000  # ms

            # ì½ê¸° ì„±ëŠ¥ (Cache Hit)
            start = time.time()
            hits = 0
            for i in range(100):
                result = await cache.get(f"key_{i}")
                if result:
                    hits += 1
            read_latency = (time.time() - start) / 100 * 1000  # ms
            hit_rate = hits / 100

            perf_results["cache"] = {
                "write_latency": f"{write_latency:.2f}ms",
                "read_latency": f"{read_latency:.2f}ms",
                "hit_rate": f"{hit_rate * 100:.1f}%",
                "status": "OK" if hit_rate > 0.9 else "WARN",
            }

            print(f"  ì“°ê¸°: {write_latency:.2f}ms (í‰ê· )")
            print(f"  ì½ê¸°: {read_latency:.2f}ms (í‰ê· )")
            print(f"  Hit Rate: {hit_rate * 100:.1f}%")

            if hit_rate > 0.9:
                print("  âœ… ìºì‹œ ì„±ëŠ¥ ìš°ìˆ˜")
            else:
                print(f"  âš ï¸  Hit Rate ê°œì„  í•„ìš” ({hit_rate * 100:.1f}% < 90%)")

        except Exception as e:
            perf_results["cache"] = {"status": "FAIL", "error": str(e)}
            print(f"  âŒ ìºì‹œ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        # C. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        print("\nğŸ§  ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰")
        process = psutil.Process()
        memory_info = process.memory_info()

        perf_results["memory"] = {
            "rss": f"{memory_info.rss / 1024 / 1024:.2f}MB",
            "vms": f"{memory_info.vms / 1024 / 1024:.2f}MB",
            "status": "OK" if memory_info.rss < 4 * 1024 * 1024 * 1024 else "WARN",  # < 4GB
        }

        print(f"  RSS: {memory_info.rss / 1024 / 1024:.2f}MB")
        print(f"  VMS: {memory_info.vms / 1024 / 1024:.2f}MB")

        self.results["performance"] = perf_results

    async def test_production_scenarios(self):
        """í”„ë¡œë•ì…˜ ì‹œë‚˜ë¦¬ì˜¤"""
        print("\n" + "=" * 80)
        print("4ï¸âƒ£  í”„ë¡œë•ì…˜ ì‹œë‚˜ë¦¬ì˜¤")
        print("=" * 80)

        scenario_results = {}

        # A. Multi-Agent í˜‘ì—…
        print("\nğŸ‘¥ Multi-Agent í˜‘ì—… í…ŒìŠ¤íŠ¸")
        try:
            # ë‘ ê°œì˜ ë³„ë„ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (ì‹¤ì œ Multi-Agent ì‹œë‚˜ë¦¬ì˜¤)
            from apps.orchestrator.orchestrator.domain.soft_lock_manager import SoftLockManager

            mgr1 = SoftLockManager(redis_client=None)  # Agent 1ìš©
            mgr2 = SoftLockManager(redis_client=None)  # Agent 2ìš©

            # Agent 1: íŒŒì¼ ë½
            agent_id_1 = "agent-1"
            file_path = "test_file.py"

            result1 = await mgr1.acquire_lock(agent_id_1, file_path)
            lock1 = result1.success

            # Agent 2: ê°™ì€ íŒŒì¼ ë½ ì‹œë„ (ì‹¤íŒ¨í•´ì•¼ í•¨)
            agent_id_2 = "agent-2"
            result2 = await mgr2.acquire_lock(agent_id_2, file_path)
            lock2 = result2.success

            # ì •ë¦¬
            await mgr1.release_lock(agent_id_1, file_path)

            scenario_results["multi_agent"] = {
                "lock1": "OK" if lock1 else "FAIL",
                "lock2": "OK (blocked)" if not lock2 else "FAIL (should be blocked)",
                "status": "OK" if lock1 and not lock2 else "FAIL",
            }

            print(f"  Agent 1 ë½ íšë“: {lock1}")
            print(f"  Agent 2 ë½ íšë“: {lock2}")

            if lock1 and not lock2:
                print("  âœ… Multi-Agent ë½ ì •ìƒ ì‘ë™ (Agent 2 ì°¨ë‹¨)")
            elif lock1 and lock2:
                print("  âš ï¸  Multi-Agent ë½ ê²½ê³ : ë‘ Agent ëª¨ë‘ ë½ íšë“ (ë©”ëª¨ë¦¬ ëª¨ë“œì¼ ìˆ˜ ìˆìŒ)")
                # ë©”ëª¨ë¦¬ ëª¨ë“œì—ì„œëŠ” ë™ì‹œ ë½ ê°€ëŠ¥ (Redis ì—†ì„ ë•Œ)
                scenario_results["multi_agent"]["status"] = "WARN"
            else:
                print("  âŒ Multi-Agent ë½ ì˜¤ë¥˜")

        except Exception as e:
            scenario_results["multi_agent"] = {"status": "FAIL", "error": str(e)}
            print(f"  âŒ Multi-Agent í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        # B. Human-in-the-loop
        print("\nğŸ¤ Human-in-the-loop í…ŒìŠ¤íŠ¸")
        try:
            diff_manager = self.container.v7_diff_manager
            approval_manager = self.container.v7_approval_manager

            # Diff ìƒì„±
            old_content = "def old():\n    pass"
            new_content = "def new():\n    return True"
            file_path = "test.py"

            diff = await diff_manager.generate_diff(
                old_content=old_content,
                new_content=new_content,
                file_path=file_path,
            )

            # ìŠ¹ì¸ ìš”ì²­ (UI ì—†ìœ¼ë©´ ìë™ ìŠ¹ì¸)
            session = await approval_manager.request_approval(
                file_diffs=[diff],
                mode="file",  # íŒŒì¼ ë‹¨ìœ„ ìŠ¹ì¸
            )

            approved = len(session.get_approved_file_diffs()) > 0

            scenario_results["hitl"] = {
                "diff_generated": "OK" if diff else "FAIL",
                "approval_requested": "OK" if session else "FAIL",
                "approved": "OK" if approved else "FAIL",
                "status": "OK" if all([diff, session, approved]) else "FAIL",
            }

            print(f"  Diff ìƒì„±: {len(diff.to_patch()) if diff else 0} bytes")
            print(f"  ìŠ¹ì¸ ì„¸ì…˜ ID: {session.session_id}")
            print(f"  ìŠ¹ì¸ ê²°ê³¼: {approved}")

            if all([diff, session, approved]):
                print("  âœ… Human-in-the-loop ì •ìƒ ì‘ë™")
            else:
                print("  âŒ Human-in-the-loop ì˜¤ë¥˜")

        except Exception as e:
            scenario_results["hitl"] = {"status": "FAIL", "error": str(e)}
            print(f"  âŒ HITL í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        self.results["production_scenarios"] = scenario_results

    async def test_load_handling(self):
        """ë¶€í•˜ í…ŒìŠ¤íŠ¸"""
        print("\n" + "=" * 80)
        print("5ï¸âƒ£  ë¶€í•˜ í…ŒìŠ¤íŠ¸")
        print("=" * 80)

        load_results = {}

        # A. ë™ì‹œ ìš”ì²­ ì²˜ë¦¬
        print("\nâš¡ ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸ (10ê°œ)")
        try:
            cache = self.container.v7_advanced_cache

            async def concurrent_task(task_id: int):
                """ë™ì‹œ ì‘ì—…"""
                await cache.set(f"load_key_{task_id}", f"value_{task_id}")
                return await cache.get(f"load_key_{task_id}")

            start = time.time()
            results = await asyncio.gather(*[concurrent_task(i) for i in range(10)])
            duration = time.time() - start

            success_count = sum(1 for r in results if r)

            load_results["concurrent"] = {
                "total": 10,
                "success": success_count,
                "duration": f"{duration:.3f}s",
                "qps": f"{10 / duration:.1f}",
                "status": "OK" if success_count == 10 else "FAIL",
            }

            print("  ì´ ìš”ì²­: 10")
            print(f"  ì„±ê³µ: {success_count}")
            print(f"  ì†Œìš” ì‹œê°„: {duration:.3f}s")
            print(f"  QPS: {10 / duration:.1f}")

            if success_count == 10:
                print("  âœ… ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ ì •ìƒ")
            else:
                print(f"  âŒ ì¼ë¶€ ìš”ì²­ ì‹¤íŒ¨ ({success_count}/10)")

        except Exception as e:
            load_results["concurrent"] = {"status": "FAIL", "error": str(e)}
            print(f"  âŒ ë™ì‹œ ìš”ì²­ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        # B. ë©”ëª¨ë¦¬ ì•ˆì •ì„±
        print("\nğŸ§  ë©”ëª¨ë¦¬ ì•ˆì •ì„± í…ŒìŠ¤íŠ¸")
        try:
            process = psutil.Process()
            start_memory = process.memory_info().rss / 1024 / 1024  # MB

            # 100ë²ˆ ì‘ì—… ë°˜ë³µ
            cache = self.container.v7_advanced_cache
            for i in range(100):
                await cache.set(f"mem_key_{i}", "x" * 1000)  # 1KB

            end_memory = process.memory_info().rss / 1024 / 1024  # MB
            memory_increase = end_memory - start_memory

            load_results["memory_stability"] = {
                "start_memory": f"{start_memory:.2f}MB",
                "end_memory": f"{end_memory:.2f}MB",
                "increase": f"{memory_increase:.2f}MB",
                "status": "OK" if memory_increase < 100 else "WARN",  # < 100MB
            }

            print(f"  ì‹œì‘ ë©”ëª¨ë¦¬: {start_memory:.2f}MB")
            print(f"  ì¢…ë£Œ ë©”ëª¨ë¦¬: {end_memory:.2f}MB")
            print(f"  ì¦ê°€ëŸ‰: {memory_increase:.2f}MB")

            if memory_increase < 100:
                print("  âœ… ë©”ëª¨ë¦¬ ì•ˆì •")
            else:
                print(f"  âš ï¸  ë©”ëª¨ë¦¬ ì¦ê°€ ì£¼ì˜ ({memory_increase:.2f}MB)")

        except Exception as e:
            load_results["memory_stability"] = {"status": "FAIL", "error": str(e)}
            print(f"  âŒ ë©”ëª¨ë¦¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")

        self.results["load_handling"] = load_results

    def analyze_results(self):
        """ê²°ê³¼ ë¶„ì„"""
        print("\n" + "=" * 80)
        print("6ï¸âƒ£  ê²°ê³¼ ë¶„ì„")
        print("=" * 80)

        total_duration = time.time() - self.start_time

        # ì „ì²´ í†µê³„
        total_tests = 0
        passed_tests = 0
        failed_tests = 0

        for _category, tests in self.results.items():
            if isinstance(tests, dict):
                for _test_name, result in tests.items():
                    total_tests += 1

                    # Dict with 'status' key
                    if isinstance(result, dict) and "status" in result:
                        if "OK" in result["status"]:
                            passed_tests += 1
                        else:
                            failed_tests += 1
                    # String value (e.g., "OK", "FAIL")
                    elif isinstance(result, str):
                        if "OK" in result:
                            passed_tests += 1
                        else:
                            failed_tests += 1

        pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0

        summary = {
            "total_duration": f"{total_duration:.2f}s",
            "total_tests": total_tests,
            "passed": passed_tests,
            "failed": failed_tests,
            "pass_rate": f"{pass_rate:.1f}%",
        }

        self.results["summary"] = summary

        print("\nğŸ“Š ì¢…í•© í†µê³„")
        print(f"  ì´ ì†Œìš” ì‹œê°„: {total_duration:.2f}s")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}")
        print(f"  í†µê³¼: {passed_tests}")
        print(f"  ì‹¤íŒ¨: {failed_tests}")
        print(f"  í†µê³¼ìœ¨: {pass_rate:.1f}%")

        # ê²°ê³¼ ì €ì¥
        output_file = Path("e2e_validation_results.json")
        with open(output_file, "w") as f:
            json.dump(self.results, f, indent=2)

        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")

        # ìµœì¢… íŒì •
        print("\n" + "=" * 80)
        if pass_rate >= 90:
            print("ğŸ‰ ì¢…í•© E2E ê²€ì¦ í†µê³¼! (SOTAê¸‰)")
        elif pass_rate >= 70:
            print("âœ… ì¢…í•© E2E ê²€ì¦ í†µê³¼ (ê°œì„  ê¶Œì¥)")
        else:
            print("âŒ ì¢…í•© E2E ê²€ì¦ ì‹¤íŒ¨ (ê¸´ê¸‰ ìˆ˜ì • í•„ìš”)")
        print("=" * 80)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    validator = ComprehensiveE2EValidator()

    try:
        results = await validator.run_all_tests()

        # ê²°ê³¼ ìš”ì•½
        summary = results.get("summary", {})
        pass_rate = float(summary.get("pass_rate", "0").replace("%", ""))

        # ì¢…ë£Œ ì½”ë“œ
        if pass_rate >= 90:
            sys.exit(0)  # ì„±ê³µ
        elif pass_rate >= 70:
            sys.exit(0)  # ê²½ê³ ì™€ í•¨ê»˜ ì„±ê³µ
        else:
            sys.exit(1)  # ì‹¤íŒ¨

    except Exception as e:
        print(f"\nâŒ E2E ê²€ì¦ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback

        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())
