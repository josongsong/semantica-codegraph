RepoMap Layer 실행 계획서

Execution Plan v1.2 (Final)

1. 요약 (High-level Summary)

1-1. 역할 요약

RepoMap Layer는 **Chunk/Graph 위에 프로젝트 지도(Project Map)**를 구축하는 상위 표현 계층임

목표:

디렉토리 → 모듈 → 파일 → 심볼 → 청크 의 LLM-friendly 트리 생성

Graph(PageRank + heuristic) 기반 중요도(importance) 산출

파일/모듈/기능 단위 요약/태깅(Summary/Tags) 생성

Retriever/Agent가 “어디부터 볼지”를 결정하는 상위 내비게이션 레이어 제공

1-2. 핵심 설계 결정

저장소 DB: RepoMap은 Postgres(JSONB) 에 저장

입력: IRStore + GraphStore + ChunkIndex + Snapshot 메타

출력: RepoMapSnapshot(트리, metrics, summary)

모듈 구성: tree / pagerank / summarizer / store / ports

사용 방식:

Index Layer: RepoMap의 importance/summary/tags를 IndexDocument에 태워 인덱싱

Retriever Layer: RepoMapPort로 subtree + candidate chunk scope를 먼저 결정 후, Lexical/Vector/Symbol 검색 수행

2. 목표 (Objectives)

2-1. 핵심 목적

Chunk Layer 위에 “사람이 읽을 수 있는 수준”의 프로젝트 상위 구조 계층 구성

LLM이 즉시 아래 질문에 답할 수 있도록 지원:

“이 레포의 핵심 구조는?”

“어디서부터 읽어야 하는가?”

“이 기능은 어떻게 연결되어 있는가?”

2-2. 아키텍처 상 위치

foundation: parsing → ir → graph → chunk

코드 구조 + 코드 그래프 + 청크 생성

repomap:

Tree + Importance(PageRank + heuristic) + Summary 생성

index:

RepoMap 결과를 tags/summary/importance로 포함해 인덱싱

retriever:

RepoMap을 read-only consumer로 사용

subtree / 중요도 기반 context 범위를 먼저 결정

2-3. 읽기/쓰기 경계

RepoMap Layer: 쓰기(생성/갱신) 전용

index / retriever / agent: RepoMap을 읽기 전용으로 소비

3. Contract-first (입력 / 출력 모델)
3-1. 입력 (Dependencies)

A. IRStore

IRDocument

symbol table

module_path, LOC, symbol_count 등 메타

B. GraphStore

GraphDocument

사용 Edge types:

CALLS

IMPORTS

ROUTE_HANDLER

USES_REPO

(선택) READS/WRITES, INHERITS/IMPLEMENTS

C. ChunkIndex

LeafChunk (function/class/method chunk)

ParentChunk (file/module/project chunk)

D. Snapshot 메타

repo_id

snapshot_id

schema_version

→ 모든 Layer가 snapshot 기준으로 일관성 있게 동작

3-2. 출력 (RepoMap Schema – 논리 모델)

RepoMapNode

id: repomap:{repo_id}:{snapshot_id}:{logical_id}

repo_id, snapshot_id

kind: repo | project | module | dir | file | symbol | chunk

name

path: 파일/디렉토리 경로

fqn: fully qualified name

parent_id / children_ids[]

chunk_ids[]: 이 노드에 직접 매핑된 leaf chunk

metrics:

loc

symbol_count

edge_degree

pagerank

change_freq

hot_score

importance (최종 점수)

summary:

title

body

tags[]

summary_text (vector index embedding 대상)

attrs: 부가 메타 (언어, 도메인 태그, entrypoint 플래그 등)

RepoMapSnapshot

repo_id

snapshot_id

root_node_id

nodes: dict[node_id, RepoMapNode]

schema_version

4. RepoMap Layer 모듈 구조
src/repomap/
  models.py       # RepoMapNode / RepoMapSnapshot / Metrics / Summary
  builder/        # 전체 파이프라인 orchestrator (Tree + PageRank + Summary)
    tree_builder.py
  pagerank/       # Graph 기반 importance 계산
    engine.py
  summarizer/     # 요약/태깅 생성 (LLM + rule-based)
    engine.py
  store/          # Postgres 저장/조회 adapter
    postgres_store.py
  ports.py        # RepoMapPort (retriever/index에서 사용)

5. 도메인 모델 (Pydantic 스키마 – 최종안)
5-1. RepoMap 모델
# src/repomap/models.py
from __future__ import annotations

from typing import Any, Literal
from pydantic import BaseModel


RepoMapKind = Literal["repo", "project", "module", "dir", "file", "symbol", "chunk"]


class RepoMapMetrics(BaseModel):
    loc: int | None = None
    symbol_count: int | None = None
    edge_degree: float | None = None

    pagerank: float | None = None
    change_freq: float | None = None
    hot_score: float | None = None

    importance: float | None = None  # 최종 종합 score


class RepoMapSummary(BaseModel):
    title: str | None = None
    body: str | None = None
    tags: list[str] = []
    summary_text: str | None = None


class RepoMapNode(BaseModel):
    id: str
    repo_id: str
    snapshot_id: str

    kind: RepoMapKind
    name: str

    path: str | None = None
    fqn: str | None = None

    parent_id: str | None = None
    children_ids: list[str] = []

    chunk_ids: list[str] = []

    metrics: RepoMapMetrics = RepoMapMetrics()
    summary: RepoMapSummary = RepoMapSummary()

    attrs: dict[str, Any] = {}


class RepoMapSnapshot(BaseModel):
    repo_id: str
    snapshot_id: str
    root_node_id: str
    nodes: dict[str, RepoMapNode]

6. Postgres 저장 구조 (Storage Schema)
6-1. repomap_snapshots
CREATE TABLE repomap_snapshots (
    repo_id        TEXT        NOT NULL,
    snapshot_id    TEXT        NOT NULL,
    root_node_id   TEXT        NOT NULL,
    schema_version TEXT        NOT NULL DEFAULT '1.0',
    created_at     TIMESTAMPTZ NOT NULL DEFAULT NOW(),

    PRIMARY KEY (repo_id, snapshot_id)
);

6-2. repomap_nodes
CREATE TABLE repomap_nodes (
    id           TEXT        NOT NULL,
    repo_id      TEXT        NOT NULL,
    snapshot_id  TEXT        NOT NULL,

    kind         TEXT        NOT NULL,
    name         TEXT        NOT NULL,
    path         TEXT        NULL,
    fqn          TEXT        NULL,

    parent_id    TEXT        NULL,
    children_ids TEXT[]      NOT NULL DEFAULT '{}',

    chunk_ids    TEXT[]      NOT NULL DEFAULT '{}',

    metrics      JSONB       NOT NULL DEFAULT '{}'::jsonb,
    summary      JSONB       NOT NULL DEFAULT '{}'::jsonb,
    attrs        JSONB       NOT NULL DEFAULT '{}'::jsonb,

    created_at   TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    updated_at   TIMESTAMPTZ NOT NULL DEFAULT NOW(),

    PRIMARY KEY (id),

    CONSTRAINT fk_repomap_nodes_snapshot
      FOREIGN KEY (repo_id, snapshot_id)
      REFERENCES repomap_snapshots (repo_id, snapshot_id)
      ON DELETE CASCADE
);

6-3. 인덱스 설계
-- repo/snapshot 범위 조회
CREATE INDEX idx_repomap_nodes_repo_snapshot
  ON repomap_nodes (repo_id, snapshot_id);

-- subtree 조회
CREATE INDEX idx_repomap_nodes_parent
  ON repomap_nodes (repo_id, snapshot_id, parent_id);

-- kind + path 검색
CREATE INDEX idx_repomap_nodes_kind_path
  ON repomap_nodes (repo_id, snapshot_id, kind, path);

-- importance 정렬 최적화
CREATE INDEX idx_repomap_nodes_importance
  ON repomap_nodes (
      repo_id,
      snapshot_id,
      ((metrics->>'importance')::double precision)
  );

-- summary.tags 검색 최적화
CREATE INDEX idx_repomap_nodes_summary_tags_gin
  ON repomap_nodes USING GIN ((summary->'tags'));

-- 선택: path fuzzy search
CREATE EXTENSION IF NOT EXISTS pg_trgm;

CREATE INDEX idx_repomap_nodes_path_trgm
  ON repomap_nodes
  USING GIN (path gin_trgm_ops);

6-4. snapshot 저장 플로우
-- 1) snapshot 메타 upsert
INSERT INTO repomap_snapshots (repo_id, snapshot_id, root_node_id)
VALUES ($1, $2, $3)
ON CONFLICT (repo_id, snapshot_id) DO UPDATE
  SET root_node_id = EXCLUDED.root_node_id,
      created_at = NOW();

-- 2) 노드 bulk upsert
INSERT INTO repomap_nodes (
  id, repo_id, snapshot_id,
  kind, name, path, fqn,
  parent_id, children_ids, chunk_ids,
  metrics, summary, attrs
)
VALUES (...), (...), ...
ON CONFLICT (id) DO UPDATE
  SET kind        = EXCLUDED.kind,
      name        = EXCLUDED.name,
      path        = EXCLUDED.path,
      fqn         = EXCLUDED.fqn,
      parent_id   = EXCLUDED.parent_id,
      children_ids= EXCLUDED.children_ids,
      chunk_ids   = EXCLUDED.chunk_ids,
      metrics     = EXCLUDED.metrics,
      summary     = EXCLUDED.summary,
      attrs       = EXCLUDED.attrs,
      updated_at  = NOW();

7. TreeBuilder 실행 계획
7-1. 책임

Chunk / IR / Graph를 읽어 RepoMapSnapshot의 “트리 골격” 생성

repo root → dir → file → module → symbol/chunk

metrics, summary는 후속 모듈에서 채움

7-2. 스켈레톤
# src/repomap/builder/tree_builder.py
from __future__ import annotations

from typing import Iterable

from src.repomap.models import RepoMapNode, RepoMapSnapshot
from src.foundation.chunk.models import Chunk
from src.foundation.chunk.store import ChunkStore
from src.foundation.ir.store import IRStore
from src.foundation.graph.store import GraphStore


class RepoMapTreeBuilder:
    def __init__(
        self,
        chunk_store: ChunkStore,
        ir_store: IRStore | None = None,
        graph_store: GraphStore | None = None,
    ) -> None:
        self.chunk_store = chunk_store
        self.ir_store = ir_store
        self.graph_store = graph_store

    def build_snapshot(
        self,
        repo_id: str,
        snapshot_id: str,
    ) -> RepoMapSnapshot:
        chunks = self._load_chunks(repo_id, snapshot_id)
        nodes: dict[str, RepoMapNode] = {}

        root = self._build_dir_file_tree(repo_id, snapshot_id, chunks, nodes)
        self._attach_module_nodes(repo_id, snapshot_id, chunks, nodes)
        self._attach_symbol_and_chunk_nodes(repo_id, snapshot_id, chunks, nodes)

        return RepoMapSnapshot(
            repo_id=repo_id,
            snapshot_id=snapshot_id,
            root_node_id=root.id,
            nodes=nodes,
        )

    def _load_chunks(
        self,
        repo_id: str,
        snapshot_id: str,
    ) -> list[Chunk]:
        return self.chunk_store.list_chunks(repo_id=repo_id, snapshot_id=snapshot_id)

    def _build_dir_file_tree(
        self,
        repo_id: str,
        snapshot_id: str,
        chunks: Iterable[Chunk],
        nodes: dict[str, RepoMapNode],
    ) -> RepoMapNode:
        root_id = f"repomap:{repo_id}:{snapshot_id}:root"
        root = RepoMapNode(
            id=root_id,
            repo_id=repo_id,
            snapshot_id=snapshot_id,
            kind="repo",
            name=repo_id,
            path=".",
            parent_id=None,
        )
        nodes[root.id] = root

        for chunk in chunks:
            if not chunk.file_path:
                continue
            self._ensure_dir_file_chain(
                repo_id=repo_id,
                snapshot_id=snapshot_id,
                root=root,
                file_path=chunk.file_path,
                nodes=nodes,
            )

        return root

    def _ensure_dir_file_chain(
        self,
        repo_id: str,
        snapshot_id: str,
        root: RepoMapNode,
        file_path: str,
        nodes: dict[str, RepoMapNode],
    ) -> RepoMapNode:
        # "src/indexing/pipeline.py" → repo → "src" → "src/indexing" → file 노드
        ...

    def _attach_module_nodes(
        self,
        repo_id: str,
        snapshot_id: str,
        chunks: Iterable[Chunk],
        nodes: dict[str, RepoMapNode],
    ) -> None:
        # module_path 기준 논리 모듈 노드 삽입
        ...

    def _attach_symbol_and_chunk_nodes(
        self,
        repo_id: str,
        snapshot_id: str,
        chunks: Iterable[Chunk],
        nodes: dict[str, RepoMapNode],
    ) -> None:
        # function/class chunk들을 file/module/symbol 노드에 붙이고 chunk_ids 채움
        ...

8. PageRankEngine 실행 계획
8-1. 책임

GraphStore의 symbol-level 그래프(CALLS/IMPORTS/ROUTE_HANDLER/USES_REPO)를 기반으로 PageRank 계산

RepoMapNode에 pagerank/importance 채워넣기

8-2. 스켈레톤
# src/repomap/pagerank/engine.py
from __future__ import annotations

from src.repomap.models import RepoMapSnapshot
from src.foundation.graph.store import GraphStore


class RepoMapPageRankEngine:
    def __init__(self, graph_store: GraphStore) -> None:
        self.graph_store = graph_store

        self.w_pr = 1.0
        self.w_loc = 0.2
        self.w_change = 0.3
        self.w_entry = 0.5
        self.w_test_penalty = 0.5

    def apply_pagerank(
        self,
        snapshot: RepoMapSnapshot,
    ) -> RepoMapSnapshot:
        symbol_pr = self._compute_symbol_pagerank(snapshot)
        self._aggregate_to_repomap_nodes(snapshot, symbol_pr)
        self._compute_importance(snapshot)
        return snapshot

    def _compute_symbol_pagerank(
        self,
        snapshot: RepoMapSnapshot,
    ) -> dict[str, float]:
        # 1) symbol_id 목록 수집
        # 2) GraphStore에서 관련 edge 조회
        # 3) 간단한 power iteration PageRank
        ...
        return {}

    def _aggregate_to_repomap_nodes(
        self,
        snapshot: RepoMapSnapshot,
        symbol_pr: dict[str, float],
    ) -> None:
        # symbol-level PR → RepoMapNode에 집계 (chunk_ids / attrs.symbol_ids 등 활용)
        ...

    def _compute_importance(
        self,
        snapshot: RepoMapSnapshot,
    ) -> None:
        for node in snapshot.nodes.values():
            m = node.metrics

            loc = (m.loc or 0)
            pr = (m.pagerank or 0.0)
            change = (m.change_freq or 0.0)
            entry = 1.0 if node.attrs.get("is_entrypoint") else 0.0
            is_test = bool(node.attrs.get("is_test_file"))

            importance = (
                self.w_pr * pr
                + self.w_loc * (loc ** 0.5)
                + self.w_change * change
                + self.w_entry * entry
            )
            if is_test:
                importance -= self.w_test_penalty

            m.importance = importance

9. Index Layer 연동 (IndexDocument 매핑 규칙)
9-1. 전제

IndexDocument (예시 필드):

chunk_id

repo_id

file_path

symbol_id / symbol_fqn

kind / language

content / content_vector

identifiers

tags (dict/JSON)

importance_score

start_line / end_line

9-2. RepoMap → IndexDocument 매핑 규칙

중요도 매핑

IndexDocument.importance_score = RepoMapNode.metrics.importance or 0.0

RepoMap 메타 태그

tags["repomap_node_id"] = RepoMapNode.id

tags["repomap_path"] = RepoMapNode.path or ""

tags["repomap_kind"] = RepoMapNode.kind

tags["repomap_score"] = str(RepoMapNode.metrics.importance or 0.0)

필요 시: tags["repomap_rank"] = "<rank_int>"

ParentChunk 연동

chunk에 parent_chunk_id가 있으면:

tags["parent_chunk_id"] = chunk.parent_id

도메인/레이어 태그

RepoMapNode.attrs 또는 Chunk.attrs에서 역할/레이어 정보 전달

tags["layer"] = "api" | "service" | "infra" ...

tags["bounded_context"] = "indexing" | "retriever" ...

Summary / Vector 연동

IndexDocument.content 구성:

[RepoMapSummary.title/body] + [Chunk.summary] + [signature] + [code] 순으로 합성

IndexDocument.content_vector:

가능하면 RepoMapSummary.summary_text를 임베딩

없으면 fallback: content 일부를 임베딩

10. Retriever Layer 연동 (RepoMap-aware Retrieval)
10-1. 고수준 흐름

사용자 질의 입력

QueryIntent/Classifier로 질의 의도 파악

RepoMapPort로 “어느 subtree를 볼지” 결정

선택된 subtree에서 candidate chunk_id 집합 구성

Lexical/Vector/Symbol 인덱스에서 해당 scope 안에서 검색

Weighted Fusion 후 상위 N개 Context 구성

10-2. 의사코드
# src/retriever/repomap_aware.py

from src.repomap.ports import RepoMapPort
from src.foundation.indexing.models import SearchHit
from src.retriever.intent import QueryIntent
from src.retriever.fusion import fuse_hits


class RepoMapAwareRetriever:
    def __init__(
        self,
        repomap_port: RepoMapPort,
        lexical_index,
        vector_index,
        symbol_index,
    ) -> None:
        self.repomap_port = repomap_port
        self.lexical_index = lexical_index
        self.vector_index = vector_index
        self.symbol_index = symbol_index

    def retrieve(
        self,
        repo_id: str,
        query: str,
        limit: int = 20,
    ) -> list[SearchHit]:
        intent = QueryIntent.from_query(query)

        focus_nodes = self._select_focus_nodes(repo_id, intent, query)
        candidate_chunk_ids = self._collect_candidate_chunks(focus_nodes)

        lexical_hits = self._search_lexical(repo_id, query, candidate_chunk_ids)
        vector_hits = self._search_vector(repo_id, query, candidate_chunk_ids)
        symbol_hits = self._search_symbol(repo_id, query, candidate_chunk_ids)

        fused = fuse_hits(
            [
                ("lexical", lexical_hits),
                ("vector", vector_hits),
                ("symbol", symbol_hits),
            ],
            weights={"lexical": 0.4, "vector": 0.4, "symbol": 0.2},
        )
        return fused[:limit]

    def _select_focus_nodes(
        self,
        repo_id: str,
        intent: QueryIntent,
        query: str,
    ):
        top_nodes = self.repomap_port.get_topk_by_importance(repo_id, k=100)
        focus_nodes = [
            n for n in top_nodes
            if self._match_intent(n, intent, query)
        ]
        return focus_nodes

    def _collect_candidate_chunks(self, nodes) -> set[str]:
        chunk_ids: set[str] = set()
        for node in nodes:
            chunk_ids.update(node.chunk_ids)
            # 필요시 subtree 순회해서 자식 chunk_ids도 추가
        return chunk_ids

    def _search_lexical(self, repo_id: str, query: str, candidate_chunk_ids: set[str]):
        hits = self.lexical_index.search(repo_id, query, limit=200)
        if not candidate_chunk_ids:
            return hits
        return [h for h in hits if h.chunk_id in candidate_chunk_ids]

    def _search_vector(self, repo_id: str, query: str, candidate_chunk_ids: set[str]):
        hits = self.vector_index.search(repo_id, query, limit=200)
        if not candidate_chunk_ids:
            return hits
        return [h for h in hits if h.chunk_id in candidate_chunk_ids]

    def _search_symbol(self, repo_id: str, query: str, candidate_chunk_ids: set[str]):
        hits = self.symbol_index.search(repo_id, query, limit=200)
        if not candidate_chunk_ids:
            return hits
        return [h for h in hits if h.chunk_id in candidate_chunk_ids]

11. 실행 단계 (Phase Plan)

11-1. Phase 1 – 기본 트리 + 저장

Pydantic 모델 (models.py) 확정

Postgres 스키마 (repomap_snapshots, repomap_nodes) 생성

TreeBuilder v1

dir/file 트리

file-level node에 chunk_ids 연결

RepoMapStore(Postgres adapter)

save_snapshot(RepoMapSnapshot) / load_snapshot(repo_id, snapshot_id)

11-2. Phase 2 – PageRank 기반 importance

GraphStore 연동

RepoMapPageRankEngine v1

symbol-level PageRank 계산

파일/모듈/디렉토리로 집계

importance 계산 후 DB 반영

11-3. Phase 3 – Summarizer / Incremental

Summarizer 엔진

Rule-based + LLM 기반 요약/태그 생성

RepoMap incremental 업데이트 정책

변경된 파일/모듈 subtree만 재계산

IndexDocument 매핑 로직 구현

11-4. Phase 4 – Retriever/Agent 통합

RepoMapPort 구현

get_topk_by_importance(repo_id, k)

get_subtree(root_node_id)

RepoMapAwareRetriever 적용

Agent 플로우에서 “프로젝트 구조 설명 / 진입점 안내” 등에 RepoMap 활용
