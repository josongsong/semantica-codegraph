1. 전체 흐름 개요
1-1. 지금 단계에서 목표


Step 1: Chunk → IndexDocument 변환 레이어 구현


Step 2: Lexical Index를 Zoekt 기반으로 붙이고, ZoektHit → Chunk 매핑 구현


결과


Zoekt: 레포 전체 파일 텍스트/정규식 검색


Semantica: Zoekt 결과를 chunk_id 단위로 승격해서


“코드 전체 텍스트 + identifier 기반 검색기” 완성


이후 Vector / Symbol / Graph / RepoMap과 Fusion 가능한 구조 확보




1-2. 현재 Chunk 모델 (이미 존재)
위치: src/foundation/chunk/models.py
class Chunk(BaseModel):
    chunk_id: str
    repo_id: str
    project_id: str | None
    module_path: str | None
    file_path: str | None

    kind: Literal["repo", "project", "module", "file", "class", "function"]
    fqn: str  # Fully qualified name

    start_line: int | None
    end_line: int | None
    content_hash: str | None

    parent_id: str | None
    children: list[str]

    language: str | None
    symbol_visibility: str | None
    symbol_id: str | None
    symbol_owner_id: str | None

    summary: str | None
    importance: float | None
    attrs: dict[str, Any] = {}

    version: int = 1
    last_indexed_commit: str | None = None
    is_deleted: bool = False

1-3. 레이어 관계 요약


Foundation


Chunk: 코드 구조 단위 (함수/클래스/파일 등)




Indexing


IndexDocument: Chunk 메타를 통합한 공통 검색 문서 (Vector/Domain용)


LexicalIndexPort: Zoekt 기반 파일 검색 + Chunk 매핑




Infra


Zoekt: 레포 파일 기준 인덱싱/검색 엔진 (별도 프로세스)




관계


인덱싱: Chunk → IndexDocument (Vector/Domain) + RepoFiles → Zoekt Index (Lexical)


검색: Zoekt.search(repo, query) → file/line → ChunkStore → SearchHit(chunk_id)


2. IndexDocument 레이어
2-1. IndexDocument 스키마
위치: src/foundation/indexing/models.py
from pydantic import BaseModel
from typing import Any, Literal

class IndexDocument(BaseModel):
    """
    모든 인덱스(Vector/Domain/Runtime)가 공유하는 공통 검색 문서 스키마.
    Lexical(Zoekt)는 파일 원본을 사용하므로 여기를 직접 쓰지 않는다.
    """

    # 식별자
    chunk_id: str
    repo_id: str
    file_path: str | None

    # Symbol 정보
    symbol_id: str | None
    symbol_fqn: str
    kind: str                  # "repo" | "project" | "module" | "file" | "class" | "function"
    language: str | None

    # 검색용 텍스트 (Vector/Domain용)
    content: str               # [SUMMARY] + [SIGNATURE] + [CODE] + [META]
    content_vector: str | None = None  # Vector용 축약 텍스트 (Phase 2에서 활용)

    identifiers: list[str] = []        # 함수명, 클래스명, import symbol, 주요 파라미터 이름 등
    tags: dict[str, str] = {}          # module, kind, visibility, layer 등

    # 랭킹/품질
    importance_score: float = 0.0

    # 위치
    start_line: int | None
    end_line: int | None


class SearchHit(BaseModel):
    """
    모든 인덱스 공통 검색 결과 스키마.
    source로 lexical/vector/symbol/... 구분.
    """
    chunk_id: str
    file_path: str | None
    symbol_id: str | None
    score: float
    source: Literal["lexical", "vector", "symbol", "fuzzy", "domain", "runtime"]
    metadata: dict[str, Any] = {}

포인트


IndexDocument는 Lexical(Zoekt)와 직접 연결되지 않음


나중 Vector/Domain/RepoMap-aware index에서 재사용


2-2. Chunk → IndexDocument 변환
위치: src/foundation/indexing/transformer.py
from src.foundation.chunk.models import Chunk
from src.foundation.indexing.models import IndexDocument
from src.foundation.ir.models import IRDocument | None  # 예시
from src.foundation.graph.models import GraphDocument | None  # 예시

def chunk_to_index_document(
    chunk: Chunk,
    ir_doc: IRDocument | None = None,
    graph_doc: GraphDocument | None = None,
    source_code: str | None = None,
) -> IndexDocument:
    return IndexDocument(
        chunk_id=chunk.chunk_id,
        repo_id=chunk.repo_id,
        file_path=chunk.file_path,
        symbol_id=chunk.symbol_id,
        symbol_fqn=chunk.fqn,
        kind=chunk.kind,
        language=chunk.language,
        content=_build_search_text(chunk, source_code),
        content_vector=None,  # Phase 2에서 축약 텍스트 생성
        identifiers=_collect_identifiers(chunk, ir_doc),
        tags=_build_tags(chunk),
        importance_score=chunk.importance or 0.0,
        start_line=chunk.start_line,
        end_line=chunk.end_line,
    )

2-3. Helper 함수들
2-3-1. _build_search_text
def _build_search_text(chunk: Chunk, source_code: str | None) -> str:
    parts: list[str] = []

    # 1) SUMMARY
    if chunk.summary:
        parts.append(f"[SUMMARY] {chunk.summary}")

    # 2) SIGNATURE (attrs.signature 사용)
    signature = chunk.attrs.get("signature", "")
    if signature:
        parts.append(f"[SIGNATURE] {signature}")

    # 3) CODE (function/class/file에만 포함)
    if chunk.kind in ("function", "class", "file") and source_code:
        parts.append(f"[CODE] {source_code}")

    # 4) META
    meta_parts: list[str] = []
    if chunk.file_path:
        meta_parts.append(f"file={chunk.file_path}")
    meta_parts.append(f"symbol={chunk.fqn}")
    if chunk.module_path:
        meta_parts.append(f"module={chunk.module_path}")
    meta_parts.append(f"kind={chunk.kind}")
    if chunk.language:
        meta_parts.append(f"lang={chunk.language}")

    parts.append(f"[META] {' '.join(meta_parts)}")

    return "\n\n".join(parts)

규칙


SUMMARY, SIGNATURE는 항상 content 맨 앞에 위치


CODE는 길어도 상관없음 (lexical은 Zoekt로 가고, 여기선 Vector/Domain용)


META는 검색 시 필터링/설명용 feature


2-3-2. _collect_identifiers
def _collect_identifiers(chunk: Chunk, ir_doc: IRDocument | None) -> list[str]:
    identifiers: set[str] = set()

    # 1) Chunk attrs에 pre-computed identifiers 있으면 우선 사용
    if "identifiers" in chunk.attrs:
        identifiers.update(chunk.attrs["identifiers"])

    # 2) FQN 조각
    for part in chunk.fqn.split("."):
        if part:
            identifiers.add(part)

    # 3) IR 기반 추가 (선택)
    # - 함수/클래스 이름
    # - 파라미터 이름
    # - import symbol 이름
    # - decorator 이름 등
    if ir_doc and chunk.symbol_id:
        # _find_ir_node는 IR 구조에 맞게 구현
        ir_node = _find_ir_node(ir_doc, chunk.symbol_id)
        if ir_node:
            # 예시: ir_node.identifiers 같은 필드가 있다고 가정
            for name in getattr(ir_node, "identifiers", []):
                identifiers.add(name)

    # 정규화
    return sorted(
        {name.lower() for name in identifiers if name}
    )

2-3-3. _build_tags
def _build_tags(chunk: Chunk) -> dict[str, str]:
    tags: dict[str, str] = {
        "kind": chunk.kind,
    }
    if chunk.module_path:
        tags["module"] = chunk.module_path
    if chunk.language:
        tags["language"] = chunk.language
    if chunk.symbol_visibility:
        tags["visibility"] = chunk.symbol_visibility
    # layer, bounded_context 등은 RepoMap/도메인 분석에서 채움
    return tags

2-4. 파일 구조
src/foundation/indexing/
  __init__.py
  models.py        # IndexDocument, SearchHit, LexicalIndexPort 등
  transformer.py   # chunk_to_index_document + helpers
  service.py       # IndexingService (Vector/Domain/Zoekt orchestrator)

3. Lexical Index (Zoekt) 레이어
3-1. 역할


레포 파일 기반 텍스트/정규식/identifier 검색 엔진


Zoekt를 Core Lexical 엔진으로 사용


검색 결과를 file_path + line_number로 받은 뒤,
ChunkStore.find_chunk_by_file_and_line을 통해 chunk_id로 매핑


IndexDocument는 Lexical이 아닌 Vector/Domain에서 사용


3-2. Port 인터페이스
위치: src/foundation/indexing/models.py (또는 별도 ports.py)
from typing import Protocol

class LexicalIndexPort(Protocol):
    """
    Zoekt 기반 Lexical Search 포트.
    """

    def reindex_repo(self, repo_id: str) -> None:
        """
        레포 전체 재인덱싱.
        - 새로 clone 또는 pull 후 zoekt-index 실행
        """

    def reindex_paths(self, repo_id: str, paths: list[str]) -> None:
        """
        특정 파일/디렉토리만 부분 인덱싱.
        - MVP에서는 전체 reindex로 시작해도 됨
        """

    def search(self, repo_id: str, query: str, limit: int = 50) -> list[SearchHit]:
        """
        Zoekt 검색 + Chunk 매핑 결과 반환.
        - SearchHit.source == "lexical"
        """

    def delete_repo(self, repo_id: str) -> None:
        """
        레포 인덱스 삭제 (필요 시).
        """

3-3. Zoekt 어댑터 구조
위치: src/infra/search/zoekt_adapter.py (또는 기존 zoekt.py 확장)
import requests
from typing import Any

from src.foundation.indexing.models import SearchHit, LexicalIndexPort
from src.foundation.chunk.store import ChunkStore


class RepoPathResolver:
    """
    repo_id ↔ filesystem path ↔ zoekt repo name 매핑.
    """
    def get_fs_path(self, repo_id: str) -> str: ...
    def get_zoekt_repo_name(self, repo_id: str) -> str: ...


class ZoektLexicalIndex(LexicalIndexPort):
    def __init__(
        self,
        http_endpoint: str,
        repo_mapper: RepoPathResolver,
        chunk_store: ChunkStore,
    ):
        self.endpoint = http_endpoint.rstrip("/")
        self.repo_mapper = repo_mapper
        self.chunk_store = chunk_store

    def reindex_repo(self, repo_id: str) -> None:
        repo_path = self.repo_mapper.get_fs_path(repo_id)
        zoekt_repo = self.repo_mapper.get_zoekt_repo_name(repo_id)
        # subprocess or RPC:
        # ex) subprocess.run(["zoekt-index", "-index", zoekt_repo, repo_path], check=True)
        ...

    def reindex_paths(self, repo_id: str, paths: list[str]) -> None:
        # MVP에서는 전체 reindex로 대체 가능
        # 추후 zoekt incremental 옵션 사용
        ...

    def search(self, repo_id: str, query: str, limit: int = 50) -> list[SearchHit]:
        zoekt_repo = self.repo_mapper.get_zoekt_repo_name(repo_id)
        zoekt_query = build_zoekt_query(query, repo=zoekt_repo)

        raw_results = self._zoekt_http_search(zoekt_query, limit=limit)
        hits: list[SearchHit] = []

        for r in raw_results:
            file_path = r["file_name"]
            line = r["line_number"]
            score = float(r["score"])
            preview = r.get("context", "")

            chunk = self.chunk_store.find_chunk_by_file_and_line(
                repo_id=repo_id,
                file_path=file_path,
                line=line,
            )

            if not chunk:
                # 매핑 실패 시 file+line 기반 fallback
                hits.append(SearchHit(
                    chunk_id=f"{file_path}:{line}",
                    file_path=file_path,
                    symbol_id=None,
                    score=score,
                    source="lexical",
                    metadata={"line": line, "preview": preview, "mapped": False},
                ))
                continue

            hits.append(SearchHit(
                chunk_id=chunk.chunk_id,
                file_path=file_path,
                symbol_id=chunk.symbol_id,
                score=score,
                source="lexical",
                metadata={
                    "line": line,
                    "preview": preview,
                    "kind": chunk.kind,
                    "mapped": True,
                },
            ))

        return hits[:limit]

    def delete_repo(self, repo_id: str) -> None:
        zoekt_repo = self.repo_mapper.get_zoekt_repo_name(repo_id)
        # zoekt index 파일 제거 or 관리 API 호출
        ...

    def _zoekt_http_search(self, query: str, limit: int) -> list[dict[str, Any]]:
        # Zoekt webserver의 실제 API 스펙에 맞게 구현
        # 예시: GET /search?q=<query>&num=<limit>
        resp = requests.get(f"{self.endpoint}/search", params={"q": query, "num": limit})
        resp.raise_for_status()
        data = resp.json()

        # data → [{file_name, line_number, context, score}, ...] 형태로 변환
        results: list[dict[str, Any]] = []
        # 변환 로직은 실제 Zoekt 응답 구조에 맞게 구현
        ...
        return results

3-4. ChunkStore.find_chunk_by_file_and_line
위치: src/foundation/chunk/store.py
from typing import Optional
from src.foundation.chunk.models import Chunk

class ChunkStore:
    ...

    def find_chunk_by_file_and_line(
        self,
        repo_id: str,
        file_path: str,
        line: int,
    ) -> Optional[Chunk]:
        """
        file_path + line_number를 덮는 function/class/file chunk를 찾는다.
        우선순위: function > class > file
        """
        # 예시: Postgres 쿼리 기반 구현
        # SELECT *
        # FROM chunks
        # WHERE repo_id = $1 AND file_path = $2
        #   AND start_line IS NOT NULL
        #   AND end_line IS NOT NULL
        #   AND start_line <= $3 AND end_line >= $3
        # ORDER BY kind_priority(kind) ASC
        # LIMIT 1;
        ...

DB 인덱스 권장
CREATE INDEX idx_chunks_span
ON chunks (repo_id, file_path, start_line, end_line);

3-5. QueryBuilder (Zoekt DSL 래퍼)
위치: src/foundation/indexing/query_builder.py
def build_zoekt_query(
    user_query: str,
    repo: str | None = None,
    language: str | None = None,
    file_prefix: str | None = None,
) -> str:
    """
    사용자 쿼리를 Zoekt DSL로 래핑.
    - repo, lang, file prefix 등을 필터로 추가.
    """
    parts: list[str] = []

    if repo:
        parts.append(f"repo:{repo}")
    if language:
        parts.append(f"lang:{language}")
    if file_prefix:
        parts.append(f"file:{file_prefix}/*")

    parts.append(user_query)
    return " ".join(parts)

4. IndexingService와 검색 플로우
4-1. IndexingService
위치: src/foundation/indexing/service.py
from src.foundation.chunk.models import Chunk
from src.foundation.indexing.models import IndexDocument
from src.foundation.indexing.transformer import chunk_to_index_document
from src.foundation.indexing.models import SearchHit, LexicalIndexPort

class IndexingService:
    def __init__(
        self,
        lexical_index: LexicalIndexPort,
        vector_index: "VectorIndexPort | None" = None,
    ):
        self.lexical_index = lexical_index
        self.vector_index = vector_index

    def index_repo_full(self, repo_id: str, chunks: list[Chunk]) -> None:
        """
        전체 레포 인덱싱.
        - Zoekt: repo 단위 reindex
        - Vector/Domain: Chunk → IndexDocument 후 upsert
        """
        if self.vector_index:
            docs: list[IndexDocument] = [
                chunk_to_index_document(c) for c in chunks
            ]
            self.vector_index.upsert_documents(docs)

        self.lexical_index.reindex_repo(repo_id)

    def index_repo_incremental(
        self,
        repo_id: str,
        refresh_result: "ChunkRefreshResult",
    ) -> None:
        """
        증분 인덱싱.
        - ChunkRefreshResult: added/updated/deleted/renamed 등 포함
        """
        # 1) Vector/Domain 인덱스 업데이트
        if self.vector_index:
            changed_chunks = refresh_result.added_chunks + refresh_result.updated_chunks
            if changed_chunks:
                docs = [chunk_to_index_document(c) for c in changed_chunks]
                self.vector_index.upsert_documents(docs)

            if refresh_result.deleted_chunks:
                self.vector_index.delete_documents(refresh_result.deleted_chunks)

        # 2) Zoekt 인덱스 업데이트 (변경된 파일만)
        changed_files = sorted({
            c.file_path
            for c in refresh_result.added_chunks + refresh_result.updated_chunks
            if c.file_path
        })
        if changed_files:
            self.lexical_index.reindex_paths(repo_id, changed_files)

4-2. Lexical 단독 검색
def search_lexical(
    repo_id: str,
    query: str,
    lexical_index: LexicalIndexPort,
    limit: int = 50,
) -> list[SearchHit]:
    return lexical_index.search(repo_id, query, limit=limit)

4-3. Hybrid 검색 확장 (후속 단계)


Lexical: Zoekt 기반 SearchHit(source="lexical")


Vector: VectorIndexPort.search(...) 결과


Symbol/Graph: 별도 포트 결과


이들을 SearchHit 리스트로 모아 Weighted Fusion / RRF 수행
def search_unified(
    repo_id: str,
    query: str,
    *,
    lexical_index: LexicalIndexPort,
    vector_index: "VectorIndexPort",
    symbol_index: "SymbolIndexPort",
    limit: int = 50,
) -> list[SearchHit]:
    lexical_hits = lexical_index.search(repo_id, query, limit=100)
    vector_hits = vector_index.search(repo_id, query, limit=100)
    symbol_hits = symbol_index.search(repo_id, query, limit=100)

    fused = reciprocal_rank_fusion(
        [lexical_hits, vector_hits, symbol_hits],
        weights=[0.4, 0.4, 0.2],
    )
    return fused[:limit]

5. 구현 순서 체크리스트 (Zoekt 반영 버전)
5-1. Phase 1: Chunk → IndexDocument


src/foundation/indexing/models.py




 IndexDocument 정의


 SearchHit 정의


 LexicalIndexPort 인터페이스 정의




src/foundation/indexing/transformer.py




 chunk_to_index_document 구현


 _build_search_text, _collect_identifiers, _build_tags 구현




ChunkStore




 find_chunk_by_file_and_line 인터페이스 정의


 DB 인덱스(idx_chunks_span) 추가


5-2. Phase 2: Zoekt Lexical Index


src/infra/search/zoekt_adapter.py




 RepoPathResolver 구현


 ZoektLexicalIndex 구현


reindex_repo


reindex_paths


search (Zoekt → Chunk 매핑)


_zoekt_http_search (임시 stub → 실제 API로 교체)






src/foundation/indexing/query_builder.py




 build_zoekt_query 구현




src/foundation/indexing/service.py




 IndexingService 구현


index_repo_full


index_repo_incremental




5-3. Phase 3: 품질/확장


품질 보완




 Zoekt 쿼리에 lang:, file: 필터 추가


 identifier 기반 추가 랭킹 정보(metadata.identifier_match 등) 넣기


 로그/메트릭: Zoekt latency, hit 수, chunk 매핑 실패율




Vector/Domain 인덱스 연동




 VectorIndexPort 설계


 IndexDocument.content_vector 생성 로직 추가


 Hybrid Fusion 구현


이 구조 그대로 가면


Lexical: Zoekt 기반 SOTA급 텍스트/정규식/identifier 검색


IndexDocument: Vector/Domain/RepoMap-aware 검색에 그대로 사용


둘 다 독립이지만, chunk_id를 공통 축으로 쓰기 때문에
Retriever/Agent에서 자연스럽게 합쳐서 사용할 수 있음.
