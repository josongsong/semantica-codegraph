# Semantica v2: Indexing Layer Architecture (인덱싱 레이어 아키텍처)

# 0. 위치 및 역할 개요

Semantica v2 엔진은 총 7단계 파이프라인으로 구성되며, Indexing Layer는 그 중 **4단계**에 해당함.

| 단계 | 레이어명                | 핵심 역할                                | 주요 산출물                                                |
| -- | ------------------- | ------------------------------------ | ----------------------------------------------------- |
| 1  | Parser              | 코드 파싱 → CodeNode                     | CodeNode, AST                                         |
| 2  | Chunking            | CodeNode → Chunk/Embedding/Delta     | LeafChunk, ParentChunk, EmbeddingDocument, ChunkDelta |
| 3  | Graph Construction  | 호출·참조·정의 그래프 생성                      | GraphEdge (calls, contains, imports, overrides)       |
| 4  | **Indexing** (본 문서) | 텍스트·벡터·그래프 인덱싱 및 증분 업데이트             | Zoekt, Qdrant, Kùzu 인덱스 상태                            |
| 5  | RepoMap             | 코드베이스 구조 요약 / 중요도 계산                 | ProjectMap, File/Module/Repo Summary                  |
| 6  | Retriever           | Hybrid 검색 + Rerank + Context Builder | SearchResults, ContextBundle                          |
| 7  | Agent               | 코드 편집·리팩토링·자동화 실행                    | Patch, ToolCall, Plan                                 |

Indexing Layer는 상위 레이어(Chunking, Graph, RepoMap)가 만들어낸 도메인 객체와 Delta 정보를 기반으로, **Zoekt / Qdrant / Kùzu** 세 가지 저장소에 대한 인덱스를 관리하는 실행 계층이다.

# 1. 설계 목표 및 원칙

## 1.1 설계 목표

1. 증분 인덱싱 최적화

   * Chunking Layer가 생성한 `ChunkDelta`를 활용해 변경된 부분만 반영
   * 전체 인덱스 재생성을 최소화

2. 다중 인덱스 백엔드 통합

   * Zoekt: 파일 단위 텍스트/구조 검색
   * Qdrant: 의미 기반(semantic) 벡터 검색
   * Kùzu: 호출·의존성 그래프 탐색

3. 스키마·백엔드 분리

   * 도메인 모델(Chunk, EmbeddingDocument, GraphEdge)과 물리 인덱스 스키마(Zoekt/Qdrant/Kùzu)를 분리
   * 백엔드 교체/추가가 가능하도록 모듈화

4. 안정성 및 재현성

   * `generation_run_id`, `source_file_hash`를 활용해 인덱스 상태를 재현 가능하게 유지
   * 실패 시 롤백·재시도 전략 명시

## 1.2 Indexing Layer Responsibilities

Indexing Layer가 반드시 수행해야 하는 책임은 다음과 같다.

1. Delta 적용

* Chunking/Graph/RepoMap에서 전달된 Delta를 Zoekt/Qdrant/Kùzu에 반영
* insert/update/delete 레벨의 변경만 수행

2. 물리 스키마 매핑

* 도메인 객체 → Zoekt/Qdrant/Kùzu 필드로 변환
* 컬렉션/테이블 설계 및 key 규칙 관리

3. 인덱스 수명 주기 관리

* repo 단위 초기 인덱싱 / 전체 재인덱싱
* branch/namespace 기준 인덱스 분리 (예: main vs feature)
* 삭제된 repo/branch의 인덱스 클린업

4. 인덱싱 실행 단위 관리

* IndexingJob, IndexingRun 개념으로 배치/증분 작업 관리
* 동시성/병렬성 제어 (파일 단위, repo 단위)

## 1.3 Indexing Layer Non‑Responsibilities

Indexing Layer는 아래 기능을 수행하지 않는다.

1. Chunk/요약 생성

* Leaf/Parent Chunk 생성, summary/search_text 생성은 Chunking/RepoMap 책임

2. 그래프 구조 계산

* 어떤 관계를 calls/imports/contains로 볼지는 Graph Construction 책임

3. 검색 / 랭킹 / 컨텍스트 조립

* 검색 전략, hybrid 가중치, reranker, context assembler는 Retriever 책임

4. 코드 편집/수정 수행

* 패치 생성, 리팩토링 플랜, 테스트 실행 등은 Agent Layer 책임

# 2. 입력/출력 계약 (Contracts)

## 2.1 입력

Indexing Layer는 다음과 같은 입력을 받는다.

1. Chunking Layer

* LeafChunk
* ParentChunk
* EmbeddingDocument
* ChunkDelta (insert/update/delete/noop)

2. Graph Construction Layer

* GraphEdge (calls, contains, imports, overrides 등)
* GraphDelta (선택: edge insert/update/delete)

3. RepoMap Layer

* FileSummary, ModuleSummary, RepoSummary
* ProjectMap (선택적으로 인덱싱 대상)

4. 환경/설정

* IndexingConfig
* RepoConfig (branch, visibility, 우선순위 등)

## 2.2 출력

Indexing Layer의 출력은 "저장소 상태"이므로, 주로 외부 인덱스들의 최신 상태와 메타정보이다.

* Zoekt 인덱스 상태

  * repo 단위 파일 인덱스
* Qdrant 컬렉션 상태

  * EmbeddingDocument 기반 벡터 인덱스
* Kùzu 그래프 스키마 및 데이터

  * Node/Edge 인덱스
* IndexingRun 메타데이터

  * 언제 무엇을 얼마나 인덱싱했는지에 대한 로그/리포트

# 3. 도메인 모델 (Indexing 전용)

## 3.1 FileIndexDocument (Zoekt용)

Zoekt는 파일 단위 인덱싱이 기본이므로, Semantica 도메인에서는 이를 `FileIndexDocument`로 추상화한다.

```python
class FileIndexDocument(BaseModel):
    id: str                 # repo_id + file_path 해시
    repo_id: str
    file_path: str
    language: str

    text: str               # 파일 전체 텍스트
    source_file_hash: str   # 파일 내용 해시

    metadata: dict[str, Any] = {}
```

## 3.2 VectorIndexRecord (Qdrant용)

```python
class VectorIndexRecord(BaseModel):
    id: str                 # EmbeddingDocument.id 재사용
    repo_id: str

    vector: list[float]     # 실제 벡터는 인덱싱 시점에만 필요
    payload: dict[str, Any] # EmbeddingDocument.metadata + ref 정보
```

실제 코드에서는 벡터 생성(임베딩 호출)을 Indexing 앞/뒤 어디서 수행할지 정책으로 나누지만, Indexing Layer 스펙에서는 "임베딩 완료된 VectorIndexRecord를 받거나, EmbeddingDocument를 받아 내부에서 벡터화" 두 가지 전략 모두 허용하도록 정의할 수 있다.

## 3.3 GraphIndexRecord (Kùzu용)

```python
class GraphNodeRecord(BaseModel):
    id: str          # node_id 또는 chunk_id
    repo_id: str
    kind: str        # file/class/function/chunk 등
    attrs: dict[str, Any] = {}

class GraphEdgeRecord(BaseModel):
    id: str
    repo_id: str
    src_id: str
    dst_id: str
    edge_type: str   # calls/contains/imports/overrides 등
    attrs: dict[str, Any] = {}
```

## 3.4 IndexingJob / IndexingRun

```python
class IndexingScope(str, Enum):
    FULL_REPO = "full_repo"
    DELTA = "delta"        # ChunkDelta/GraphDelta 기반
    SINGLE_FILE = "single_file"

class IndexingJob(BaseModel):
    job_id: str
    repo_id: str
    scope: IndexingScope
    target_files: list[str] | None = None
    triggered_by: str  # user, ci, webhook 등

class IndexingRun(BaseModel):
    run_id: str
    job_id: str
    started_at: datetime
    finished_at: datetime | None
    status: Literal["running", "success", "failed", "partial"]
    stats: dict[str, Any] = {}
```

# 4. IndexingConfig

```python
class IndexingConfig(BaseModel):
    # Zoekt
    zoekt_repo_root: str
    zoekt_shard_size_mb: int = 128
    zoekt_max_parallel_files: int = 32

    # Qdrant
    qdrant_collection_name: str = "code_embeddings"
    qdrant_shard_count: int = 1

    # Kùzu
    kuzu_db_path: str

    # 공통
    max_parallel_repos: int = 4
    max_parallel_jobs_per_repo: int = 2

    # Delta 정책
    enable_delta_indexing: bool = True
    full_reindex_on_schema_change: bool = True

    # Namespace/브랜치
    index_namespace: str = "default"  # e.g. "main", "feature/xyz"
```

# 5. 전체 인덱싱 플로우

Indexing Layer는 Full Indexing과 Delta Indexing 두 모드를 기본으로 지원하며, 이 둘을 실행 단위(IndexingJob/IndexingRun)와 스케줄러가 관리한다.

## 5.1 풀 인덱싱 (Full Indexing)

1. Parser/Chunking/Graph/RepoMap가 선행되어, 전체 CodeNode/Chunk/Graph/Summary가 준비된 상태
2. IndexingJob(scope=FULL_REPO) 생성
3. ZoektIndexer

   * repo 내 모든 파일을 FileIndexDocument로 변환 → Zoekt 인덱스 생성
4. QdrantIndexer

   * 모든 EmbeddingDocument를 벡터화 후 upsert
5. KuzuIndexer

   * 모든 GraphNodeRecord/GraphEdgeRecord를 upsert
6. IndexingRun에 통계 기록

## 5.2 증분 인덱싱 (Delta Indexing)

1. Chunking에서 ChunkDelta 리스트 생성
2. Graph에서 GraphDelta (optional) 생성
3. IndexingJob(scope=DELTA) 생성
4. Delta 처리 로직

   * Zoekt: `source_file_hash` 변경된 파일만 reindex
   * Qdrant: ChunkDelta 기반으로 EmbeddingDocument insert/update/delete
   * Kùzu: GraphDelta 기반으로 edge/node insert/update/delete

## 5.3 Indexing Job Scheduler & Priority Queue 설계

Indexing Job Scheduler는 다양한 소스에서 들어오는 인덱싱 요청을 우선순위에 따라 정렬하고, 병렬 실행 수를 제어한다.

### 5.3.1 Job 소스

* Git 이벤트 (commit/push/merge/rebase)
* CI 파이프라인 (PR 생성/업데이트)
* 수동 트리거 (관리자/운영자)
* 주기적 재인덱싱 (cron 기반)

### 5.3.2 Priority 규칙 예시

* P0: 스키마 변경으로 인한 full_reindex
* P1: main/master 브랜치의 Delta Indexing
* P2: feature 브랜치의 Delta Indexing
* P3: 저우선 백그라운드 재인덱싱 (오래된 namespace 정리 등)

### 5.3.3 Scheduler 동작

* Priority Queue에 IndexingJob enqueue
* `max_parallel_repos`, `max_parallel_jobs_per_repo`를 고려해 pull & 실행
* Job 완료 후 IndexingRun 기록 업데이트

## 5.4 Realtime Indexing 모드 (Event-based)

Realtime Indexing 모드는 Git/IDE 이벤트를 기반으로 **지연 시간이 매우 짧은 Delta Indexing**을 수행하는 모드이다.

### 5.4.1 지원 이벤트

* 파일 저장 (save)
* Git commit
* CI 성공 후 main 브랜치 업데이트

### 5.4.2 동작 원칙

* Realtime 모드는 항상 **Delta Indexing**만 수행
* 동일 파일에 대한 연속 이벤트는 debounce/coalesce하여 묶어서 처리 (예: 1~5초 윈도우)
* 대량 변경이 감지되면 Realtime 모드에서 배치 모드로 전환 (PR 단위 처리)

---

# 6. Zoekt 인덱싱 설계

## 6.1 인덱싱 단위

* Zoekt는 파일 단위 인덱싱이 기본이므로, Semantica는 **파일 단위**로 Zoekt를 사용함
* Chunk 단위 검색은 Retriever에서 Zoekt 결과 + Chunk 메타를 조합하는 방식으로 구현

## 6.2 Zoekt 스키마 매핑

FileIndexDocument → Zoekt:

* repo: repo_id
* file: file_path
* content: text
* language: language
* metadata: branch, namespace, source_file_hash 등

## 6.3 Zoekt Delta 전략

* 파일 내용 해시(`source_file_hash`)가 변경된 파일만 재인덱싱
* 삭제된 파일은 Zoekt repo에서 제거
* 새 파일은 추가

# 7. Qdrant 인덱싱 설계

## 7.1 컬렉션 구조

* collection: `code_embeddings`
* id: EmbeddingDocument.id
* vector: text_for_embedding 임베딩 결과
* payload 예시

```json
{
  "repo_id": "repo-123",
  "ref_type": "parent",
  "ref_id": "parent-abc",
  "embedding_purpose": "summary",
  "language": "python",
  "file_path": "app/service.py",
  "importance_score": 0.8
}
```

## 7.2 Delta 반영

* ChunkDelta.operation == INSERT → upsert
* UPDATE → upsert (payload/벡터 갱신)
* DELETE → delete_by_id

# 8. Kùzu 인덱싱 설계

## 8.1 그래프 스키마

* Node 테이블: `nodes(id, repo_id, kind, attrs_json)`
* Edge 테이블: `edges(id, repo_id, src_id, dst_id, edge_type, attrs_json)`

## 8.2 Delta 반영

* 새로운 GraphNodeRecord/GraphEdgeRecord → insert
* 변경된 레코드 → update
* 삭제된 레코드 → delete

# 9. 성능 및 안정성 전략

## 9.1 병렬 처리

* repo 단위 병렬: `max_parallel_repos`
* repo 내부 파일/청크 단위 병렬: `max_parallel_jobs_per_repo`

## 9.2 배치 크기 조정

* Qdrant upsert는 벡터 배치 단위로 수행 (예: 128~512개)
* Zoekt는 파일 묶음 단위로 처리

## 9.3 장애 대응

* IndexingRun.status = "partial" 상태 허용
* 실패한 job만 재시도 가능
* full_reindex_on_schema_change == True이면, 스키마 변경 시 전체 재인덱싱 수행

# 10. Observability

Indexing Layer는 성능/안정성/품질을 모니터링하기 위해 표준화된 메트릭과 JSON 기반 IndexingRun 리포트 포맷을 제공해야 한다.

## 10.1 메트릭 종류

* 인덱싱 시간 지표

  * `indexing_time_per_repo`
  * `indexing_time_per_backend` (Zoekt/Qdrant/Kùzu)
* 데이터량 지표

  * `files_indexed`
  * `chunks_indexed`
  * `vectors_indexed`
  * `edges_indexed`
* 오류 지표

  * `indexing_failures_total`
  * `backend_error_rate`
* Delta 품질 지표

  * `chunks_delta_ratio` (전체 청크 대비 Delta 대상 비율)

## 10.2 IndexingRun 메트릭 JSON 포맷 (표준)

IndexingRun.stats는 아래와 같은 JSON 스키마를 따른다.

```json
{
  "repo_id": "repo-123",
  "namespace": "main",
  "scope": "delta",
  "started_at": "2025-11-23T10:15:00Z",
  "finished_at": "2025-11-23T10:15:02Z",
  "duration_ms": 2150,
  "backends": {
    "zoekt": {
      "files_indexed": 12,
      "duration_ms": 430
    },
    "qdrant": {
      "vectors_upserted": 48,
      "duration_ms": 1280
    },
    "kuzu": {
      "nodes_updated": 10,
      "edges_updated": 22,
      "duration_ms": 340
    }
  },
  "delta": {
    "chunks_total": 1200,
    "chunks_affected": 60,
    "chunks_delta_ratio": 0.05
  },
  "status": "success",
  "error": null
}
```

이 JSON 포맷을 고정함으로써, 대시보드/알림/로그 수집 시스템에서 IndexingRun의 상태를 일관성 있게 파싱할 수 있다.

---

# 11. Git 및 공동편집 대응 전략

Indexing Layer는 실제 코드베이스의 변경이 **Git 이벤트**와 **공동편집(소스 공유·Cloud IDE·동시 작성)**에서 발생함을 고려하여 아래 기능들을 지원해야 함.

Indexing Layer는 실제 코드베이스의 변경이 **Git 이벤트**와 **공동편집(소스 공유·Cloud IDE·동시 작성)**에서 발생함을 고려하여 아래 기능들을 지원해야 함.

## 12.1 Git 이벤트 기반 인덱싱 트리거

Indexing Layer는 Git 이벤트를 통해 증분 인덱싱을 자동으로 트리거할 수 있어야 한다.

### 지원해야 할 Git 이벤트

* `commit` (단일 파일 변경 감지)
* `push` (브랜치 단위 변경)
* `merge` (두 브랜치의 변경 병합)
* `rebase` (히스토리 재작성)
* `checkout` / `switch` (브랜치 변경)
* `pull` (원격 변경 서빙)

### 처리 규칙

* commit/push: 해당 파일 리스트만 Delta Indexing
* merge: 양 브랜치의 파일 해시 비교 후 Delta Indexing
* rebase: generation_run_id 비교 → 전체 재인덱싱 여부 결정
* checkout: namespace(브랜치)별 별도 인덱스 유지

---

## 12.2 Branch / Namespace 격리 인덱싱

Indexing Layer는 다음 구조를 지원해야 함.

### 1) 브랜치 단위 인덱스

```
index_namespace = "main"
index_namespace = "feature/payment-refactor"
```

각 namespace는 Zoekt/Qdrant/Kùzu에서 **독립된 인덱스 공간**을 사용한다.

### 2) 브랜치 간 인덱스 재사용 전략

* 공통된 파일 해시가 동일하면, 기존 인덱스를 **복사(copy-on-write)**하여 빠르게 생성
* 브랜치 생성 시 전체 재인덱싱 금지

---

## 12.3 Collaborative Editing (공동편집) 대응

VSCode LiveShare, JetBrains Code With Me, GitHub Codespaces 등에서 동시에 파일이 수정될 수 있으므로 아래 상황을 지원해야 함.

### 1) 실시간 편집 버퍼는 즉시 인덱싱하지 않음

* 실시간 편집 중인 ephemeral buffer는 인덱싱 금지
* 저장(`save`) 또는 버전 스냅샷 단위로만 인덱싱

### 2) "file saved" 이벤트 기반 Delta Indexing

* 실시간 diff가 아닌, 저장 시점 스냅샷 기반으로 FileIndexDocument 갱신
* Zoekt/Qdrant/Kùzu 모두 변경된 파일만 업데이트

### 3) 충돌 상태(conflict) 처리

* Git conflict 상태에서는 인덱싱 중단
* conflict 해결 후 자동 재시작

### 4) Codespaces/JetBrains Gateway 등 원격 IDE 환경 지원

* 원격 환경에서도 동일한 IndexingConfig 정책 적용

---

## 12.4 Monorepo 및 Submodule 대응

### 1) Submodule은 repo_id 기준으로 별도 인덱스 분리

* submodule 내부는 독립 repo로 간주

### 2) Monorepo는 path prefix 기반 sharding

```
repo_id = global-repo
module_id = global-repo://packages/auth-service
```

* Zoekt shard / Qdrant payload / Kùzu 노드 모두 동일 prefix 규칙 적용

### 3) Partial checkout 대응

* Git sparse checkout 환경에서도 변경된 경로만 Delta Indexing

---

## 12.5 CI 연동 (GitHub Actions / GitLab CI / pre-commit)

Indexing Layer는 Git/CI 파이프라인과 자연스럽게 통합되어야 하며, 다음과 같은 연동 포인트를 갖는다.

### 1) GitHub Actions / GitLab CI 파이프라인 연동

* `push` / `merge_request` / `pull_request` 이벤트에서 IndexingJob 트리거
* 예시 워크플로우 단계:

  1. 코드 체크아웃
  2. 변경 파일 목록 추출 (`git diff --name-only origin/main...HEAD`)
  3. 변경 파일 리스트를 포함한 IndexingJob(scope=DELTA) 생성
  4. IndexingRun 완료 후, 요약 리포트(인덱싱 시간, 파일 수, 실패 여부)를 CI 로그에 출력

### 2) pre-commit / pre-push hook 기반 Delta 캐시

* 개발자 로컬 환경에서 pre-commit hook으로 변경 파일 목록을 미리 계산하여 캐싱
* 이 캐시를 CI 파이프라인에서 재활용하여, Delta Indexing 대상 파일을 빠르게 결정

예시:

* `.git/hooks/pre-commit` 에서 변경 파일 목록을 JSON으로 저장 (`.semantica/delta_files.json`)
* CI에서 해당 파일을 읽어 IndexingJob.target_files로 사용

### 3) PR 기반 인덱싱 전략

* 작은 PR: 해당 PR에 포함된 파일만 Delta Indexing
* 대형 PR: 변경 파일 수가 임계치(예: 500개)를 넘으면, 경고를 발생시키고 선택적으로 full_repo 또는 모듈 단위 IndexingJob 실행

---

## 12.6 Local Edit Cache (Cursor-style)

Local Edit Cache는 아직 Git에 커밋되지 않은 로컬 편집 상태를 별도 캐시로 관리하여, **로컬 검색/에이전트 기능**은 최신 상태를 보되, 중앙 인덱스는 안정된 상태만 반영하도록 하는 전략이다.

### 1) 구조

* Central Index: Zoekt/Qdrant/Kùzu에 저장된 안정 인덱스
* Local Edit Cache: IDE/로컬 환경에서만 유지되는 임시 인덱스 (파일 스냅샷 기반)

### 2) 동작 원칙

* 파일 저장 시:

  * Local Edit Cache에 우선 반영
  * Realtime Indexing 정책에 따라 중앙 인덱스로 승격 (옵션)
* 커밋/PR 생성 시:

  * Local Edit Cache 내용과 Git 상태를 동기화

### 3) LLM/Retriever와의 통합

* 검색 시:

  1. Local Edit Cache에서 우선 검색 (가장 최신 상태)
  2. 없으면 Central Index 검색
  3. 결과를 머지하여 최종 컨텍스트를 구성

이로써 Indexing Layer는 Git/CI 이벤트 흐름과 자연스럽게 연결되어, **개발 플로우를 방해하지 않으면서도 최

---

# 10. Delta Processor 명세 (ChunkDelta → Backend Operations 매핑)

Indexing Layer는 ChunkDelta/GraphDelta를 Zoekt, Qdrant, Kùzu의 물리적 인덱스 작업으로 변환해야 한다.
아래 표는 **Semantica의 공식 매핑 테이블**이다.

## 10.1 ChunkDelta → Zoekt/Qdrant/Kùzu 매핑

### 1) INSERT

* Zoekt: 해당 파일 전체 reindex (신규 파일은 add)
* Qdrant: EmbeddingDocument 기반 vector upsert
* Kùzu: GraphNodeRecord + GraphEdgeRecord insert

### 2) UPDATE

* Zoekt: source_file_hash 변경 시 파일 reindex
* Qdrant: 동일 id에 대해 upsert (payload/벡터 갱신)
* Kùzu: node/edge 업데이트 (attrs 반영)

### 3) DELETE

* Zoekt: 해당 파일 삭제
* Qdrant: delete_by_id(ref_id)
* Kùzu: node 및 연결된 edge 삭제

### 4) NOOP

* Zoekt/Qdrant/Kùzu 모두 변경 없음

## 10.2 GraphDelta → Kùzu 매핑

### Edge INSERT

* edges 테이블 insert

### Edge UPDATE

* attrs_json 갱신

### Edge DELETE

* edges.id 기준 삭제

### Node DELETE 시 특수 규칙

* 노드를 삭제할 경우 해당 node_id가 src/dst로 사용된 edge 자동 삭제 (ON DELETE CASCADE)

---

# 11. Index Lifecycle & Garbage Collection 정책

증분 인덱싱/브랜치 격리 환경에서는 오래된 인덱스가 축적되므로 **GC 정책이 필수**이다.

## 11.1 Namespace GC

* 삭제된 브랜치(namespace)의 Zoekt/Qdrant/Kùzu 인덱스 폴더 완전 삭제
* TTL 기반 정책 예:

  * feature 브랜치: 14일 유지
  * release 브랜치: 90일 유지

## 11.2 Orphaned Index Cleanup

ChunkDelta/GraphDelta에 더 이상 참조되지 않는 인덱스는 GC 대상이다.

### Zoekt

* 존재하지 않는 파일 경로의 shard 제거

### Qdrant

* ref_id가 ParentChunk/LeafChunk/EmbeddingDocument에 존재하지 않으면 삭제

### Kùzu

* node_id가 현재 RepoMap/GraphLayer에 없으면 GC

## 11.3 Schema Drift Cleanup

스키마 변경(Chunk/EmbeddingDocument 구조 변경 등)이 감지되면 아래 정책 적용:

* full_reindex_on_schema_change=True 인 경우, 해당 namespace 전체 재인덱싱
* 아니면 변경된 부분만 Delta 기반 부분 재인덱싱

## 11.4 Rebase/Force Push 대비 복구 정책

Git force-push/rebase에서는 HEAD가 과거로 되돌아갈 수 있다.

* generation_run_id 비교로 rollback/reindex 판단
* HEAD 되돌림 시 이전 generation 인덱스를 재활성화하거나 필요 시 재인덱싱

---

# 12. 테스트 시나리오 (Test Scenarios)

Indexing Layer의 안정성·일관성·증분 인덱싱 품질을 보장하기 위해 아래 시나리오들을 MUST 테스트해야 함.

## 12.1 Delta Indexing 시나리오

### 시나리오 A: 파일 한 줄 수정

* 조건: 동일 파일에서 한 줄만 수정
* 입력: `source_file_hash` 변경, 관련 Chunk에 대해 `ChunkDelta = UPDATE`
* 기대 결과:

  * Zoekt: 해당 파일만 재인덱싱
  * Qdrant: 해당 ParentChunk/LeafChunk의 EmbeddingDocument만 재삽입(upsert)
  * Kùzu: 그래프 구조 변화 없으면 변경 없음 (NOOP)

### 시나리오 B: 함수 삭제

* 입력: 특정 함수/클래스가 삭제되어 해당 ParentChunk/LeafChunk에 대한 `ChunkDelta = DELETE`
* 기대 결과:

  * Zoekt: 파일 전체 재인덱싱
  * Qdrant: 해당 ref_id(ParentChunk/LeafChunk) 관련 벡터 삭제
  * Kùzu: 해당 노드 및 연결된 edge 모두 삭제

### 시나리오 C: 신규 파일 추가

* 입력: 새 파일 추가, 해당 파일에 대한 `ChunkDelta = INSERT`
* 기대 결과:

  * Zoekt: 새 파일 인덱스 추가
  * Qdrant: 새 ParentChunk/LeafChunk의 EmbeddingDocument 인덱싱
  * Kùzu: 새 노드/엣지 인덱싱

## 12.2 Branch / Namespace 시나리오

### 시나리오 D: feature 브랜치 생성

* 조건: main과 동일한 커밋에서 분기 (파일 해시 동일)
* 기대 결과:

  * index_namespace만 다르고, 인덱스 내용은 copy-on-write로 재사용
  * 추가 인덱싱 작업 거의 없음

### 시나리오 E: 브랜치 전환 (main → feature/payment)

* 기대 결과:

  * index_namespace에 따라 다른 인덱스 세트가 로드
  * 검색 결과가 브랜치별로 명확히 분리됨

## 12.3 Git 이벤트 시나리오

### 시나리오 F: merge

* 상황: main ← feature/payment 머지
* 기대 결과:

  * 공통 파일(내용 동일)은 NOOP
  * 달라진 파일만 Delta Indexing
  * 충돌(conflict) 발생 시, conflict 해제 전까지 인덱싱 중단

### 시나리오 G: rebase

* 상황: feature 브랜치가 main 위로 rebase
* 기대 결과:

  * generation_run_id / commit hash 비교로 full reindex 필요 여부 판정
  * 필요 시 해당 브랜치 인덱스만 재생성

## 12.4 CI 연동 시나리오

### 시나리오 H: PR 생성 (변경 3개 파일)

* CI → `IndexingJob(scope=DELTA, target_files=[3개 파일])`
* 기대 결과:

  * Delta Indexing 후, IndexingRun에 인덱싱 시간/파일 수/상태 기록
  * CI 로그에 요약 리포트 출력

### 시나리오 I: 대형 PR (1000개 파일 변경)

* 기대 결과:

  * 변경 파일 수가 임계치(예: 500)를 초과하면 경고 발생
  * 정책에 따라 모듈 단위 또는 repo 단위 full indexing 전환

## 12.5 공동편집 시나리오

### 시나리오 J: LiveShare에서 실시간 편집

* 조건: 동일 파일을 여러 사용자가 동시에 편집
* 기대 결과:

  * 저장 전에는 인덱싱 발생 X
  * 저장 시점의 snapshot 기준으로만 Delta Indexing 수행

### 시나리오 K: conflict 발생

* 조건: Git 머지 시 충돌 발생
* 기대 결과:

  * conflict 상태에서는 인덱싱 중단
  * conflict 해결 커밋 이후에만 Delta Indexing 재개

## 12.6 실패 복구 시나리오

### 시나리오 L: Qdrant upsert 장애

* 상황: 벡터 upsert 중 네트워크/백엔드 오류
* 기대 결과:

  * IndexingRun.status = "partial"
  * 실패한 배치만 재시도 (idempotent upsert)

### 시나리오 M: Zoekt shard 손상

* 상황: Zoekt shard 파일 손상/삭제
* 기대 결과:

  * full_reindex_on_schema_change 규칙에 따라 해당 shard 대상 full reindex 수행

---

# 13. 요약

Indexing Layer는 Semantica v2에서

* Zoekt (텍스트)
* Qdrant (벡터)
* Kùzu (그래프)

세 가지 인덱스 백엔드를 통합 관리하는 실행 계층으로,
Chunking/Graph/RepoMap에서 생산한 의미 구조를 **검색 가능한 형태로 영속화**하는 역할을 담당한다.

이를 통해 Retriever/Agent Layer는 고비용 연산 없이, 각 시나리오에 적합한 인덱스를 조합해 고품질 검색·편집 기능을 제공할 수 있다.
