# Semantica v2: Indexing Layer Architecture (인덱싱 레이어 아키텍처)

# 0. 위치 및 역할 개요

Semantica v2 엔진은 총 7단계 파이프라인으로 구성되며, Indexing Layer는 그 중 **4단계**에 해당함.

| 단계 | 레이어명                | 핵심 역할                                | 주요 산출물                                                |
| -- | ------------------- | ------------------------------------ | ----------------------------------------------------- |
| 1  | Parser              | 코드 파싱 → CodeNode                     | CodeNode, AST                                         |
| 2  | Chunking            | CodeNode → Chunk/Embedding/Delta     | LeafChunk, ParentChunk, EmbeddingDocument, ChunkDelta |
| 3  | Graph Construction  | 호출·참조·정의 그래프 생성                      | GraphEdge (calls, contains, imports, overrides)       |
| 4  | **Indexing** (본 문서) | 텍스트·벡터·그래프 인덱싱 및 증분 업데이트             | Zoekt, Qdrant, Kùzu 인덱스 상태                            |
| 5  | RepoMap             | 코드베이스 구조 요약 / 중요도 계산                 | ProjectMap, File/Module/Repo Summary                  |
| 6  | Retriever           | Hybrid 검색 + Rerank + Context Builder | SearchResults, ContextBundle                          |
| 7  | Agent               | 코드 편집·리팩토링·자동화 실행                    | Patch, ToolCall, Plan                                 |

Indexing Layer는 상위 레이어(Chunking, Graph, RepoMap)가 만들어낸 도메인 객체와 Delta 정보를 기반으로, **Zoekt / Qdrant / Kùzu** 세 가지 저장소에 대한 인덱스를 관리하는 실행 계층이다.

---

# 1. 설계 목표 및 원칙

## 1.0 구현 범위 명시 (v1 vs 확장)

본 문서는 **Indexing Layer 전체 아키텍처**를 정의하지만, 실제 구현은 단계적으로 진행함.

### v1 코어 구현 범위 (MUST)

* 0–5.2: 기본 Indexing 플로우 (Full/Delta), 도메인 모델, IndexingConfig, Job/Run
* 6–8: Zoekt / Qdrant / Kùzu 기본 인덱싱/델타 연동
* 9: 최소 수준의 병렬 처리·장애 대응
* 10: 기본 Observability (메트릭 + IndexingRun JSON 포맷)
* 11: Delta Processor 구체적 알고리즘 (파일 단위 병합, 멱등성 보장)
* 12: Index Lifecycle & GC (Namespace GC, Orphaned Index Cleanup)
* 13.1–13.2: Git 이벤트 트리거 + Branch/Namespace 격리
* 14.1–14.3: 핵심 Delta/Git 시나리오 테스트 (정량적 검증 기준 포함)
* 15: 성능 목표 및 SLA 정의

### v1에서 **설계만 하고 구현은 보류(EXT)**

* 5.3–5.4: 고급 스케줄러/Realtime 모드 (필요 시 Hook만 정의)
* 13.3–13.6: CI 연동, 공동편집, Local Edit Cache (인터페이스만 정의)
* 14.4–14.6: 고급 시나리오 (대형 PR, 공동편집, 실패 복구 상세)
* 16 전체: Enterprise Extensions (확장 기능 전용)

→ 구현 시점에는 "v1 MUST" 항목만을 필수 구현 대상으로 삼고, 나머지는 **확장 가능성을 깨뜨리지 않는 선에서 인터페이스와 구조만 유지**하는 것을 원칙으로 함.

---

## 1.1 설계 목표

1. **증분 인덱싱 최적화**
   * Chunking Layer가 생성한 `ChunkDelta`를 활용해 변경된 부분만 반영
   * 전체 인덱스 재생성을 최소화

2. **다중 인덱스 백엔드 통합**
   * Zoekt: 파일 단위 텍스트/구조 검색
   * Qdrant: 의미 기반(semantic) 벡터 검색
   * Kùzu: 호출·의존성 그래프 탐색

3. **스키마·백엔드 분리**
   * 도메인 모델(Chunk, EmbeddingDocument, GraphEdge)과 물리 인덱스 스키마(Zoekt/Qdrant/Kùzu)를 분리
   * 백엔드 교체/추가가 가능하도록 모듈화

4. **안정성 및 재현성**
   * `generation_run_id`, `source_file_hash`를 활용해 인덱스 상태를 재현 가능하게 유지
   * 실패 시 롤백·재시도 전략 명시

---

## 1.2 Indexing Layer Responsibilities

Indexing Layer가 반드시 수행해야 하는 책임은 다음과 같다.

1. **Delta 적용**
   * Chunking/Graph/RepoMap에서 전달된 Delta를 Zoekt/Qdrant/Kùzu에 반영
   * insert/update/delete 레벨의 변경만 수행

2. **물리 스키마 매핑**
   * 도메인 객체 → Zoekt/Qdrant/Kùzu 필드로 변환
   * 컬렉션/테이블 설계 및 key 규칙 관리

3. **인덱스 수명 주기 관리**
   * repo 단위 초기 인덱싱 / 전체 재인덱싱
   * branch/namespace 기준 인덱스 분리 (예: main vs feature)
   * 삭제된 repo/branch의 인덱스 클린업

4. **인덱싱 실행 단위 관리**
   * IndexingJob, IndexingRun 개념으로 배치/증분 작업 관리
   * 동시성/병렬성 제어 (파일 단위, repo 단위)

---

## 1.3 Indexing Layer Non‑Responsibilities

Indexing Layer는 아래 기능을 수행하지 않는다.

1. **Chunk/요약 생성**
   * Leaf/Parent Chunk 생성, summary/search_text 생성은 Chunking/RepoMap 책임

2. **그래프 구조 계산**
   * 어떤 관계를 calls/imports/contains로 볼지는 Graph Construction 책임

3. **검색 / 랭킹 / 컨텍스트 조립**
   * 검색 전략, hybrid 가중치, reranker, context assembler는 Retriever 책임

4. **코드 편집/수정 수행**
   * 패치 생성, 리팩토링 플랜, 테스트 실행 등은 Agent Layer 책임

---

# 2. 입력/출력 계약 (Contracts)

## 2.1 입력

Indexing Layer는 다음과 같은 입력을 받는다.

### 1) Chunking Layer

* **LeafChunk**: 코드 블록 단위 청크
* **ParentChunk**: 계층 구조 상위 청크
* **EmbeddingDocument**: 임베딩 대상 문서 (text_for_embedding 포함)
* **ChunkDelta**: insert/update/delete/noop 연산 목록

**중요: Embedding 생성 책임 (v1 정책)**

* **입력 형태**: Chunking Layer는 `text_for_embedding`까지만 생성하여 전달
* **벡터 생성**: Indexing Layer가 LLM Provider를 호출하여 벡터 생성 (`INDEXING_SYNC` 모드)
* **실패 처리**: Exponential backoff + 최대 3회 재시도
* **확장**: v2+에서는 `PRE_INDEXING`, `INDEXING_ASYNC`, `EXTERNAL_SERVICE` 모드 지원 가능 (섹션 16.1 참조)

### 2) Graph Construction Layer

* **GraphEdge**: calls, contains, imports, overrides 등
* **GraphDelta**: (선택) edge insert/update/delete

### 3) RepoMap Layer

* **FileSummary**, **ModuleSummary**, **RepoSummary**
* **ProjectMap**: (선택적으로 인덱싱 대상)

### 4) 환경/설정

* **IndexingConfig**: 백엔드 설정, 병렬 처리 정책
* **RepoConfig**: branch, visibility, 우선순위 등

---

## 2.2 출력

Indexing Layer의 출력은 "저장소 상태"이므로, 주로 외부 인덱스들의 최신 상태와 메타정보이다.

* **Zoekt 인덱스 상태**: repo 단위 파일 인덱스
* **Qdrant 컬렉션 상태**: EmbeddingDocument 기반 벡터 인덱스
* **Kùzu 그래프 스키마 및 데이터**: Node/Edge 인덱스
* **IndexingRun 메타데이터**: 언제 무엇을 얼마나 인덱싱했는지에 대한 로그/리포트

---

# 3. 도메인 모델 (Indexing 전용)

## 3.1 FileIndexDocument (Zoekt용)

Zoekt는 파일 단위 인덱싱이 기본이므로, Semantica 도메인에서는 이를 `FileIndexDocument`로 추상화한다.

```python
class FileIndexDocument(BaseModel):
    id: str                 # repo_id + file_path 해시
    repo_id: str
    file_path: str
    language: str
    namespace: str          # e.g. "main", "feature/xyz"

    text: str               # 파일 전체 텍스트
    source_file_hash: str   # 파일 내용 해시

    metadata: dict[str, Any] = {}
```

---

## 3.2 VectorIndexRecord (Qdrant용)

```python
class VectorIndexRecord(BaseModel):
    id: str                 # EmbeddingDocument.id 재사용
    repo_id: str
    namespace: str          # 브랜치 격리

    vector: list[float]     # 실제 벡터 (LLM 호출 결과)
    payload: dict[str, Any] # EmbeddingDocument.metadata + ref 정보
```

---

## 3.3 GraphIndexRecord (Kùzu용)

```python
class GraphNodeRecord(BaseModel):
    id: str          # node_id 또는 chunk_id
    repo_id: str
    namespace: str   # 브랜치 격리
    kind: str        # file/class/function/chunk 등
    attrs: dict[str, Any] = {}

class GraphEdgeRecord(BaseModel):
    id: str
    repo_id: str
    namespace: str
    src_id: str
    dst_id: str
    edge_type: str   # calls/contains/imports/overrides 등
    attrs: dict[str, Any] = {}
```

---

## 3.4 IndexingJob / IndexingRun / IndexingOperation

```python
class IndexingScope(str, Enum):
    FULL_REPO = "full_repo"
    DELTA = "delta"        # ChunkDelta/GraphDelta 기반
    SINGLE_FILE = "single_file"

class IndexingJob(BaseModel):
    job_id: str
    repo_id: str
    namespace: str         # 브랜치/네임스페이스
    scope: IndexingScope
    target_files: list[str] | None = None
    triggered_by: str      # user, ci, webhook 등
    priority: int = 1      # 0=highest, 3=lowest

class IndexingOperation(BaseModel):
    """개별 인덱싱 작업 (멱등성 보장용)"""
    operation_id: str      # 멱등성 키 (repo_id + target_ref + hash)
    backend: Literal["zoekt", "qdrant", "kuzu"]
    operation_type: str    # "upsert", "delete", "index_file"
    target_ref: str        # file_path, chunk_id, node_id 등
    status: Literal["pending", "success", "failed"]
    retry_count: int = 0
    max_retries: int = 3
    error_message: str | None = None

class IndexingRun(BaseModel):
    run_id: str
    job_id: str
    started_at: datetime
    finished_at: datetime | None = None
    status: Literal["running", "success", "failed", "partial"]
    operations: list[IndexingOperation] = []  # 각 operation 추적
    stats: dict[str, Any] = {}

    def get_failed_operations(self) -> list[IndexingOperation]:
        """재시도 대상 operation 목록"""
        return [op for op in self.operations if op.status == "failed"]
```

---

# 4. IndexingConfig

```python
class ConcurrencyPolicy(BaseModel):
    """동시성 제어 정책 (v1)"""
    file_lock_strategy: Literal["optimistic", "pessimistic"] = "optimistic"
    namespace_isolation_level: Literal["strict", "shared_read"] = "strict"
    conflict_resolution: Literal["queue", "abort", "merge"] = "queue"
    same_file_policy: Literal["last_write_wins", "queue", "error"] = "queue"

class IndexingConfig(BaseModel):
    # Zoekt
    zoekt_repo_root: str
    zoekt_shard_size_mb: int = 128
    zoekt_max_parallel_files: int = 32

    # Qdrant
    qdrant_collection_name: str = "code_embeddings"
    qdrant_shard_count: int = 1
    qdrant_batch_size: int = 256  # upsert 배치 크기

    # Kùzu
    kuzu_db_path: str

    # 공통
    max_parallel_repos: int = 4
    max_parallel_jobs_per_repo: int = 2
    concurrency_policy: ConcurrencyPolicy = ConcurrencyPolicy()

    # Delta 정책
    enable_delta_indexing: bool = True
    full_reindex_on_schema_change: bool = True

    # Namespace/브랜치
    index_namespace: str = "default"  # e.g. "main", "feature/xyz"

    # Embedding (v1)
    embedding_model: str = "text-embedding-3-small"
    embedding_max_retries: int = 3
    embedding_timeout_seconds: int = 30
```

---

# 5. 전체 인덱싱 플로우

Indexing Layer는 Full Indexing과 Delta Indexing 두 모드를 기본으로 지원하며, 이 둘을 실행 단위(IndexingJob/IndexingRun)와 스케줄러가 관리한다.

## 5.1 풀 인덱싱 (Full Indexing)

1. Parser/Chunking/Graph/RepoMap가 선행되어, 전체 CodeNode/Chunk/Graph/Summary가 준비된 상태
2. `IndexingJob(scope=FULL_REPO, namespace="main")` 생성
3. **ZoektIndexer**
   * repo 내 모든 파일을 FileIndexDocument로 변환 → Zoekt 인덱스 생성
4. **QdrantIndexer**
   * 모든 EmbeddingDocument의 text_for_embedding을 LLM에 전달 → 벡터 생성
   * 벡터를 배치 단위(256개)로 upsert
5. **KuzuIndexer**
   * 모든 GraphNodeRecord/GraphEdgeRecord를 upsert
6. IndexingRun에 통계 기록 (IndexingOperation별 상태 추적)

---

## 5.2 증분 인덱싱 (Delta Indexing)

1. Chunking에서 ChunkDelta 리스트 생성
2. Graph에서 GraphDelta (optional) 생성
3. `IndexingJob(scope=DELTA, namespace="main")` 생성
4. **Delta 처리 로직** (섹션 11 참조)
   * Zoekt: `source_file_hash` 변경된 파일만 reindex
   * Qdrant: ChunkDelta 기반으로 EmbeddingDocument insert/update/delete
   * Kùzu: GraphDelta 기반으로 edge/node insert/update/delete
5. IndexingOperation별로 멱등성 보장 (operation_id 기반)

---

## 5.3 Indexing Job Scheduler & Priority Queue 설계

**v1 구현 범위**: 기본 Priority Queue + 병렬 처리 제어만 구현
**v2+ 확장**: 고급 스케줄러, Resource-aware throttling (섹션 16.3 참조)

### 5.3.1 Job 소스

* Git 이벤트 (commit/push/merge/rebase)
* CI 파이프라인 (PR 생성/업데이트)
* 수동 트리거 (관리자/운영자)
* 주기적 재인덱싱 (cron 기반)

### 5.3.2 Priority 규칙 예시

* P0: 스키마 변경으로 인한 full_reindex
* P1: main/master 브랜치의 Delta Indexing
* P2: feature 브랜치의 Delta Indexing
* P3: 저우선 백그라운드 재인덱싱 (오래된 namespace 정리 등)

### 5.3.3 Scheduler 동작 (v1)

* Priority Queue에 IndexingJob enqueue
* `max_parallel_repos`, `max_parallel_jobs_per_repo`를 고려해 pull & 실행
* Job 완료 후 IndexingRun 기록 업데이트

---

## 5.4 Realtime Indexing 모드 (Event-based)

**v1 구현 범위**: 설계만 정의, Hook 인터페이스만 유지
**v2+ 구현**: 실제 Realtime 모드 구현

Realtime Indexing 모드는 Git/IDE 이벤트를 기반으로 **지연 시간이 매우 짧은 Delta Indexing**을 수행하는 모드이다.

### 5.4.1 지원 이벤트

* 파일 저장 (save)
* Git commit
* CI 성공 후 main 브랜치 업데이트

### 5.4.2 동작 원칙

* Realtime 모드는 항상 **Delta Indexing**만 수행
* 동일 파일에 대한 연속 이벤트는 debounce/coalesce하여 묶어서 처리 (예: 1~5초 윈도우)
* 대량 변경이 감지되면 Realtime 모드에서 배치 모드로 전환 (PR 단위 처리)

---

# 6. Zoekt 인덱싱 설계

## 6.1 인덱싱 단위

* Zoekt는 파일 단위 인덱싱이 기본이므로, Semantica는 **파일 단위**로 Zoekt를 사용함
* Chunk 단위 검색은 Retriever에서 Zoekt 결과 + Chunk 메타를 조합하는 방식으로 구현

---

## 6.2 Zoekt 스키마 매핑

FileIndexDocument → Zoekt:

* repo: `repo_id`
* file: `file_path`
* content: `text`
* language: `language`
* metadata: `namespace`, `source_file_hash` 등

---

## 6.3 Zoekt Namespace 격리 전략 (v1)

### Namespace별 별도 Shard 생성

각 namespace는 독립된 Zoekt shard로 관리:

```
{zoekt_repo_root}/main_{repo_id}.zoekt
{zoekt_repo_root}/feature-payment_{repo_id}.zoekt
```

**장점**: 브랜치 간 완전 격리, GC 단순화
**단점**: 공통 파일 중복 저장 (v2+에서 CoW 최적화 고려)

---

## 6.4 Zoekt Delta 전략

* 파일 내용 해시(`source_file_hash`)가 변경된 파일만 재인덱싱
* 삭제된 파일은 Zoekt repo에서 제거
* 새 파일은 추가

---

# 7. Qdrant 인덱싱 설계

## 7.1 컬렉션 구조

### Namespace별 별도 Collection 생성 (v1)

```
code_embeddings_main
code_embeddings_feature_payment
```

* **id**: EmbeddingDocument.id
* **vector**: text_for_embedding 임베딩 결과 (OpenAI API 호출)
* **payload** 예시:

```json
{
  "repo_id": "repo-123",
  "namespace": "main",
  "ref_type": "parent",
  "ref_id": "parent-abc",
  "embedding_purpose": "summary",
  "language": "python",
  "file_path": "app/service.py",
  "importance_score": 0.8,
  "model_id": "text-embedding-3-small"
}
```

---

## 7.2 Delta 반영

* `ChunkDelta.operation == INSERT` → upsert (벡터 생성 후)
* `UPDATE` → upsert (payload/벡터 갱신)
* `DELETE` → delete_by_id

---

## 7.3 Embedding 생성 흐름 (v1)

1. ChunkDelta → EmbeddingDocument 추출
2. `text_for_embedding`을 LLM Provider에 전달
3. 벡터 응답 받음
4. VectorIndexRecord 생성
5. Qdrant upsert (배치 단위)

**실패 처리**:
* Exponential backoff (1초, 2초, 4초)
* 최대 3회 재시도
* 재시도 실패 시 IndexingOperation.status = "failed"

---

# 8. Kùzu 인덱싱 설계

## 8.1 그래프 스키마

```sql
-- Node 테이블
CREATE NODE TABLE nodes (
    id STRING PRIMARY KEY,
    repo_id STRING,
    namespace STRING,
    kind STRING,
    attrs_json STRING
);

-- Edge 테이블
CREATE REL TABLE edges (
    FROM nodes TO nodes,
    id STRING PRIMARY KEY,
    repo_id STRING,
    namespace STRING,
    edge_type STRING,
    attrs_json STRING
);

-- Namespace별 인덱스
CREATE INDEX ON nodes(namespace);
CREATE INDEX ON edges(namespace);
```

---

## 8.2 Namespace 격리 전략 (v1)

### 단일 DB, 테이블 컬럼 기반 필터링

모든 namespace의 노드/엣지를 동일 테이블에 저장하되, `namespace` 컬럼으로 필터링:

```cypher
MATCH (n:nodes {namespace: 'main'})
RETURN n;
```

**장점**: 단일 DB 관리, 크로스 브랜치 쿼리 가능
**단점**: 대규모 repo에서 성능 고려 필요

---

## 8.3 Delta 반영

* 새로운 GraphNodeRecord/GraphEdgeRecord → insert
* 변경된 레코드 → update (attrs_json)
* 삭제된 레코드 → delete (ON DELETE CASCADE로 관련 edge 자동 삭제)

---

# 9. 성능 및 안정성 전략

## 9.1 병렬 처리

* repo 단위 병렬: `max_parallel_repos`
* repo 내부 파일/청크 단위 병렬: `max_parallel_jobs_per_repo`
* 동시성 제어: ConcurrencyPolicy 기반

---

## 9.2 배치 크기 조정

* Qdrant upsert는 벡터 배치 단위로 수행 (기본 256개)
* Zoekt는 파일 묶음 단위로 처리 (max_parallel_files)
* Kùzu는 bulk insert API 사용

---

## 9.3 장애 대응

* IndexingRun.status = "partial" 상태 허용
* 실패한 IndexingOperation만 재시도 (멱등성 보장)
* `full_reindex_on_schema_change == True`이면, 스키마 변경 시 전체 재인덱싱 수행

---

# 10. Observability

Indexing Layer는 성능/안정성/품질을 모니터링하기 위해 표준화된 메트릭과 JSON 기반 IndexingRun 리포트 포맷을 제공해야 한다.

## 10.1 메트릭 종류

### 인덱싱 시간 지표

* `indexing_time_per_repo` (ms)
* `indexing_time_per_backend` (Zoekt/Qdrant/Kùzu)

### 데이터량 지표

* `files_indexed`
* `chunks_indexed`
* `vectors_indexed`
* `edges_indexed`

### 오류 지표

* `indexing_failures_total`
* `backend_error_rate`
* `embedding_api_errors`

### Delta 품질 지표

* `chunks_delta_ratio` (전체 청크 대비 Delta 대상 비율)
* `delta_efficiency` = (Delta 시간) / (Full Reindex 시간)

---

## 10.2 IndexingRun 메트릭 JSON 포맷 (표준)

IndexingRun.stats는 아래 Pydantic 모델을 따른다.

```python
class BackendStats(BaseModel):
    files_indexed: int = 0
    vectors_upserted: int = 0
    nodes_updated: int = 0
    edges_updated: int = 0
    duration_ms: int
    errors: int = 0

class DeltaStats(BaseModel):
    chunks_total: int
    chunks_affected: int
    chunks_delta_ratio: float  # chunks_affected / chunks_total

class IndexingRunStats(BaseModel):
    """IndexingRun.stats의 표준 스키마"""
    repo_id: str
    namespace: str
    scope: IndexingScope
    started_at: datetime
    finished_at: datetime | None = None  # 실행 중이면 None
    duration_ms: int | None = None

    backends: dict[str, BackendStats]  # "zoekt", "qdrant", "kuzu"
    delta: DeltaStats | None = None    # Full indexing이면 None

    status: Literal["running", "success", "failed", "partial"]
    error: str | None = None

    model_config = ConfigDict(
        json_schema_extra={
            "examples": [{
                "repo_id": "repo-123",
                "namespace": "main",
                "scope": "delta",
                "started_at": "2025-11-23T10:15:00Z",
                "finished_at": "2025-11-23T10:15:02Z",
                "duration_ms": 2150,
                "backends": {
                    "zoekt": {"files_indexed": 12, "duration_ms": 430, "errors": 0},
                    "qdrant": {"vectors_upserted": 48, "duration_ms": 1280, "errors": 0},
                    "kuzu": {"nodes_updated": 10, "edges_updated": 22, "duration_ms": 340, "errors": 0}
                },
                "delta": {
                    "chunks_total": 1200,
                    "chunks_affected": 60,
                    "chunks_delta_ratio": 0.05
                },
                "status": "success",
                "error": None
            }]
        }
    )
```

이 JSON 포맷을 고정함으로써, 대시보드/알림/로그 수집 시스템에서 IndexingRun의 상태를 일관성 있게 파싱할 수 있다.

---

# 11. Delta Processor 명세 (ChunkDelta → Backend Operations 매핑)

Indexing Layer는 ChunkDelta/GraphDelta를 Zoekt, Qdrant, Kùzu의 물리적 인덱스 작업으로 변환해야 한다.

## 11.1 Delta Processor 구체적 알고리즘

### 핵심 원칙

1. **파일 단위 병합**: 동일 파일에 대한 여러 ChunkDelta는 파일 단위로 병합
2. **멱등성 보장**: operation_id 기반으로 중복 실행 방지
3. **순서 보장**: DELETE → UPDATE → INSERT 순서로 처리

---

### 알고리즘 의사코드

```python
class DeltaProcessor:
    def process_deltas(
        self,
        chunk_deltas: list[ChunkDelta],
        graph_deltas: list[GraphDelta]
    ) -> list[IndexingOperation]:
        """ChunkDelta → IndexingOperation 변환"""

        operations = []

        # 1. 파일 단위로 ChunkDelta 그룹화
        file_groups = self._group_by_file(chunk_deltas)

        for file_path, deltas in file_groups.items():
            # 2. 파일 레벨 변경 감지
            file_op = self._merge_file_deltas(file_path, deltas)

            # 3. Zoekt: 파일 단위 operation 생성
            if file_op.needs_reindex:
                operations.append(IndexingOperation(
                    operation_id=f"zoekt:{file_op.file_hash}",
                    backend="zoekt",
                    operation_type="index_file",
                    target_ref=file_path,
                    status="pending"
                ))

            # 4. Qdrant: 청크 단위 operation 생성
            for delta in deltas:
                if delta.operation == DeltaOperation.DELETE:
                    operations.append(IndexingOperation(
                        operation_id=f"qdrant:{delta.ref_id}",
                        backend="qdrant",
                        operation_type="delete",
                        target_ref=delta.ref_id,
                        status="pending"
                    ))
                elif delta.operation in [DeltaOperation.INSERT, DeltaOperation.UPDATE]:
                    operations.append(IndexingOperation(
                        operation_id=f"qdrant:{delta.ref_id}:{delta.content_hash}",
                        backend="qdrant",
                        operation_type="upsert",
                        target_ref=delta.ref_id,
                        status="pending"
                    ))

        # 5. Kùzu: GraphDelta 처리
        for graph_delta in graph_deltas:
            operations.append(self._create_graph_operation(graph_delta))

        return operations

    def _merge_file_deltas(
        self,
        file_path: str,
        deltas: list[ChunkDelta]
    ) -> FileOperation:
        """동일 파일 내 여러 청크 변경 → 파일 단위로 병합"""

        # 파일 전체 삭제 여부 확인
        if self._is_entire_file_deleted(deltas):
            return FileOperation(
                file_path=file_path,
                operation_type="delete",
                needs_reindex=True
            )

        # 파일 내용 변경 여부 확인 (source_file_hash 비교)
        current_hash = self._get_file_hash(file_path)
        previous_hash = self._get_previous_hash(file_path)

        if current_hash != previous_hash:
            return FileOperation(
                file_path=file_path,
                operation_type="reindex",
                needs_reindex=True,
                file_hash=current_hash
            )

        return FileOperation(
            file_path=file_path,
            operation_type="noop",
            needs_reindex=False
        )
```

---

## 11.2 ChunkDelta → Zoekt/Qdrant/Kùzu 매핑

### 1) INSERT

* **Zoekt**: 해당 파일 전체 reindex (신규 파일은 add)
* **Qdrant**:
  1. text_for_embedding → LLM 호출 → 벡터 생성
  2. VectorIndexRecord upsert
* **Kùzu**: GraphNodeRecord + GraphEdgeRecord insert

### 2) UPDATE

* **Zoekt**: `source_file_hash` 변경 시 파일 reindex (변경 없으면 NOOP)
* **Qdrant**:
  1. 동일 id에 대해 벡터 재생성
  2. upsert (payload/벡터 갱신)
* **Kùzu**: node/edge 업데이트 (attrs 반영)

### 3) DELETE

* **Zoekt**: 해당 파일 삭제 (파일 전체 삭제 시만)
* **Qdrant**: `delete_by_id(ref_id)`
* **Kùzu**: node 및 연결된 edge 삭제 (ON DELETE CASCADE)

### 4) NOOP

* **Zoekt/Qdrant/Kùzu**: 모두 변경 없음

---

## 11.3 GraphDelta → Kùzu 매핑

### Edge INSERT

```sql
INSERT INTO edges (id, repo_id, namespace, src_id, dst_id, edge_type, attrs_json)
VALUES (...);
```

### Edge UPDATE

```sql
UPDATE edges SET attrs_json = '{...}' WHERE id = '...';
```

### Edge DELETE

```sql
DELETE FROM edges WHERE id = '...';
```

### Node DELETE 시 특수 규칙

노드를 삭제할 경우 해당 node_id가 src/dst로 사용된 edge 자동 삭제 (ON DELETE CASCADE)

---

# 12. Index Lifecycle & Garbage Collection 정책

증분 인덱싱/브랜치 격리 환경에서는 오래된 인덱스가 축적되므로 **GC 정책이 필수**이다.

## 12.1 Namespace GC (v1 구현)

### 정책

* 삭제된 브랜치(namespace)의 Zoekt/Qdrant/Kùzu 인덱스 완전 삭제
* TTL 기반 정책:
  - feature 브랜치: 14일 유지
  - release 브랜치: 90일 유지
  - main/master: 무기한 유지

### 실행 트리거

* Git 브랜치 삭제 이벤트
* 주기적 GC 작업 (일 1회)

### 구현

```python
class NamespaceGC:
    def cleanup_namespace(self, namespace: str):
        """특정 namespace 인덱스 완전 삭제"""
        # 1. Zoekt shard 삭제
        zoekt_shard_path = f"{zoekt_repo_root}/{namespace}_{repo_id}.zoekt"
        os.remove(zoekt_shard_path)

        # 2. Qdrant collection 삭제
        qdrant_collection = f"code_embeddings_{namespace}"
        qdrant_client.delete_collection(qdrant_collection)

        # 3. Kùzu: namespace 필터링 삭제
        kuzu_conn.execute(f"DELETE FROM nodes WHERE namespace = '{namespace}'")
        kuzu_conn.execute(f"DELETE FROM edges WHERE namespace = '{namespace}'")
```

---

## 12.2 Orphaned Index Cleanup (v1 구현)

ChunkDelta/GraphDelta에 더 이상 참조되지 않는 인덱스는 GC 대상이다.

### Zoekt

* 존재하지 않는 파일 경로의 shard 제거
* 구현: Git에서 삭제된 파일 목록 추출 → Zoekt 인덱스에서 제거

### Qdrant

* `ref_id`가 ParentChunk/LeafChunk/EmbeddingDocument에 존재하지 않으면 삭제
* 구현: 주기적으로 Qdrant의 모든 ID와 DB의 chunk ID 비교 → dangling vector 삭제

### Kùzu

* `node_id`가 현재 RepoMap/GraphLayer에 없으면 GC
* 구현: MATCH 쿼리로 dangling node 탐지 → 삭제

---

## 12.3 Schema Drift Cleanup (v1 설계만, v2+ 구현)

스키마 변경(Chunk/EmbeddingDocument 구조 변경 등)이 감지되면 아래 정책 적용:

* `full_reindex_on_schema_change=True`인 경우, 해당 namespace 전체 재인덱싱
* 아니면 변경된 부분만 Delta 기반 부분 재인덱싱

---

## 12.4 Rebase/Force Push 대비 복구 정책 (v1 설계만)

Git force-push/rebase에서는 HEAD가 과거로 되돌아갈 수 있다.

* `generation_run_id` 비교로 rollback/reindex 판단
* HEAD 되돌림 시 이전 generation 인덱스를 재활성화하거나 필요 시 재인덱싱

---

# 13. Git 및 공동편집 대응 전략

Indexing Layer는 실제 코드베이스의 변경이 **Git 이벤트**와 **공동편집(소스 공유·Cloud IDE·동시 작성)**에서 발생함을 고려하여 아래 기능들을 지원해야 함.

## 13.1 Git 이벤트 기반 인덱싱 트리거 (v1 구현)

Indexing Layer는 Git 이벤트를 통해 증분 인덱싱을 자동으로 트리거할 수 있어야 한다.

### 지원해야 할 Git 이벤트

* `commit` (단일 파일 변경 감지)
* `push` (브랜치 단위 변경)
* `merge` (두 브랜치의 변경 병합)
* `rebase` (히스토리 재작성)
* `checkout` / `switch` (브랜치 변경)
* `pull` (원격 변경 서빙)

### 처리 규칙

* **commit/push**: 해당 파일 리스트만 Delta Indexing
* **merge**: 양 브랜치의 파일 해시 비교 후 Delta Indexing
* **rebase**: generation_run_id 비교 → 전체 재인덱싱 여부 결정
* **checkout**: namespace(브랜치)별 별도 인덱스 유지

---

### Git 이벤트 처리 순서 우선순위 (v1)

| 상태              | 허용 이벤트                      | 차단 이벤트                | 동작                          |
|-------------------|----------------------------------|---------------------------|-------------------------------|
| **Clean**         | commit, push, merge, checkout    | -                         | Delta Indexing 즉시 수행      |
| **Merging**       | merge (완료 시)                  | commit, rebase            | Merge 완료 후 Delta Indexing  |
| **Rebasing**      | rebase (완료 시)                 | commit, merge             | Rebase 완료 후 재인덱싱 판정  |
| **Conflict**      | conflict 해제 후만               | 모든 인덱싱 차단          | Conflict 해결 전까지 대기     |
| **Detached HEAD** | checkout (브랜치로 복귀 시)      | commit, merge             | 경고 발생, 인덱싱 중단        |

---

## 13.2 Branch / Namespace 격리 인덱싱 (v1 구현)

Indexing Layer는 다음 구조를 지원해야 함.

### 1) 브랜치 단위 인덱스

```
index_namespace = "main"
index_namespace = "feature/payment-refactor"
```

각 namespace는 Zoekt/Qdrant/Kùzu에서 **독립된 인덱스 공간**을 사용한다.

---

### 2) Namespace 격리 전략 (v1)

| 백엔드  | 격리 방식                          | 예시                                    | v1 구현 여부 |
|---------|------------------------------------|-----------------------------------------|-------------|
| **Zoekt**   | Shard prefix 분리                  | `main_repo123.zoekt`, `feature_repo123.zoekt` | ✅ MUST     |
| **Qdrant**  | Collection suffix 분리             | `code_embeddings_main`, `code_embeddings_feature` | ✅ MUST     |
| **Kùzu**    | 테이블 컬럼 기반 필터링             | `nodes.namespace = 'main'`              | ✅ MUST     |

---

### 3) 브랜치 간 인덱스 재사용 전략 (v2+ 확장)

* 공통된 파일 해시가 동일하면, 기존 인덱스를 **복사(copy-on-write)**하여 빠르게 생성
* 브랜치 생성 시 전체 재인덱싱 금지

**v1**: 각 namespace는 독립적으로 인덱싱 (중복 허용)
**v2+**: CoW 최적화로 공통 파일 재사용

---

## 13.3 Collaborative Editing (공동편집) 대응 (v1 설계만)

VSCode LiveShare, JetBrains Code With Me, GitHub Codespaces 등에서 동시에 파일이 수정될 수 있으므로 아래 상황을 지원해야 함.

### 1) 실시간 편집 버퍼는 즉시 인덱싱하지 않음

* 실시간 편집 중인 ephemeral buffer는 인덱싱 금지
* 저장(`save`) 또는 버전 스냅샷 단위로만 인덱싱

### 2) "file saved" 이벤트 기반 Delta Indexing

* 실시간 diff가 아닌, 저장 시점 스냅샷 기반으로 FileIndexDocument 갱신
* Zoekt/Qdrant/Kùzu 모두 변경된 파일만 업데이트

### 3) 충돌 상태(conflict) 처리

* Git conflict 상태에서는 인덱싱 중단
* conflict 해결 후 자동 재시작

---

## 13.4 Monorepo 및 Submodule 대응 (v1 설계만)

### 1) Submodule은 repo_id 기준으로 별도 인덱스 분리

* submodule 내부는 독립 repo로 간주

### 2) Monorepo는 path prefix 기반 sharding

```
repo_id = global-repo
module_id = global-repo://packages/auth-service
```

* Zoekt shard / Qdrant payload / Kùzu 노드 모두 동일 prefix 규칙 적용

---

## 13.5 CI 연동 (GitHub Actions / GitLab CI / pre-commit) (v1 설계만)

Indexing Layer는 Git/CI 파이프라인과 자연스럽게 통합되어야 하며, 다음과 같은 연동 포인트를 갖는다.

### 1) GitHub Actions / GitLab CI 파이프라인 연동

* `push` / `merge_request` / `pull_request` 이벤트에서 IndexingJob 트리거
* 예시 워크플로우 단계:
  1. 코드 체크아웃
  2. 변경 파일 목록 추출 (`git diff --name-only origin/main...HEAD`)
  3. 변경 파일 리스트를 포함한 IndexingJob(scope=DELTA) 생성
  4. IndexingRun 완료 후, 요약 리포트를 CI 로그에 출력

### 2) PR 기반 인덱싱 전략

* 작은 PR: 해당 PR에 포함된 파일만 Delta Indexing
* 대형 PR: 변경 파일 수가 임계치(예: 500개)를 넘으면, 경고 발생

---

## 13.6 Local Edit Cache (Cursor-style) (v2+ 확장)

Local Edit Cache는 아직 Git에 커밋되지 않은 로컬 편집 상태를 별도 캐시로 관리하여, **로컬 검색/에이전트 기능**은 최신 상태를 보되, 중앙 인덱스는 안정된 상태만 반영하도록 하는 전략이다.

**v1**: 설계만 정의
**v2+**: 실제 구현

---

# 14. 테스트 시나리오 (Test Scenarios)

Indexing Layer의 안정성·일관성·증분 인덱싱 품질을 보장하기 위해 아래 시나리오들을 MUST 테스트해야 함.

## 14.1 Delta Indexing 시나리오 (v1 MUST)

### 시나리오 A: 파일 한 줄 수정

**조건**: 동일 파일에서 한 줄만 수정 (file.py 10줄 중 1줄 변경)

**입력**:
* `source_file_hash` 변경
* 관련 Chunk에 대해 `ChunkDelta = UPDATE`

**기대 결과** (정량적):
* **Zoekt**: 1개 파일만 reindex (전체 파일 수 불변)
* **Qdrant**: ≤ 2개 벡터 upsert (해당 Leaf + 상위 Parent)
* **Kùzu**: 0개 노드 변경 (구조 동일 시)
* **인덱싱 시간**: < 500ms (baseline 대비 5% 이내)
* **Delta 비율**: `chunks_delta_ratio < 0.01`

---

### 시나리오 B: 함수 삭제

**입력**: 특정 함수/클래스가 삭제되어 해당 ParentChunk/LeafChunk에 대한 `ChunkDelta = DELETE`

**기대 결과** (정량적):
* **Zoekt**: 1개 파일 전체 재인덱싱
* **Qdrant**: 해당 ref_id 관련 벡터 삭제 (1~N개)
* **Kùzu**: 해당 노드 + 연결된 edge 모두 삭제 (≥ 1개 노드, ≥ 0개 edge)
* **인덱싱 시간**: < 1초
* **IndexingOperation.status**: 모두 "success"

---

### 시나리오 C: 신규 파일 추가

**입력**: 새 파일 추가 (100줄), 해당 파일에 대한 `ChunkDelta = INSERT`

**기대 결과** (정량적):
* **Zoekt**: 1개 새 파일 인덱스 추가
* **Qdrant**: N개 벡터 upsert (ParentChunk + LeafChunk 개수만큼)
* **Kùzu**: M개 노드 + K개 엣지 인덱싱 (파일/클래스/함수 구조에 따라)
* **인덱싱 시간**: < 2초 (100줄 기준)
* **Delta 비율**: 신규 파일이므로 N/A

---

## 14.2 Branch / Namespace 시나리오 (v1 MUST)

### 시나리오 D: feature 브랜치 생성

**조건**: main과 동일한 커밋에서 분기 (파일 해시 동일)

**기대 결과**:
* **Zoekt**: 새 shard 생성 (`feature_repo123.zoekt`)
* **Qdrant**: 새 collection 생성 (`code_embeddings_feature`)
* **Kùzu**: 동일 테이블에 namespace='feature' 레코드 추가
* **추가 인덱싱 시간**: < 5초 (v1에서는 중복 인덱싱 허용)

---

### 시나리오 E: 브랜치 전환 (main → feature/payment)

**기대 결과**:
* **검색 쿼리**: namespace 필터링으로 다른 인덱스 세트 로드
* **검색 결과**: 브랜치별로 명확히 분리됨
* **전환 시간**: < 100ms (인덱스 로드 캐싱)

---

## 14.3 Git 이벤트 시나리오 (v1 MUST)

### 시나리오 F: merge

**상황**: main ← feature/payment 머지

**기대 결과**:
* 공통 파일(내용 동일): NOOP (0개 파일 인덱싱)
* 달라진 파일만 Delta Indexing (예: 5개 파일)
* 충돌(conflict) 발생 시: conflict 해제 전까지 인덱싱 중단
* **인덱싱 시간**: < 3초 (5개 파일 기준)

---

### 시나리오 G: rebase

**상황**: feature 브랜치가 main 위로 rebase

**기대 결과**:
* `generation_run_id` / commit hash 비교로 full reindex 필요 여부 판정
* 필요 시 해당 브랜치 인덱스만 재생성 (전체 repo 아님)
* **인덱싱 시간**: < 10초 (1000개 파일 repo 기준)

---

## 14.4 CI 연동 시나리오 (v1 설계만, v2+ 구현)

### 시나리오 H: PR 생성 (변경 3개 파일)

**입력**: CI → `IndexingJob(scope=DELTA, target_files=[3개 파일])`

**기대 결과**:
* Delta Indexing 후, IndexingRun에 인덱싱 시간/파일 수/상태 기록
* CI 로그에 요약 리포트 출력
* **인덱싱 시간**: < 2초

---

### 시나리오 I: 대형 PR (1000개 파일 변경)

**기대 결과**:
* 변경 파일 수가 임계치(예: 500)를 초과하면 경고 발생
* 정책에 따라 모듈 단위 또는 repo 단위 full indexing 전환
* **인덱싱 시간**: < 60초

---

## 14.5 공동편집 시나리오 (v1 설계만)

### 시나리오 J: LiveShare에서 실시간 편집

**조건**: 동일 파일을 여러 사용자가 동시에 편집

**기대 결과**:
* 저장 전에는 인덱싱 발생 X
* 저장 시점의 snapshot 기준으로만 Delta Indexing 수행

---

### 시나리오 K: conflict 발생

**조건**: Git 머지 시 충돌 발생

**기대 결과**:
* conflict 상태에서는 인덱싱 중단
* conflict 해결 커밋 이후에만 Delta Indexing 재개

---

## 14.6 실패 복구 시나리오 (v1 설계만)

### 시나리오 L: Qdrant upsert 장애

**상황**: 벡터 upsert 중 네트워크/백엔드 오류

**기대 결과**:
* IndexingRun.status = "partial"
* 실패한 IndexingOperation만 재시도 (멱등성 보장)
* 최대 3회 재시도 후 실패 시 error_message 기록

---

### 시나리오 M: Zoekt shard 손상

**상황**: Zoekt shard 파일 손상/삭제

**기대 결과**:
* `full_reindex_on_schema_change` 규칙에 따라 해당 shard 대상 full reindex 수행
* **복구 시간**: < 30초 (1000개 파일 repo 기준)

---

# 15. 성능 목표 및 SLA (v1)

Indexing Layer의 성능 목표를 정량적으로 정의하여, 구현 시 벤치마크 기준선으로 활용한다.

## 15.1 성능 목표

| 지표                          | 목표 (v1)            | 측정 방법                     | 우선순위 |
|-------------------------------|----------------------|------------------------------|---------|
| **Full Indexing (10K files)** | < 5분                | E2E 타이머                    | P1      |
| **Delta Indexing (10 files)** | < 5초                | E2E 타이머                    | P0      |
| **Delta Indexing (1 file)**   | < 500ms              | save → 검색 가능까지          | P1      |
| **Qdrant upsert (1K vectors)**| < 2초                | batch upsert 타이머           | P1      |
| **Zoekt file index (100 files)**| < 10초             | shard 생성 타이머             | P2      |
| **Kùzu graph update (1K edges)**| < 1초              | bulk insert 타이머            | P2      |
| **Embedding API 성공률**      | > 99%                | (성공 호출) / (총 호출)       | P0      |
| **Delta 효율성**              | > 20x                | (Full 시간) / (Delta 시간)    | P1      |

---

## 15.2 리소스 제약

* **메모리**: 최대 4GB (인덱싱 프로세스 기준)
* **CPU**: 최대 4 cores 동시 사용
* **디스크 I/O**: 최대 500 MB/s (SSD 기준)
* **네트워크**: Embedding API 호출 최대 10 req/s (rate limit)

---

## 15.3 SLA (Service Level Agreement)

### P0 (Critical)

* **Delta Indexing (1 file)**: 95% 요청이 500ms 이내 완료
* **Embedding API 성공률**: 99% 이상

### P1 (High)

* **Delta Indexing (10 files)**: 95% 요청이 5초 이내 완료
* **Full Indexing (10K files)**: 90% 요청이 5분 이내 완료

### P2 (Medium)

* **Zoekt file index (100 files)**: 90% 요청이 10초 이내 완료

---

## 15.4 성능 테스트 환경

* **Hardware**: MacBook Pro M1, 16GB RAM, 512GB SSD
* **Repo 크기**:
  - Small: 100 files, 10K lines
  - Medium: 1K files, 100K lines
  - Large: 10K files, 1M lines
* **Embedding Model**: text-embedding-3-small (OpenAI)

---

## 15.5 성능 저하 시 대응 절차

1. **90% SLA 미달 시**: 경고 로그 + Slack 알림
2. **80% SLA 미달 시**: 자동 fallback to batch mode (Realtime 모드 비활성화)
3. **70% SLA 미달 시**: 긴급 알림 + 수동 개입 필요

---

# 16. 확장성 및 고급 운영 기능 (Enterprise Extensions)

본 섹션은 Indexing Layer의 코어 요구사항은 아니며, **대규모 저장소 / 엔터프라이즈 환경 / 분산 인프라 운영**을 위한 "향후 확장 기능"을 정의함.

* **v1 구현**: 이 섹션에 정의된 기능들은 **구현 대상이 아님**. 단, 관련 옵션/필드를 추가하는 경우, 향후 이 기능들이 무리 없이 붙을 수 있도록 인터페이스 수준의 확장성만 고려함.
* **v2+ 이후**: 운영 환경과 규모가 커질 때, 여기 정의된 전략들을 단계적으로 구현·활성화하는 것을 목표로 함.

각 기능은 선택적이며, 플러그형 구조로 설계해야 함.

---

## 16.1 임베딩 생성 전략 (Embedding Generation Strategy)

임베딩 생성 위치와 책임을 명확히 하기 위한 전략.

### 정책 옵션

* **PRE_INDEXING**: Chunking Layer에서 생성
* **INDEXING_SYNC**: Indexing 과정에서 동기 벡터 생성 (v1 기본)
* **INDEXING_ASYNC**: Indexing → 큐 → Embedding Worker → Qdrant upsert
* **EXTERNAL_SERVICE**: 독립 Embedding Service (gRPC/HTTP)

### 실패/재시도 정책

* embedding 호출 실패 → exponential backoff + dead-letter queue
* 모델 회전(Model versioning) 지원 → A/B 벡터 coexist 가능하도록 payload에 model_id 포함

---

## 16.2 Multi‑Backend 분산 트랜잭션

Zoekt/Qdrant/Kùzu에 대한 업데이트를 **일관성 있게 Commit**하기 위한 확장 기능.

* **v1**: 백엔드별 독립 업데이트 + 실패 시 재시도/부분 실패 허용 (Partial 상태 허용)
* **v2+**: 2‑Phase Commit 또는 Compensation 기반 트랜잭션 매니저 도입 가능하도록, IndexingRun/BackendOperation 레벨의 추상화 인터페이스만 유지

---

## 16.3 Resource-aware Scheduling & Throttling

대규모 인덱싱/벡터 생성 시 시스템 리소스를 보호하기 위한 계층.

### 기능

* 메모리/CPU pressure 감지 후 batch 크기 자동 축소
* embedding API rate limit 적용
* Disk IO budget 관리로 Zoekt shard 생성 제어

---

## 16.4 인덱스 상태 검증 (Cross‑Backend Health Check)

Zoekt/Qdrant/Kùzu 간 일관성을 검증하는 계층.

### 검증 기준

* backend별 record count 비교
* consistency_ratio > 0.95 유지
* graph nodes vs embedding documents cross-check

---

## 16.5 Backend Optimization Profiles

각 인덱스 백엔드의 고급 튜닝 프로필.

### Qdrant

* Product Quantization 지원
* HNSW 튜닝 (ef/m)
* deleted_threshold 기반 vacuum 정책

### Zoekt

* shard_by_language / shard_by_module
* max_shard_size_mb 기반 자동 분할
* dynamic_sharding

### Kùzu

* edge fanout 최적화
* bulk load 최적화 모드

---

## 16.6 고급 모니터링 및 품질 메트릭

기존 메트릭 대비 더 깊은 운영 레벨 지표.

### 예시

* `zoekt_indexing_latency` (Histogram)
* `qdrant_upsert_throughput` (Gauge)
* `kuzu_query_performance` (Summary)
* `indexing_coverage_ratio`
* `vector_quality_score`
* `cross_backend_consistency`

---

## 16.7 장애 복구 & 재동기화 (Recovery & Resync)

백엔드 실패 또는 데이터 불일치 발생 시 복구 전략.

### 기능

* 실패 지점 식별 → 해당 범위만 재인덱싱
* Kùzu ↔ Qdrant 간 dangling node/vector cleanup
* index_namespace 단위 rollback

---

## 16.8 캐시 계층 (Indexing Cache Layer)

인덱싱 속도를 높이기 위한 다양한 캐시.

* **embedding_cache** (Redis): 동일 문서·동일 모델 ID → cached embedding 재사용
* **delta_cache** (로컬/메모리): NOOP 빠르게 계산
* **metadata_cache** (Redis): FileIndexDocument 메타데이터 캐싱

---

## 16.9 보안 및 접근 제어

네임스페이스별 접근 제어 및 감사 로깅.

### 기능

* cross-namespace 데이터 접근 방지
* 역할 기반 권한 (RBAC)
* IndexingRun 감사 로그

---

## 16.10 배포 및 스케일링 전략

분산 환경에서 Indexing Layer 수평 확장 설정.

### 전략

* shard_by_repo 기반 워커 분배
* leader_election으로 중복 실행 방지
* workload_partitioning으로 대형 인덱싱 부하 분산

---

## 16.11 데이터 보존 및 아카이빙 정책

### 보존 규칙

* active namespace TTL: 설정가능하게
* inactive namespace TTL: 설정가능하게
* 삭제 전 아카이빙 옵션 지원

### 적용

* 오래된 Zoekt shard, Qdrant collection document, Kùzu node 자동 정리

---

# 17. 구현 전 결정 사항 (Decisions)

구현을 시작하기 전에 명확히 해야 할 사항들을 정리한다.

## 17.1 Embedding 모델 버전 관리

**질문**: 임베딩 모델 업데이트 시 기존 벡터를 어떻게 처리?

**결정 (v1)**:
* 모델 변경 시 전체 재인덱싱 (full_reindex_on_schema_change=True)
* payload에 `model_id` 필드 추가하여 버전 추적

**확장 (v2+)**:
* A/B 벡터 coexist (동일 chunk에 대해 여러 모델 벡터 보유)
* 점진적 재인덱싱 (백그라운드 작업)

---

## 17.2 Chunking → Indexing 데이터 전달 방식

**질문**: ChunkDelta를 어떻게 전달?

**결정 (v1)**:
* In-memory 객체 전달 (Pydantic 모델)
* 동일 프로세스 내에서 함수 호출

**확장 (v2+)**:
* Message Queue (RabbitMQ/Kafka) 기반 비동기 전달
* gRPC/HTTP API

---

## 17.3 IndexingRun 메타데이터 저장소

**질문**: IndexingRun을 어디에 저장?

**결정 (v1)**:
* PostgreSQL (relational_store) 활용
* `indexing_runs` 테이블 생성
* IndexingOperation은 JSON 컬럼으로 저장

---

## 17.4 Namespace 삭제 정책

**질문**: feature 브랜치가 merge되면 자동 삭제?

**결정 (v1)**:
* 자동 삭제 안 함 (수동 GC)
* TTL 기반 정책: feature 브랜치 14일 유지 후 GC

**확장 (v2+)**:
* Git 이벤트 기반 자동 삭제 (브랜치 삭제 시)

---

## 17.5 Realtime 모드 기본값

**질문**: v1에서 Realtime 모드 기본 활성화?

**결정 (v1)**:
* 기본 비활성화 (opt-in)
* 설정 파일에서 `enable_realtime_indexing: false`

**이유**: v1에서는 안정성 우선, v2+에서 활성화

---

## 17.6 Concurrency Policy 기본값

**질문**: 동일 파일 동시 인덱싱 시 어떻게 처리?

**결정 (v1)**:
* `same_file_policy: "queue"` (큐에 쌓아서 순차 처리)
* `file_lock_strategy: "optimistic"` (낙관적 잠금)

---

# 18. 요약

확장 기능(Enterprise Extensions)은 대규모 엔터프라이즈 환경에서의 안정성·성능·운영 편의를 강화하기 위한 선택적 모듈로, 코어 Indexing Layer와는 독립적으로 설계되어야 함. 이를 통해 Semantica v2는 소규모 프로젝트부터 초대형 모노레포까지 모두 대응 가능한 유연한 인덱싱 엔진으로 확장 가능하다.

Indexing Layer는 Semantica v2에서:

* **Zoekt** (텍스트)
* **Qdrant** (벡터)
* **Kùzu** (그래프)

세 가지 인덱스 백엔드를 통합 관리하는 실행 계층으로, Chunking/Graph/RepoMap에서 생산한 의미 구조를 **검색 가능한 형태로 영속화**하는 역할을 담당한다.

이를 통해 Retriever/Agent Layer는 고비용 연산 없이, 각 시나리오에 적합한 인덱스를 조합해 고품질 검색·편집 기능을 제공할 수 있다.

---

## 핵심 설계 원칙 (재확인)

1. **증분 인덱싱 우선**: Delta Indexing으로 90% 이상의 인덱싱 작업 처리
2. **멱등성 보장**: IndexingOperation.operation_id 기반 중복 실행 방지
3. **Namespace 격리**: 브랜치별 독립 인덱스 공간 (v1: 중복 허용, v2+: CoW 최적화)
4. **실패 허용**: Partial 상태 허용, 재시도 가능한 구조
5. **확장성**: v1 코어 구현 후, v2+에서 Enterprise Extensions 단계적 추가