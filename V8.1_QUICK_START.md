# v8.1 Quick Start Guide

> **ë¹ ë¥¸ ì‹œì‘**: v8.1 Autonomous Coding Agent 5ë¶„ ì•ˆì— ì‹¤í–‰í•˜ê¸°

## âœ… ì‚¬ì „ ì¤€ë¹„

```bash
# Python 3.12+
python --version

# ì˜ì¡´ì„±
pip install openai langgraph radon pytest python-dotenv
```

## ğŸš€ 30ì´ˆ ì‹¤í–‰

### 1. E2E í…ŒìŠ¤íŠ¸ (ì „ì²´ íŒŒì´í”„ë¼ì¸ ê²€ì¦)

```bash
cd /Users/songmin/Documents/code-jo/semantica-v2/codegraph
python scripts/final_e2e_test.py
```

**ê¸°ëŒ€ ê²°ê³¼**:
```
âœ… Phase 0: Router â†’ fast
âœ… Phase 1: ToT + LLM â†’ 3 strategies
âœ… Phase 2: Reflection â†’ rollback
âœ… Phase 3: Experience â†’ ready
ğŸ‰ Full Pipeline Complete!
Exit Code: 0
```

### 2. Phaseë³„ ê²€ì¦

```bash
# Phase 0: Dynamic Router
python scripts/verify_phase0.py

# Phase 1: Tree-of-Thought
python scripts/verify_phase1_5.py

# Phase 2: Self-Reflection
python scripts/verify_phase2.py

# Phase 3: Experience Store
python scripts/verify_experience_store.py

# LLM Integration
python scripts/verify_llm_integration.py
```

## ğŸ“– ì‚¬ìš© ì˜ˆì œ

### Example 1: System 1/2 ê²°ì •

```python
from src.container import Container

container = Container()
decide_path = container.v8_decide_reasoning_path

# ê°„ë‹¨í•œ ë¬¸ì œ (System 1)
decision = decide_path.execute(
    problem_description="Add logging to service",
    target_files=["service.py"],
    code_snippet="def process(): pass",
)

print(f"Path: {decision.path.value}")  # â†’ "fast" (System 1)
print(f"Confidence: {decision.confidence}")  # â†’ 0.85
```

### Example 2: Tree-of-Thought ì‹¤í–‰

```python
import asyncio
from src.container import Container

async def main():
    container = Container()
    execute_tot = container.v8_execute_tot
    
    result = await execute_tot.execute(
        problem="Fix NullPointerException in login",
        context={
            "code": "def login(user): return user.name.upper()",
            "files": ["auth/service.py"],
        },
        strategy_count=3,
        top_k=2,
    )
    
    print(f"Generated: {result.total_generated}")
    print(f"Best Score: {result.best_score:.2f}")
    
    for strategy in result.ranked_strategies[:2]:
        print(f"\n{strategy.title}")
        print(f"  Type: {strategy.strategy_type.value}")
        print(f"  Confidence: {strategy.llm_confidence:.2f}")

asyncio.run(main())
```

### Example 3: Self-Reflection

```python
from src.container import Container
from src.agent.domain.reasoning import (
    ReflectionInput,
    GraphImpact,
    ExecutionTrace,
)

container = Container()
judge = container.v8_reflection_judge

# High quality change
reflection_input = ReflectionInput(
    original_problem="Add null check",
    strategy_id="strategy_001",
    strategy_description="Add defensive null check",
    graph_impact=GraphImpact(
        cfg_nodes_before=10,
        cfg_nodes_after=12,
        cfg_nodes_added=2,
    ),
    execution_trace=ExecutionTrace(
        coverage_before=0.75,
        coverage_after=0.80,
        new_exceptions=[],
    ),
)

output = judge.judge(reflection_input)

print(f"Verdict: {output.verdict.value}")  # â†’ "accept"
print(f"Confidence: {output.confidence:.2f}")  # â†’ 0.88
print(f"Reasoning: {output.reasoning}")
```

## ğŸ”§ í™˜ê²½ë³€ìˆ˜ ì„¤ì •

### .env íŒŒì¼

```bash
# LLM
SEMANTICA_OPENAI_API_KEY=sk-...
SEMANTICA_LITELLM_MODEL=gpt-4o-mini

# Profile
SEMANTICA_PROFILE=local

# Database (Optional)
DATABASE_URL=postgresql://localhost/semantica_agent
```

### í”„ë¡œê·¸ë˜ë° ë°©ì‹

```python
import os

os.environ["SEMANTICA_OPENAI_API_KEY"] = "sk-..."
os.environ["SEMANTICA_PROFILE"] = "local"
```

## ğŸ“Š ì˜ˆìƒ ì¶œë ¥

### E2E Test ì„±ê³µ ì‹œ

```
================================================================================
ğŸš€ v8.1 Full Pipeline E2E Test
================================================================================

Phase 0: Dynamic Reasoning Router
  Path: fast
  Complexity: 0.05
  Risk: 0.20
  Confidence: 0.80
âœ… PASS

Phase 1: Tree-of-Thought + LLM
  Generated: 3
  Executed: 3
  Best Score: 0.72
  Time: 12.95s
  Best Strategy: "Add Null Check for User in Login Function"
âœ… PASS

Phase 2: Self-Reflection Judge
  Verdict: rollback
  Confidence: 0.00
  Graph Stability: stable
âœ… PASS

Phase 3: Experience Store
  Type: bugfix
  Strategy: direct_fix
  Score: 0.88
âœ… PASS

ğŸ‰ Full Pipeline Complete!
Total: ~13s
Exit Code: 0
```

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. API Key ì˜¤ë¥˜

```
No LLM client, using fallback
```

**í•´ê²°**:
```bash
export SEMANTICA_OPENAI_API_KEY="sk-..."
# ë˜ëŠ” .env íŒŒì¼ ìƒì„±
```

### 2. radon not installed

```
radon not installed, using fallback
```

**í•´ê²°** (Optional):
```bash
pip install radon
```

### 3. PostgreSQL ì—°ê²° ì˜¤ë¥˜

```
PostgreSQL connection failed
```

**í•´ê²°**:
```bash
# Localì—ì„œëŠ” í•„ìˆ˜ ì•„ë‹˜ (Fallback ì‘ë™)
# í•„ìš”ì‹œ:
createdb semantica_agent
```

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„

1. **LLM í™œìš©**: OpenAI API Key ì„¤ì •
2. **DB ì—°ë™**: PostgreSQL Migration
3. **ì‹¤ì œ ì½”ë“œ ìƒì„±**: LLM â†’ Code Diff â†’ Apply

## ğŸ“š ì¶”ê°€ ë¬¸ì„œ

- [ìµœì¢… ì™„ì„± ë³´ê³ ì„œ](_roadmap/V8.1_FINAL_COMPLETION.md)
- [ADR-001: v8 Roadmap](_roadmap/ADR-001-V8-ROADMAP.md)
- [Architecture RFC](_roadmap/Autonomous coding agent - hybrid architecture.md)

---

**5ë¶„ ë§Œì— v8.1 ì‹¤í–‰ ì™„ë£Œ! ğŸ‰**
