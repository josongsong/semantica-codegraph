# Job ê¸°ë°˜ ì¸ë±ì‹± ì‹œìŠ¤í…œ

> Distributed Lock + Job Queue + Idempotent Retries

---

## ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [ì•„í‚¤í…ì²˜](#2-ì•„í‚¤í…ì²˜)
3. [Job ë¼ì´í”„ì‚¬ì´í´](#3-job-ë¼ì´í”„ì‚¬ì´í´)
4. [Distributed Lock](#4-distributed-lock)
5. [Checkpoint & Retry](#5-checkpoint--retry)
6. [Conflict Resolution](#6-conflict-resolution)
7. [ì‚¬ìš© ê°€ì´ë“œ](#7-ì‚¬ìš©-ê°€ì´ë“œ)

---

## 1. ê°œìš”

### ë¬¸ì œ
- ë©€í‹° í”„ë¡œì„¸ìŠ¤ í™˜ê²½ì—ì„œ ë™ì¼ ë ˆí¬ ë™ì‹œ ì¸ë±ì‹± ë°©ì§€
- ì¥ì‹œê°„ ì‘ì—… ì¤‘ ì‹¤íŒ¨ ì‹œ ì²˜ìŒë¶€í„° ì¬ì‹œì‘
- ì¤‘ë³µ ìš”ì²­ ì²˜ë¦¬

### í•´ê²°ì±…
**IndexJobOrchestrator** = Distributed Lock + Job Queue + Checkpoint

### íŠ¹ì§•
```
âœ… Single Writer Guarantee (per repo+snapshot)
âœ… Idempotent Retries (checkpoint ê¸°ë°˜)
âœ… Job Deduplication (SKIP/SUPERSEDE/QUEUE)
âœ… Lock Extension (ì¥ì‹œê°„ ì‘ì—…)
âœ… Observability (metrics + logs)
```

---

## 2. ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ êµ¬ì¡°

```
User/API
    â†“
IndexJobOrchestrator
    â”œâ”€ submit_job() â†’ Job Queue (PostgreSQL)
    â”‚
    â”œâ”€ Worker Pool
    â”‚   â”œâ”€ Worker 1 (acquire lock)
    â”‚   â”œâ”€ Worker 2 (acquire lock)
    â”‚   â””â”€ Worker N (acquire lock)
    â”‚
    â””â”€ execute_job()
        â”œâ”€ DistributedLock (Redis)
        â”‚   â””â”€ Key: "indexing:repo-123:snapshot-456"
        â”‚
        â”œâ”€ IndexingOrchestrator (9-Stage Pipeline)
        â”‚   â”œâ”€ Checkpoint ì €ì¥ (ë§¤ íŒŒì¼)
        â”‚   â””â”€ stop_event ì²´í¬
        â”‚
        â””â”€ Storage
            â”œâ”€ PostgreSQL (metadata, jobs)
            â”œâ”€ Qdrant (vectors)
            â””â”€ Zoekt/Tantivy (lexical)
```

### ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ì—­í•  | ê¸°ìˆ  |
|---------|------|------|
| **Job Queue** | Job ì €ì¥ + ìƒíƒœ ê´€ë¦¬ | PostgreSQL |
| **Distributed Lock** | Single writer ë³´ì¥ | Redis |
| **Checkpoint** | ì§„í–‰ìƒíƒœ ì €ì¥ | PostgreSQL JSONB |
| **ConflictRegistry** | ì¤‘ë³µ ì²˜ë¦¬ | In-memory |
| **Worker** | Job ì‹¤í–‰ | asyncio |

---

## 3. Job ë¼ì´í”„ì‚¬ì´í´

### ìƒíƒœ ì „ì´

```mermaid
stateDiagram-v2
    [*] --> QUEUED: submit_job()

    QUEUED --> RUNNING: acquire lock
    QUEUED --> CANCELLED: conflict (SKIP)
    QUEUED --> SUPERSEDED: conflict (SUPERSEDE)

    RUNNING --> COMPLETED: success
    RUNNING --> FAILED: error
    RUNNING --> CANCELLED: timeout

    FAILED --> QUEUED: retry (with checkpoint)

    COMPLETED --> [*]
    FAILED --> [*]
    CANCELLED --> [*]
    SUPERSEDED --> [*]
```

### Job ë°ì´í„° ëª¨ë¸

```python
@dataclass
class IndexJob:
    id: str                    # UUID
    repo_id: str
    snapshot_id: str
    status: JobStatus          # QUEUED/RUNNING/COMPLETED/FAILED
    trigger: TriggerType       # MANUAL/AUTO/PR/REPAIR
    priority: int              # 1=HIGH, 2=MEDIUM, 3=LOW

    # Execution
    started_at: datetime | None
    completed_at: datetime | None
    duration_ms: int | None
    worker_id: str | None

    # Checkpoint
    checkpoint: IndexJobCheckpoint | None
    retry_count: int
    max_retries: int

    # Metadata
    created_at: datetime
    updated_at: datetime
```

### JobStatus

```python
class JobStatus(str, Enum):
    QUEUED = "queued"          # ëŒ€ê¸° ì¤‘
    RUNNING = "running"        # ì‹¤í–‰ ì¤‘
    COMPLETED = "completed"    # ì™„ë£Œ
    FAILED = "failed"          # ì‹¤íŒ¨ (ì¬ì‹œë„ ê°€ëŠ¥)
    CANCELLED = "cancelled"    # ì·¨ì†Œë¨
    SUPERSEDED = "superseded"  # ë” ìƒˆë¡œìš´ jobìœ¼ë¡œ ëŒ€ì²´
```

---

## 4. Distributed Lock

### Redis ê¸°ë°˜ Lock

```python
# Lock key í˜•ì‹
lock_key = f"indexing:{repo_id}:{snapshot_id}"

# ì˜ˆ: "indexing:my-repo:snapshot-123"
```

### Lock íšë“ & ì—°ì¥

```python
class IndexJobOrchestrator:
    async def execute_job(self, job_id: str, repo_path: Path):
        # 1. Lock íšë“ (5ë¶„ TTL)
        async with DistributedLock(
            redis=self.redis,
            lock_key=self._generate_lock_key(job.repo_id, job.snapshot_id),
            ttl=300,  # 5 minutes
            instance_id=self.instance_id,
        ) as lock:

            # 2. Lock ì—°ì¥ íƒœìŠ¤í¬ ì‹œì‘ (1ë¶„ë§ˆë‹¤)
            extend_task = asyncio.create_task(
                self._extend_lock_periodically(lock, interval=60)
            )

            try:
                # 3. ì¸ë±ì‹± ì‹¤í–‰ (ì¥ì‹œê°„ ê°€ëŠ¥)
                result = await self._execute_indexing(job, repo_path)

            finally:
                # 4. ì—°ì¥ íƒœìŠ¤í¬ ì¤‘ë‹¨
                extend_task.cancel()

        # Lock ìë™ í•´ì œ (context manager)
```

### Lock ì¶©ëŒ ì²˜ë¦¬

```python
try:
    async with DistributedLock(...) as lock:
        # ì¸ë±ì‹± ì‹¤í–‰
        pass

except LockAcquisitionError:
    # ì´ë¯¸ ë‹¤ë¥¸ workerê°€ ì‹¤í–‰ ì¤‘
    logger.warning(f"Job {job_id} locked by another worker")

    # ConflictStrategyì— ë”°ë¼ ì²˜ë¦¬
    if strategy == ConflictStrategy.SKIP:
        job.status = JobStatus.CANCELLED
    elif strategy == ConflictStrategy.QUEUE:
        # 5ë¶„ í›„ ì¬ì‹œë„
        await asyncio.sleep(300)
        return await self.execute_job(job_id, repo_path)
```

---

## 5. Checkpoint & Retry

### Checkpoint ë°ì´í„°

```python
@dataclass
class IndexJobCheckpoint:
    stage: str                   # "parsing" / "ir" / "indexing"
    completed_files: list[str]   # ì™„ë£Œëœ íŒŒì¼ë“¤
    total_files: int
    progress_percent: float

    # Stageë³„ ë©”íƒ€ë°ì´í„°
    parsing_completed: int
    ir_completed: int
    indexing_completed: int

    created_at: datetime
```

### Checkpoint ì €ì¥

```python
# IndexingOrchestratorì—ì„œ
async def execute_with_checkpoint(
    self,
    job: IndexJob,
    repo_path: Path,
) -> IndexingResult:

    # Checkpoint ë³µì›
    completed = set(job.checkpoint.completed_files) if job.checkpoint else set()

    # íŒŒì¼ ì²˜ë¦¬
    for file_path in all_files:
        if str(file_path) in completed:
            continue  # ì´ë¯¸ ì²˜ë¦¬ë¨

        # ì²˜ë¦¬
        await self._process_file(file_path)

        # Checkpoint ì €ì¥ (100ê°œë§ˆë‹¤)
        completed.add(str(file_path))
        if len(completed) % 100 == 0:
            await self._save_checkpoint(job.id, completed)
```

### Retry ë¡œì§

```python
async def execute_job(self, job_id: str, repo_path: Path):
    try:
        result = await self._execute_indexing(job, repo_path)

        # ì„±ê³µ
        job.status = JobStatus.COMPLETED
        job.completed_at = datetime.now()
        await self._update_job(job)

    except Exception as e:
        logger.error(f"Job {job_id} failed: {e}")

        # Retry íŒì •
        if job.retry_count < job.max_retries:
            # Checkpoint ì €ì¥
            await self._save_checkpoint(job.id, progress)

            # ì¬ì‹œë„ ìŠ¤ì¼€ì¤„ (exponential backoff)
            delay = 2 ** job.retry_count  # 1s, 2s, 4s, 8s
            await asyncio.sleep(delay)

            job.retry_count += 1
            job.status = JobStatus.QUEUED
            await self._update_job(job)

            # ì¬ì‹¤í–‰
            return await self.execute_job(job_id, repo_path)

        else:
            # Max retries ì´ˆê³¼
            job.status = JobStatus.FAILED
            job.error_message = str(e)
            await self._update_job(job)
```

---

## 6. Conflict Resolution

### ConflictRegistry

```python
class ConflictStrategy(str, Enum):
    SKIP = "skip"          # ê¸°ì¡´ job ìœ ì§€, ìƒˆ ìš”ì²­ ì·¨ì†Œ
    SUPERSEDE = "supersede"  # ê¸°ì¡´ job ì·¨ì†Œ, ìƒˆ ìš”ì²­ ì‹¤í–‰
    QUEUE = "queue"        # ìƒˆ ìš”ì²­ ëŒ€ê¸°ì—´ ì¶”ê°€
```

### ì¤‘ë³µ ê°ì§€

```python
class ConflictRegistry:
    def __init__(self):
        self._active_jobs: dict[tuple[str, str], str] = {}
        # Key: (repo_id, snapshot_id), Value: job_id

    def check_conflict(
        self,
        repo_id: str,
        snapshot_id: str,
        new_job_id: str,
        strategy: ConflictStrategy,
    ) -> ConflictResolution:

        key = (repo_id, snapshot_id)
        existing_job_id = self._active_jobs.get(key)

        if not existing_job_id:
            # ì¶©ëŒ ì—†ìŒ
            self._active_jobs[key] = new_job_id
            return ConflictResolution(action="proceed")

        # ì¶©ëŒ ë°œìƒ
        if strategy == ConflictStrategy.SKIP:
            return ConflictResolution(
                action="cancel",
                reason=f"Job {existing_job_id} already running"
            )

        elif strategy == ConflictStrategy.SUPERSEDE:
            # ê¸°ì¡´ job ì·¨ì†Œ
            await self._cancel_job(existing_job_id)
            self._active_jobs[key] = new_job_id
            return ConflictResolution(action="proceed")

        elif strategy == ConflictStrategy.QUEUE:
            return ConflictResolution(
                action="queue",
                wait_for=existing_job_id
            )
```

---

## 7. ì‚¬ìš© ê°€ì´ë“œ

### ê¸°ë³¸ ì‚¬ìš©

```python
from src.contexts.analysis_indexing.infrastructure.job_orchestrator import (
    IndexJobOrchestrator,
    TriggerType,
)

# ì´ˆê¸°í™”
orchestrator = IndexJobOrchestrator(
    orchestrator=indexing_orchestrator,
    postgres_store=postgres,
    redis_client=redis,
)

# Job ì œì¶œ
job = await orchestrator.submit_job(
    repo_id="my-repo",
    snapshot_id="snapshot-123",
    repo_path=Path("/path/to/repo"),
    trigger=TriggerType.MANUAL,
)

# Job ì‹¤í–‰
result = await orchestrator.execute_job(job.id, Path("/path/to/repo"))

# ê²°ê³¼ í™•ì¸
if result.success:
    print(f"Indexed {result.indexed_files} files")
else:
    print(f"Failed: {result.error}")
```

### Worker Pool

```python
# ë©€í‹° ì›Œì»¤ ì‹¤í–‰
async def worker(worker_id: int):
    while True:
        # Job ê°€ì ¸ì˜¤ê¸°
        job = await orchestrator.get_next_job()

        if not job:
            await asyncio.sleep(5)
            continue

        # ì‹¤í–‰
        try:
            await orchestrator.execute_job(job.id, job.repo_path)
        except Exception as e:
            logger.error(f"Worker {worker_id} failed: {e}")

# 5ê°œ ì›Œì»¤ ì‹œì‘
workers = [asyncio.create_task(worker(i)) for i in range(5)]
await asyncio.gather(*workers)
```

### Conflict Strategy ì„¤ì •

```python
# SKIP: ì¤‘ë³µ ë¬´ì‹œ (ê¸°ë³¸ê°’)
orchestrator = IndexJobOrchestrator(
    ...,
    conflict_strategy=ConflictStrategy.SKIP,
)

# SUPERSEDE: ìƒˆ ìš”ì²­ ìš°ì„  (git push í›„)
orchestrator = IndexJobOrchestrator(
    ...,
    conflict_strategy=ConflictStrategy.SUPERSEDE,
)

# QUEUE: ëŒ€ê¸°ì—´ ì¶”ê°€ (ìˆœì°¨ ì‹¤í–‰)
orchestrator = IndexJobOrchestrator(
    ...,
    conflict_strategy=ConflictStrategy.QUEUE,
)
```

### Checkpoint ì¬ê°œ

```python
# ì‹¤íŒ¨í•œ job ì¬ì‹¤í–‰
failed_job = await orchestrator.get_job(job_id)

if failed_job.checkpoint:
    print(f"Resuming from {failed_job.checkpoint.progress_percent}%")

# ìë™ìœ¼ë¡œ checkpointë¶€í„° ì¬ê°œ
result = await orchestrator.execute_job(job_id, repo_path)
```

---

## ì„±ëŠ¥ íŠ¹ì„±

### Lock Overhead

| ì‘ì—… | ì‹œê°„ |
|------|------|
| Lock íšë“ | ~ |
| Lock ì—°ì¥ | ~ |
| Lock í•´ì œ | ~ |

### Checkpoint Overhead

| ì‘ì—… | ì‹œê°„ |
|------|------|
| Checkpoint ì €ì¥ | ~ |
| Checkpoint ë¡œë“œ | ~ |

### Job Throughput

| ì„¤ì • | Throughput |
|------|-----------|
| 1 worker | ~10 jobs/hour |
| 5 workers | ~40 jobs/hour |
| 10 workers | ~70 jobs/hour |

---

## ë©”íŠ¸ë¦­

### OpenTelemetry

```python
# Counter
record_counter("indexing.jobs.submitted", 1, {"trigger": trigger})
record_counter("indexing.jobs.completed", 1, {"repo_id": repo_id})
record_counter("indexing.jobs.failed", 1, {"repo_id": repo_id})

# Histogram
record_histogram("indexing.job.duration", duration_ms)
record_histogram("indexing.lock.wait_time", wait_ms)
```

### ë¡œê·¸ í‚¤ì›Œë“œ

```bash
# Job ë¼ì´í”„ì‚¬ì´í´
grep "job_submitted" logs/
grep "job_started" logs/
grep "job_completed" logs/
grep "job_failed" logs/

# Lock
grep "lock_acquired" logs/
grep "lock_extended" logs/
grep "lock_acquisition_error" logs/

# Checkpoint
grep "checkpoint_saved" logs/
grep "checkpoint_resumed" logs/
```

---

## ì œì•½ì‚¬í•­

### í˜„ì¬ ì œì•½
- **Single snapshotë§Œ ë³´ì¥:** ë™ì¼ repoì˜ ë‹¤ë¥¸ snapshotì€ ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥
- **Redis í•„ìˆ˜:** Distributed lockì„ ìœ„í•´ Redis í•„ìš” (ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ëŠ” NoOpLock)
- **PostgreSQL í•„ìˆ˜:** Job queue ì €ì¥

### í–¥í›„ ê³„íš
- [ ] **SemanticaTask Engine í†µí•©** (í˜„ì¬ëŠ” ë³„ë„)
- [ ] **Multi-region lock** (í˜„ì¬ëŠ” ë‹¨ì¼ Redis)
- [ ] **Job priority queue** (í˜„ì¬ëŠ” FIFO)
- [ ] **Job scheduling** (cron, delay)

---

## íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### Lock íšë“ ì‹¤íŒ¨
```bash
# ì¦ìƒ
ERROR: Lock acquisition timeout after 30s

# ì›ì¸
- ë‹¤ë¥¸ workerê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘
- Redis ì—°ê²° ì‹¤íŒ¨
- Lock TTL ë¶€ì¡±

# í•´ê²°
1. ì‹¤í–‰ ì¤‘ì¸ job í™•ì¸: SELECT * FROM index_jobs WHERE status='RUNNING'
2. Redis ìƒíƒœ í™•ì¸: redis-cli PING
3. TTL ì¦ê°€: lock_ttl=600 (10ë¶„)
```

### Checkpoint ë³µêµ¬ ì‹¤íŒ¨
```bash
# ì¦ìƒ
WARNING: Checkpoint corrupted, starting from scratch

# ì›ì¸
- PostgreSQL JSONB ì†ìƒ
- Checkpoint ë²„ì „ ë¶ˆì¼ì¹˜

# í•´ê²°
1. Checkpoint ì‚­ì œ: UPDATE index_jobs SET checkpoint=NULL WHERE id='...'
2. ì¬ì‹¤í–‰: ì²˜ìŒë¶€í„° ì‹œì‘
```

---

## ì°¸ê³ 

### êµ¬í˜„ íŒŒì¼
```
src/contexts/analysis_indexing/infrastructure/
â”œâ”€â”€ job_orchestrator.py           # ë©”ì¸ êµ¬í˜„
â”œâ”€â”€ conflict_registry.py          # ì¤‘ë³µ ì²˜ë¦¬
â”œâ”€â”€ lock_key_generator.py         # Lock key ìƒì„±
â””â”€â”€ models/job.py                 # Job ëª¨ë¸

src/infra/cache/
â””â”€â”€ distributed_lock.py           # Redis lock
```

### ê´€ë ¨ ë¬¸ì„œ
- `pipelines-detailed.md` - íŒŒì´í”„ë¼ì¸ ì „ì²´
- `9-stage-pipeline.md` - Stageë³„ ìƒì„¸
- `configuration.md` - ì„¤ì • ê°€ì´ë“œ

---

**Last 
**Status:** ğŸŸ¢ Production Ready
