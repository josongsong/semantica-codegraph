# RFC-028: Critical Analysis Gaps (Cost, Concurrency, Differential)
**Status**: DRAFT
**Priority**: P0 (Critical)
**Timeline**: 6-8ì£¼
**Owner**: Static Analysis Team

---

## 1. Executive Summary

í˜„ì¬ Semantica v2ëŠ” **Heap/Taint ë¶„ì„ì€ Inferê¸‰**ì´ì§€ë§Œ, **Cost/Concurrency/Differential Analysisê°€ ë¶€ì¬**í•˜ì—¬ ì‹¤ìš©ì„±ì´ í¬ê²Œ ì œí•œë©ë‹ˆë‹¤.

### 1.1 RFC-027 ì—°ë™ (ë³‘í–‰ ì‘ì—…)

**ë³¸ RFCëŠ” RFC-027ê³¼ ë³‘í–‰ ì‘ì—… ê°€ëŠ¥í•©ë‹ˆë‹¤.**

- âœ… **Evidence ìŠ¤í‚¤ë§ˆ í™•ì • ì™„ë£Œ** (`src/agent/domain/rfc_specs/evidence.py`)
- âœ… **Claim ìŠ¤í‚¤ë§ˆ í™•ì • ì™„ë£Œ** (`src/agent/domain/rfc_specs/claim.py`)
- âœ… **Mapping í…Œì´ë¸” í™•ì •** (`src/agent/adapters/rfc/mappings.py`)
- âœ… **ë³‘í–‰ ì‘ì—… ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ**

**ì°¸ê³  ë¬¸ì„œ**: `_docs/_backlog/RFC-027-028-PARALLEL-WORK-PLAN.md`

### í˜„ì¬ ìƒí™©
```
âœ… Null Safety:        95% (Infer ê·¼ì ‘)
âœ… Heap Analysis:      90% (Sep Logic, Bi-abduction)
âœ… Taint Analysis:     95% (Interprocedural, context-sensitive)
âœ… Semantic Diff:      70% (ê¸°ë³¸ êµ¬í˜„ ìˆìŒ)

âš ï¸  Cost Analysis:      40% (Core ì¼ë¶€, complexity term/evidence/diff ë¯¸ì™„)
âš ï¸  Concurrency:        30% (Prototype ë£°, alias/escape/await ëª¨ë¸ í‘œì¤€í™” ë¯¸ì™„)
âš ï¸  Differential:       50% (Semantic diff ìˆìŒ, taint/cost/breaking ì¢…í•© diff ë¯¸ì™„)
```

### ë¹„ì¦ˆë‹ˆìŠ¤ ì„íŒ©íŠ¸

**Without Cost Analysis**:
- âŒ IDEì—ì„œ "ì´ ë£¨í”„ëŠ” ëŠë¦¼" ì‹¤ì‹œê°„ ê²½ê³  ë¶ˆê°€
- âŒ PR ë¦¬ë·°ì—ì„œ ì„±ëŠ¥ íšŒê·€ ìë™ íƒì§€ ë¶ˆê°€
- âŒ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì‹œ timeout ì˜ˆì¸¡ ë¶ˆê°€

**Without Concurrency Analysis**:
- âŒ Python async ì½”ë“œì˜ race condition íƒì§€ ë¶ˆê°€
- âŒ FastAPI/Django async viewì˜ ê³µìœ  ë³€ìˆ˜ ì ‘ê·¼ ê²½ê³  ë¶ˆê°€
- âŒ í”„ë¡œë•ì…˜ data race ì‚¬ì „ ë°©ì§€ ë¶ˆê°€

**Without Differential Analysis**:
- âŒ PRì—ì„œ "Sanitizer ì œê±°ë¨" ìë™ ê²½ê³  ë¶ˆê°€
- âŒ "O(n) â†’ O(nÂ²) íšŒê·€" ìë™ íƒì§€ ë¶ˆê°€
- âŒ Breaking change ìë™ ê°ì§€ ë¶ˆê°€

---

## 2. Architecture Overview

### 2.1 í˜„ì¬ ì¸í”„ë¼ (ì¬ì‚¬ìš© ê°€ëŠ¥)

```
âœ… SCCP Engine          â€” src/contexts/code_foundation/infrastructure/dfg/constant/
âœ… SSA Builder          â€” src/contexts/code_foundation/infrastructure/dfg/ssa/
âœ… CFG Builder          â€” src/contexts/code_foundation/infrastructure/semantic_ir/cfg/
âœ… Call Graph           â€” src/contexts/code_foundation/infrastructure/graphs/
âœ… Query Engine         â€” src/contexts/code_foundation/infrastructure/query/
âœ… Semantic Differ      â€” src/contexts/reasoning_engine/infrastructure/semantic_diff/
âœ… Impact Analyzer      â€” src/contexts/reasoning_engine/infrastructure/impact/
```

**í•µì‹¬**: ê¸°ë°˜ì€ ì™„ë²½. ìœ„ì— Cost/Concurrency/Differentialë§Œ ì¶”ê°€í•˜ë©´ ë¨.

### 2.2 ëª©í‘œ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  New Analysis Layers (RFC-028)         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ CostAnalyzer                      â”‚  â”‚ â† ì¶”ê°€
â”‚  â”‚ ConcurrencyAnalyzer              â”‚  â”‚ â† ì¶”ê°€
â”‚  â”‚ DifferentialAnalyzer             â”‚  â”‚ â† ê°•í™”
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ uses
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Existing Infrastructure (Reuse)        â”‚
â”‚  - SCCP, SSA, CFG                       â”‚ â† ì¬ì‚¬ìš©
â”‚  - Call Graph, Query Engine             â”‚ â† ì¬ì‚¬ìš©
â”‚  - Semantic Differ                      â”‚ â† í™•ì¥
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. Common Evidence Schema (í•„ìˆ˜) â­ â€” LOCKED

**âœ… Evidence ìŠ¤í‚¤ë§ˆ í™•ì • ì™„ë£Œ** (RFC-027 + RFC-028 í†µí•©)

**ìœ„ì¹˜**: `src/agent/domain/rfc_specs/evidence.py` (êµ¬í˜„ ì™„ë£Œ, í…ŒìŠ¤íŠ¸ í†µê³¼)

**ëª¨ë“  AnalyzerëŠ” ê³µí†µ ì¦ê±° í˜•ì‹ì„ ë°˜í™˜í•´ì•¼ í•¨** (RFC-027 ì—°ë™)

### 3.1 Base Result Schema (RFC-028 ì¶œë ¥ í˜•ì‹)

**íŒ€ A (RFC-028)ê°€ ë°˜í™˜í•  í˜•ì‹** (íŒ€ Bê°€ ì´ê²ƒì„ ë°›ì•„ì„œ ResultEnvelopeë¡œ ë³€í™˜):

```python
from src.agent.domain.rfc_specs import Evidence, Claim, ConfidenceBasis
from typing import Literal

@dataclass
class AnalysisResult:
    """
    ê³µí†µ ë¶„ì„ ê²°ê³¼ (ëª¨ë“  Analyzer ë°˜í™˜)

    íŒ€ A â†’ íŒ€ B Interface Contract:
    - verdict: "proven"/"likely"/"heuristic" (ë¬¸ìì—´)
    - evidence: Evidence ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜ (íŒ€ ê³µí†µ)
    - íŒ€ Bê°€ verdict â†’ ConfidenceBasis ë³€í™˜
    """

    # Verdict (íŒ€ Bê°€ ConfidenceBasisë¡œ ë³€í™˜)
    verdict: Literal["proven", "likely", "heuristic"]
    confidence: float  # 0.0-1.0

    # Evidence (RFC-027 ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜!) â­
    evidence: Evidence  # â† src/agent/domain/rfc_specs/evidence.py

    # Explanation (human-readable)
    explanation: str  # 1ì¤„ ìš”ì•½

    # Analysis-specific metadata
    metadata: dict[str, Any] = field(default_factory=dict)
```

**ë³€í™˜ íë¦„**:
```python
# íŒ€ A: Analysis ê²°ê³¼
result = CostResult(
    verdict="proven",  # â† ë¬¸ìì—´
    evidence=Evidence(...)  # â† ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜
)

# íŒ€ B: ResultEnvelopeë¡œ ë³€í™˜
claim = Claim(
    confidence_basis=VERDICT_TO_CONFIDENCE_BASIS[result.verdict],  # â† ë§¤í•‘
    ...
)
```

### 3.2 CostEvidence Schema â€” LOCKED âœ…

**âœ… êµ¬í˜„ ì™„ë£Œ**: `src/agent/domain/rfc_specs/evidence.py` â†’ `CostEvidenceBuilder`

**íŒ€ AëŠ” ì´ Builderë¥¼ ì‚¬ìš©í•´ì•¼ í•¨** (ì§ì ‘ Evidence ìƒì„± ê¸ˆì§€):

```python
from src.agent.domain.rfc_specs.evidence import CostEvidenceBuilder

# âœ… GOOD: Builder ì‚¬ìš©
evidence = CostEvidenceBuilder.build(
    evidence_id="req_001_ev_001",
    location=Location(file_path="utils.py", start_line=10, end_line=20),
    cost_term="n * m",
    loop_bounds=[
        {"loop_id": "loop_1", "bound": "n", "method": "pattern", "confidence": 1.0}
    ],
    hotspots=[{"line": 15, "reason": "nested loop"}],
    provenance=Provenance(engine="CostAnalyzer", version="1.0.0"),
    claim_ids=["pending"]  # â† íŒ€ Bê°€ ë‚˜ì¤‘ì— ì‹¤ì œ IDë¡œ êµì²´
)

# âŒ BAD: ì§ì ‘ ìƒì„± (validation ìš°íšŒ ê°€ëŠ¥)
evidence = Evidence(kind=EvidenceKind.COST_TERM, content={...})
```

**Content êµ¬ì¡°** (CostEvidenceBuilderê°€ ë³´ì¥):

```python
@dataclass
class CostEvidence:
    """Cost Analysis ì¦ê±° (RFC-LLM-001 í˜¸í™˜)"""

    # Loop bounds
    loop_bounds: list[LoopBound]  # [(loop_id, bound_expr, method, confidence)]

    # Cost term (expression tree)
    cost_term: CostTerm  # add(mul(n, m), log(n))

    # Hotspots
    hotspots: list[Hotspot]  # [(block_id, local_term, reason)]

    # Method
    inference_method: Literal["pattern", "sccp", "widening", "heuristic"]

    # Provenance
    provenance: dict = field(default_factory=lambda: {
        "engine": "cost_analyzer",
        "version": "1.0"
    })

@dataclass
class LoopBound:
    """ê°œë³„ ë£¨í”„ bound ì¦ê±°"""
    loop_id: str
    bound_expr: str  # "n", "len(arr)", "unknown"
    method: str      # "pattern", "sccp", "heuristic"
    confidence: float
    location: tuple[str, int]  # (file, line)

@dataclass
class CostTerm:
    """ë³µì¡ë„ expression tree"""
    kind: Literal["const", "symbol", "add", "mul", "log", "pow"]
    value: int | str | None = None  # const: 1, symbol: "n"
    children: list[CostTerm] = field(default_factory=list)

    def __str__(self) -> str:
        if self.kind == "const": return str(self.value)
        if self.kind == "symbol": return str(self.value)
        if self.kind == "add": return f"({' + '.join(map(str, self.children))})"
        if self.kind == "mul": return f"({' * '.join(map(str, self.children))})"
        if self.kind == "log": return f"log({self.children[0]})"
        if self.kind == "pow": return f"({self.children[0]}^{self.children[1]})"
```

### 3.3 ConcurrencyEvidence Schema â€” LOCKED âœ…

**âœ… êµ¬í˜„ ì™„ë£Œ**: `src/agent/domain/rfc_specs/evidence.py` â†’ `ConcurrencyEvidenceBuilder`

**íŒ€ AëŠ” ì´ Builderë¥¼ ì‚¬ìš©í•´ì•¼ í•¨**:

```python
from src.agent.domain.rfc_specs.evidence import ConcurrencyEvidenceBuilder

# âœ… GOOD: Builder ì‚¬ìš©
evidence = ConcurrencyEvidenceBuilder.build(
    evidence_id="req_002_ev_001",
    location=Location(...),
    shared_variable={
        "var_id": "v1",
        "var_name": "cache",
        "escape_status": "shared"  # â† í•„ìˆ˜ (local/shared/unknown)
    },
    await_cuts=["node_5", "node_10"],
    lock_regions=[
        {"lock_id": "lock_1", "scope": [45, 65], "resolved_alias": True}  # â† resolved_alias í•„ìˆ˜!
    ],
    race_witness={"access1": "line_52", "access2": "line_58", "interleaving_path": ["await_55"]},
    provenance=Provenance(engine="RaceDetector", version="1.0.0"),
    claim_ids=["pending"]
)
```

**Content êµ¬ì¡°** (ConcurrencyEvidenceBuilderê°€ ë³´ì¥):

```python
@dataclass
class ConcurrencyEvidence:
    """Concurrency Analysis ì¦ê±°"""

    # Shared variable identity
    shared_identity: SharedVar  # var_id + escape_status

    # Await cuts (interleaving points)
    await_cuts: list[str]  # [node_id]

    # Lock regions
    lock_regions: list[LockRegion]

    # Race witness (if race detected)
    race_witness: RaceWitness | None

    # Provenance
    provenance: dict = field(default_factory=lambda: {
        "engine": "concurrency_analyzer",
        "version": "1.0"
    })

@dataclass
class SharedVar:
    """ê³µìœ  ë³€ìˆ˜ identity"""
    var_id: str
    var_name: str
    escape_status: Literal["local", "shared", "unknown"]  # â† í•„ìˆ˜!
    location: tuple[str, int]

@dataclass
class LockRegion:
    """Lock ë³´í˜¸ ì˜ì—­"""
    lock_id: str
    lock_primitive: str  # "asyncio.Lock", "threading.Lock"
    scope: tuple[int, int]  # (start_line, end_line)
    resolved_alias: bool  # Alias resolution ì„±ê³µ ì—¬ë¶€ â† CRITICAL!

@dataclass
class RaceWitness:
    """Race condition ì¦ê±°"""
    access1: VarAccess
    access2: VarAccess
    interleaving_path: list[str]  # Await points between
    confidence: float
```

### 3.4 DifferentialEvidence Schema â€” LOCKED âœ…

**âœ… êµ¬í˜„ ì™„ë£Œ**: `src/agent/domain/rfc_specs/evidence.py` â†’ `DifferentialEvidenceBuilder`

**íŒ€ AëŠ” ì´ Builderë¥¼ ì‚¬ìš©í•´ì•¼ í•¨**:

```python
from src.agent.domain.rfc_specs.evidence import DifferentialEvidenceBuilder

# âœ… GOOD: Builder ì‚¬ìš©
evidence = DifferentialEvidenceBuilder.build(
    evidence_id="req_003_ev_001",
    location=Location(...),
    base_snapshot="snap_455",
    pr_snapshot="snap_456",
    scope={
        "changed_functions": ["func1"],
        "impact_closure": ["func2", "func3"],  # â† BFS í™•ì¥ í•„ìˆ˜!
        "total_symbols": 3
    },
    deltas={
        "sanitizer_removed": [("source1", "sink1")],
        "cost_regressions": []
    },
    fingerprints={"before": {"func1": "hash1"}, "after": {"func1": "hash2"}},
    provenance=Provenance(engine="DifferentialAnalyzer", version="1.0.0"),
    claim_ids=["pending"]
)
```

**Content êµ¬ì¡°** (DifferentialEvidenceBuilderê°€ ë³´ì¥):

```python
@dataclass
class DifferentialEvidence:
    """Differential Analysis ì¦ê±°"""

    # Scope
    base_snapshot: str
    pr_snapshot: str
    scope: DiffScope  # changed + impact_closure

    # Deltas
    deltas: DiffDeltas

    # Before/After fingerprints
    before_fingerprint: dict  # {function: cost_term/path_fingerprint}
    after_fingerprint: dict

    # Provenance
    provenance: dict = field(default_factory=lambda: {
        "engine": "differential_analyzer",
        "version": "1.0"
    })

@dataclass
class DiffScope:
    """Diff ë¶„ì„ ë²”ìœ„ (RFC-LLM-001 í˜¸í™˜)"""
    changed_functions: list[str]
    impact_closure: list[str]  # Callers + callees + data deps â† MUST
    total_symbols: int

    # Evidenceì— scope ê·¼ê±° ê¸°ë¡
    closure_method: Literal["call_graph", "data_deps", "both"]
    max_depth: int  # BFS depth used

    def to_evidence(self) -> dict:
        """Evidenceë¡œ ë³€í™˜"""
        return {
            "changed": len(self.changed_functions),
            "impacted": len(self.impact_closure),
            "total": self.total_symbols,
            "method": self.closure_method,
            "depth": self.max_depth
        }

@dataclass
class DiffDeltas:
    """ë³€ê²½ ì‚¬í•­"""
    sanitizer_edges_removed: list[tuple[str, str]]  # (source, sink)
    new_source_to_sink_paths: list[str]
    cost_regressions: list[tuple[str, str, str]]  # (function, before, after)
    breaking_changes: list[str]
```

---

## 4. Phase 1: Cost Analysis (2-3ì£¼)

**Real-time (ì‹¤ì‹œê°„ ì¦ë¶„ ëª¨ë“œ)**:
- IDEì—ì„œ ì½”ë”© ì¤‘ "ì´ ë£¨í”„ëŠ” O(nÂ²), ëŠë¦´ ìˆ˜ ìˆìŒ" ê²½ê³ 
-  ì´ë‚´ ì¦ë¶„ ê³„ì‚°

**PR Review (PR ë¦¬ë·° ëª¨ë“œ)**:
- Before: O(n) â†’ After: O(nÂ²) ìë™ íƒì§€
- "ì„±ëŠ¥ íšŒê·€ ìœ„í—˜" ìë™ ê²½ê³ 

### 3.2 êµ¬í˜„ ìœ„ì¹˜

```
src/contexts/code_foundation/infrastructure/analyzers/cost/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ cost_analyzer.py           # Main entry point
â”œâ”€â”€ loop_bound_analyzer.py     # ë£¨í”„ ë°˜ë³µ íšŸìˆ˜ ì¶”ë¡ 
â”œâ”€â”€ complexity_calculator.py   # O(n), O(nÂ²) ê³„ì‚°
â”œâ”€â”€ models.py                  # ComplexityClass, CostResult
â””â”€â”€ cache.py                   # Function-level cost cache
```

### 3.3 ì•Œê³ ë¦¬ì¦˜

**Step 1: Loop Bound Inference** (Infer-style)
```python
# Pattern matching (Fast path)
for i in range(n):           â†’ Bound(n), confidence=1.0
for i in range(len(arr)):    â†’ Bound(len(arr)), confidence=1.0
while i < n:                 â†’ Bound(n), confidence=0.8 (with widening)

# Symbolic execution (lightweight)
for i in range(start, end):  â†’ Bound(end - start), confidence=0.9

# âš ï¸  Unbounded loop (CRITICAL CASE)
while True:                  â†’ Bound(âˆ), confidence=0.3 (Heuristic: assume O(n))
while condition:             â†’ Bound(unknown), confidence=0.2 (Heuristic: assume O(n))
```

**âš ï¸  Critical: Unbounded Loop Handling**
- âŒ **BAD**: ì¶”ë¡  ì‹¤íŒ¨ ì‹œ `Unknown` ë¦¬í„´ â†’ IDEì—ì„œ "ë¶„ì„ ë¶ˆê°€" í‘œì‹œ
- âœ… **GOOD**: ì¶”ë¡  ì‹¤íŒ¨ ì‹œ `Heuristic Bound (O(n))` + `confidence: low` ë¦¬í„´
  - IDEì—ì„œ "ì ì¬ì  ì„±ëŠ¥ ìœ„í—˜ (í™•ì‹ ë„ ë‚®ìŒ)" í‘œì‹œ
  - UX ê°œì„ : "ëª¨ë¥´ê² ë‹¤" ëŒ€ì‹  "ìœ„í—˜í•  ìˆ˜ ìˆë‹¤"

**Step 2: Cost Composition**
```python
# Sequential
cost(S1; S2) = cost(S1) + cost(S2)

# Nested loops
for i in range(n):
    for j in range(m):       â†’ O(n * m)
        ...

# Function call
cost(f()) = lookup(f)        # Cached function cost
```

**Step 3: Complexity Classification**
```python
O(1)      : const
O(log n)  : binary search
O(n)      : single loop
O(n log n): merge sort
O(nÂ²)     : nested loop
O(2^n)    : exponential
```

### 3.4 Integration Points

**ê¸°ì¡´ ì¸í”„ë¼ ì¬ì‚¬ìš©**:
```python
class CostAnalyzer:
    def __init__(self,
                 sccp_engine: SCCPEngine,      # â† ì¬ì‚¬ìš©
                 ssa_builder: SSABuilder,      # â† ì¬ì‚¬ìš©
                 cfg_provider: CFGProvider):   # â† ì¬ì‚¬ìš©
        self.sccp = sccp_engine
        self.ssa = ssa_builder
        self.cfg = cfg_provider

    def analyze_function(self, func_fqn: str) -> CostResult:
        # 1. Get CFG (ì´ë¯¸ ìˆìŒ)
        cfg = self.cfg.get_cfg(func_fqn)

        # 2. Build SSA (ì´ë¯¸ ìˆìŒ)
        ssa = self.ssa.build(cfg)

        # 3. Use SCCP for constant bounds (ì´ë¯¸ ìˆìŒ)
        constants = self.sccp.analyze(ssa)

        # 4. Infer loop bounds (NEW)
        bounds = self._infer_loop_bounds(cfg, constants)

        # 5. Calculate complexity (NEW)
        complexity = self._calculate_complexity(cfg, bounds)

        return CostResult(
            function=func_fqn,
            time_complexity=complexity,
            bottlenecks=[...]
        )
```

### 3.5 ì‹¤ì‹œê°„ ì¦ë¶„ ìµœì í™”

**ì¦ë¶„ ê³„ì‚°** (ê¸°ì¡´ `ChunkIncrementalRefresher` íŒ¨í„´ ì¬ì‚¬ìš©):
```python
class IncrementalCostAnalyzer:
    def __init__(self, cache: CostCache):
        self._cache = cache

    def analyze_changed(self, func_fqn: str, changed_lines: set[int]) -> CostResult:
        # 1. Check cache
        if not changed_lines and self._cache.has(func_fqn):
            return self._cache.get(func_fqn)

        # 2. Analyze only affected basic blocks (ì¦ë¶„)
        affected_blocks = self._get_affected_blocks(func_fqn, changed_lines)

        # 3. Reuse cached costs for unchanged blocks
        ...

        # Target:  per function
```

### 3.6 Escape Analysis (Shared Variable Detection)

**âš ï¸  CRITICAL**: Shared variable íŒì •ì— escape analysis í•„ìš”

```python
# í˜„ì¬ ë‹¨ìˆœ ì •ì˜: global/class fieldë§Œ
# ì‹¤ì „ async ì¼€ì´ìŠ¤:

# 1. Captured mutable closure
def create_worker():
    cache = {}  # â† Shared? (closure capture)

    async def worker(key):
        cache[key] = value  # â† Race ê°€ëŠ¥!

    return worker

# 2. Module singleton
_global_cache = {}  # â† Obvious shared

# 3. Injected dependency
class Service:
    def __init__(self, cache: Cache):
        self.cache = cache  # â† Shared? (depends on DI)
```

**Required**:
```python
@dataclass
class SharedVar:
    var_id: str
    var_name: str
    escape_status: Literal["local", "shared", "unknown"]  # â† í•„ìˆ˜!
    escape_reason: str | None  # "global", "field", "closure", "unknown"

class SharedVarTracker:
    def analyze_escape(self, var: Variable) -> SharedVar:
        # 1. Global â†’ shared
        if var.is_global():
            return SharedVar(..., escape_status="shared", escape_reason="global")

        # 2. Class field â†’ shared
        if var.is_field():
            return SharedVar(..., escape_status="shared", escape_reason="field")

        # 3. Closure capture â†’ shared (if mutable)
        if var.is_captured() and var.is_mutable():
            return SharedVar(..., escape_status="shared", escape_reason="closure")

        # 4. Unknown â†’ conservative
        return SharedVar(..., escape_status="unknown", escape_reason="complex_flow")
```

### 3.7 API Integration

**ReasoningPipeline í†µí•©** (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í™•ì¥):
```python
# src/contexts/reasoning_engine/application/reasoning_pipeline.py

class ReasoningPipeline:
    def __init__(self, ...):
        ...
        # NEW: Cost analyzer
        self.cost_analyzer = CostAnalyzer(...)

    def analyze_performance_regression(self, changes: dict) -> PerformanceReport:
        """NEW: ì„±ëŠ¥ íšŒê·€ ë¶„ì„"""
        regressions = []

        for func, (before, after) in changes.items():
            # Before cost
            cost_before = self.cost_analyzer.analyze(before)

            # After cost
            cost_after = self.cost_analyzer.analyze(after)

            # Compare
            if cost_after.worse_than(cost_before):
                regressions.append(PerformanceRegression(
                    function=func,
                    before=cost_before.complexity,
                    after=cost_after.complexity,
                    severity="HIGH" if cost_after.is_exponential() else "MEDIUM"
                ))

        return PerformanceReport(regressions=regressions)
```

---

## 4. Phase 2: Concurrency Analysis (2-3ì£¼)

### 4.1 ëª©í‘œ

**Python async (ìš°ì„ ìˆœìœ„)**:
- `asyncio.Lock` ì—†ì´ shared variable ì ‘ê·¼ íƒì§€
- Race condition ê²½ê³ 
- Deadlock ê°€ëŠ¥ì„± ê²½ê³ 

**Target**:
- FastAPI/Django async views
- `asyncio` ê¸°ë°˜ ì½”ë“œ
- ì‹¤ì‹œê°„  ì¦ë¶„

### 4.2 êµ¬í˜„ ìœ„ì¹˜

```
src/contexts/code_foundation/infrastructure/analyzers/concurrency/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ race_detector.py           # Race condition íƒì§€
â”œâ”€â”€ lock_analyzer.py           # Lock acquisition ë¶„ì„
â”œâ”€â”€ async_analyzer.py          # Python async/await ì „ìš©
â”œâ”€â”€ shared_var_tracker.py      # ê³µìœ  ë³€ìˆ˜ ì¶”ì 
â””â”€â”€ models.py                  # RaceCondition, LockRegion
```

### 4.3 ì•Œê³ ë¦¬ì¦˜ (RacerD-inspired, Lightweight)

**Step 1: Shared Variable Detection**
```python
# Class fields
class Counter:
    def __init__(self):
        self.count = 0  # â† Shared variable

    async def increment(self):
        self.count += 1  # â† Access

# Global variables
cache = {}  # â† Shared

async def get(key):
    return cache[key]  # â† Access
```

**Step 2: Lock Region Detection**
```python
# asyncio.Lock
lock = asyncio.Lock()

async with lock:    # â† Lock acquired
    self.count += 1 # â† Protected
# â† Lock released

# No lock
self.count += 1     # â† Unprotected (RACE!)
```

**Step 3: Await Point Detection**
```python
async def increment(self):
    temp = self.count
    await asyncio.sleep(0)  # â† Interleaving possible!
    self.count = temp + 1   # â† RACE CONDITION
```

**Step 4: Race Detection**
```
Rule: If (multiple writes OR write+read)
      AND at least one has await before
      AND not protected by lock
      â†’ RACE CONDITION
```

### 4.4 Integration Points

**âš ï¸  CRITICAL DEPENDENCY: Alias Analysis**

Concurrency ë¶„ì„ì˜ ì •í™•ë„ëŠ” **AliasAnalyzerì˜ must-alias ì •í™•ë„**ì— ì˜ì¡´í•©ë‹ˆë‹¤:

```python
# Case: Lockì´ í•¨ìˆ˜ ì¸ìë¡œ ì „ë‹¬
async def increment(self, lock: asyncio.Lock):
    async with lock:        # â† lock ë³€ìˆ˜
        self.count += 1     # Protected? â†’ Alias analysis í•„ìš”

async def worker(self):
    my_lock = asyncio.Lock()
    await self.increment(my_lock)  # lock === my_lock?
```

**Mitigation**:
- Phase 2 ì‹œì‘ **ì „ì—** `alias_analyzer.py`ì˜ must-alias ê¸°ëŠ¥ ê²€ì¦
- Parameter aliasing ì •í™•ë„ ì¸¡ì •
- ì •í™•ë„ ë‚®ìœ¼ë©´ Conservative (False Positive í—ˆìš©)

**ê¸°ì¡´ ì¸í”„ë¼ ì¬ì‚¬ìš©**:
```python
class AsyncRaceDetector:
    def __init__(self,
                 call_graph: CallGraph,          # â† ì¬ì‚¬ìš©
                 dfg_builder: DFGBuilder,        # â† ì¬ì‚¬ìš©
                 alias_analyzer: AliasAnalyzer): # â† ì¬ì‚¬ìš© (CRITICAL!)
        self.call_graph = call_graph
        self.dfg = dfg_builder
        self.alias = alias_analyzer

        # âš ï¸  Phase 2 ì „ì— ê²€ì¦ í•„ìš”
        self._validate_alias_accuracy()

    def analyze_async_function(self, func_fqn: str) -> list[RaceCondition]:
        # 1. Get async call graph (ì´ë¯¸ ìˆìŒ)
        async_callees = self._get_async_callees(func_fqn)

        # 2. Find shared variable accesses (DFG ì¬ì‚¬ìš©)
        shared_accesses = self._find_shared_accesses(func_fqn)

        # 3. Check lock protection (NEW)
        locks = self._find_lock_regions(func_fqn)

        # 4. Find await points (NEW)
        await_points = self._find_await_points(func_fqn)

        # 5. Detect races (NEW)
        races = []
        for var, accesses in shared_accesses.items():
            if self._has_race(accesses, locks, await_points):
                races.append(RaceCondition(
                    variable=var,
                    accesses=accesses,
                    reason="Unprotected access with await"
                ))

        return races
```

### 4.5 API Integration

**ReasoningPipeline í†µí•©**:
```python
class ReasoningPipeline:
    def __init__(self, ...):
        ...
        # NEW: Concurrency analyzer
        self.concurrency_analyzer = AsyncRaceDetector(...)

    def analyze_concurrency_issues(self) -> ConcurrencyReport:
        """NEW: ë™ì‹œì„± ë¬¸ì œ ë¶„ì„"""
        races = []
        deadlocks = []

        # Find all async functions
        async_functions = self._find_async_functions()

        for func in async_functions:
            # Race detection
            func_races = self.concurrency_analyzer.analyze(func)
            races.extend(func_races)

        return ConcurrencyReport(
            race_conditions=races,
            deadlocks=deadlocks
        )
```

---

## 5. Phase 3: Differential Analysis (2ì£¼)

### 5.1 ëª©í‘œ

**Security Regression**:
- "Sanitizer ì œê±°ë¨" ìë™ íƒì§€
- "Source â†’ Sink ìƒˆ ê²½ë¡œ" ìë™ íƒì§€

**Performance Regression** (Cost Analysis ê¸°ë°˜):
- "O(n) â†’ O(nÂ²) íšŒê·€" ìë™ íƒì§€

**Breaking Change**:
- Return value semantic ë³€ê²½
- Exception flow ë³€ê²½

### 5.2 êµ¬í˜„ ìœ„ì¹˜

```
src/contexts/reasoning_engine/infrastructure/differential/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ taint_diff_analyzer.py     # Taint before/after ë¹„êµ
â”œâ”€â”€ cost_diff_analyzer.py      # Cost before/after ë¹„êµ
â”œâ”€â”€ semantic_diff_enhancer.py  # ê¸°ì¡´ semantic_differ í™•ì¥
â””â”€â”€ models.py                  # DiffResult, Regression
```

### 5.3 ì•Œê³ ë¦¬ì¦˜

**Taint Differential** (NEW):
```python
class TaintDiffAnalyzer:
    def __init__(self,
                 taint_engine: TaintEngine):  # â† ì¬ì‚¬ìš©
        self.taint = taint_engine

    def analyze_diff(self,
                     repo_id: str,
                     base_snapshot: str,
                     pr_snapshot: str,
                     changed_functions: list[str]) -> TaintDiffResult:

        # âš ï¸  CRITICAL: Scopeë¥¼ impact_closureë¡œ í™•ì¥
        # changed_functionsë§Œìœ¼ë¡œëŠ” regression ë†“ì¹¨
        scope = self._compute_diff_scope(changed_functions)
        # scope = changed_set + callers + callees + data deps
        # 0. âš ï¸  Compute diff scope (impact_closure) â† CRITICAL
        scope = self._compute_diff_scope(changed_functions)
        # scope = changed_set + callers + callees + data deps (2-3 hops)

        # 1. Run taint on both snapshots (í™•ì¥ëœ scope)
        base_vulns = self.taint.analyze(base_snapshot, scope.all_functions)
        pr_vulns = self.taint.analyze(pr_snapshot, scope.all_functions)

        # 2. New vulnerabilities (NEW)
        new_vulns = [v for v in pr_vulns if v not in base_vulns]

        # 3. Fixed vulnerabilities (NEW)
        fixed_vulns = [v for v in base_vulns if v not in pr_vulns]

        # 4. CRITICAL: Sanitizer removed (NEW)
        sanitizer_removed = self._detect_sanitizer_removal(base_vulns, pr_vulns)

        return TaintDiffResult(
            new_vulnerabilities=new_vulns,
            fixed_vulnerabilities=fixed_vulns,
            sanitizer_removed=sanitizer_removed  # â† HIGH severity
        )
```

**Cost Differential** (Cost Analysis ê¸°ë°˜):
```python
class CostDiffAnalyzer:
    def __init__(self,
                 cost_analyzer: CostAnalyzer):  # â† Phase 1ì—ì„œ êµ¬í˜„
        self.cost = cost_analyzer

    def analyze_diff(self, before_code: str, after_code: str) -> CostDiffResult:
        # 1. Analyze both (Phase 1 ì¬ì‚¬ìš©)
        cost_before = self.cost.analyze(before_code)
        cost_after = self.cost.analyze(after_code)

        # 2. Compare (NEW)
        if cost_after.worse_than(cost_before):
            return CostDiffResult(
                regression=True,
                before=cost_before.complexity,
                after=cost_after.complexity,
                message=f"Performance regression: {cost_before} â†’ {cost_after}"
            )

        return CostDiffResult(regression=False)
```

### 5.4 Integration Points

**ê¸°ì¡´ SemanticDiffer í™•ì¥**:
```python
# src/contexts/reasoning_engine/infrastructure/semantic_diff/semantic_differ.py

class SemanticDiffer:
    def __init__(self, ...):
        ...
        # NEW: Specialized diff analyzers
        self.taint_diff = TaintDiffAnalyzer(...)
        self.cost_diff = CostDiffAnalyzer(...)

    def analyze_comprehensive_diff(self,
                                   before: str,
                                   after: str) -> ComprehensiveDiffResult:
        """ê¸°ì¡´ semantic diff + taint diff + cost diff"""

        # 1. Existing semantic diff (ì´ë¯¸ ìˆìŒ)
        semantic = self.analyze_effects(before, after)

        # 2. NEW: Taint diff
        taint = self.taint_diff.analyze_diff(before, after)

        # 3. NEW: Cost diff
        cost = self.cost_diff.analyze_diff(before, after)

        return ComprehensiveDiffResult(
            semantic_changes=semantic,
            security_regressions=taint.new_vulnerabilities,
            sanitizer_removed=taint.sanitizer_removed,  # â† CRITICAL
            performance_regressions=cost.regressions,
            breaking_changes=semantic.breaking_changes
        )
```

---

## 6. Integration Architecture (í†µí•© ì „ëµ)

### 6.1 Two-Pipeline Pattern

**í•µì‹¬ êµ¬ì¡°**: ìƒì„± íŒŒì´í”„ë¼ì¸ + ì‚¬ìš© íŒŒì´í”„ë¼ì¸

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline 1: Indexing (ìƒì„±)                   â”‚
â”‚ src/contexts/analysis_indexing/               â”‚
â”‚                                                â”‚
â”‚ 9-Stage Pipeline:                              â”‚
â”‚ 1. Git â†’ 2. Discovery â†’ 3. Parsing            â”‚
â”‚ 4. IR (CFG/DFG/SSA) â­                        â”‚
â”‚ 5. Semantic IR â†’ 6. Graph                     â”‚
â”‚ 7. Chunk â†’ 8. RepoMap â†’ 9. Index             â”‚
â”‚                                                â”‚
â”‚ Output: IR, Graph, Chunk, Index               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ produces
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Pipeline 2: Reasoning (ì‚¬ìš©)                  â”‚
â”‚ src/contexts/reasoning_engine/                â”‚
â”‚                                                â”‚
â”‚ ReasoningPipeline:                             â”‚
â”‚ - analyze_effects()                            â”‚
â”‚ - analyze_impact()                             â”‚
â”‚ - simulate_patch()                             â”‚
â”‚ âœ… - analyze_cost() (NEW)                     â”‚
â”‚ âœ… - analyze_concurrency() (NEW)              â”‚
â”‚ âœ… - analyze_pr_diff() (NEW)                  â”‚
â”‚                                                â”‚
â”‚ Input: IR, Graph (from Pipeline 1)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 Integration Points (4ê³³)

#### **Point 1: IRStage (ì‹¤ì‹œê°„ ì¦ë¶„ ëª¨ë“œ)** âš¡ Real-time

**ìœ„ì¹˜**: `src/contexts/analysis_indexing/infrastructure/stages/ir_stage.py`

**í†µí•© ë°©ì‹**: IR ìƒì„± ì§í›„ ì¦‰ì‹œ ë¶„ì„
```python
class IRStage(BaseStage):
    def __init__(self, ...,
                 cost_analyzer=None,           # â† DI ì¶”ê°€
                 concurrency_analyzer=None):   # â† DI ì¶”ê°€
        super().__init__(...)
        self.cost_analyzer = cost_analyzer
        self.concurrency_analyzer = concurrency_analyzer

    async def execute(self, ctx: StageContext) -> StageContext:
        # 1. IR ìƒì„± (ê¸°ì¡´)
        ir_docs = {}
        for file in ctx.files:
            ir_doc = self.ir_builder.build(file)
            ir_docs[file] = ir_doc

            # âœ… 2. ìƒì„± ì§í›„ ì¦‰ì‹œ ë¶„ì„ (ì‹¤ì‹œê°„)
            if ctx.config.enable_realtime_analysis:
                # Cost analysis (per-file, )
                if self.cost_analyzer:
                    cost = self.cost_analyzer.analyze_ir(ir_doc)
                    ctx.analysis_results[f"cost:{file}"] = cost

                # Concurrency (async only, )
                if self.concurrency_analyzer and ir_doc.has_async:
                    races = self.concurrency_analyzer.analyze_ir(ir_doc)
                    ctx.analysis_results[f"race:{file}"] = races

        ctx.ir_docs = ir_docs
        return ctx
```

**ìš©ë„**: IDE ì €ì¥ ì‹œ ì¦‰ì‹œ ê²½ê³  (íŒŒì¼ ë‹¨ìœ„)
**Target**: 100- per file
**Mode**: Incremental only

---

#### **Point 2: ReasoningPipeline (PR/Audit ëª¨ë“œ)** ğŸ” Deep Analysis

**ìœ„ì¹˜**: `src/contexts/reasoning_engine/application/reasoning_pipeline.py`

**í†µí•© ë°©ì‹**: ì „ì²´ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
```python
class ReasoningPipeline:
    def __init__(self,
                 graph: GraphDocument,
                 workspace_root: str | None = None,
                 # âœ… NEW: DI ì¶”ê°€
                 cost_analyzer=None,
                 concurrency_analyzer=None,
                 differential_analyzer=None):

        self.ctx = ReasoningContext(graph=graph)

        # ê¸°ì¡´
        self.effect_differ = EffectAnalyzerAdapter()
        self.impact_analyzer = ImpactAnalyzerAdapter(graph, max_depth=5)
        self.slicer = SlicerAdapter(graph)
        self.risk_analyzer = RiskAnalyzerAdapter()

        # âœ… NEW
        self.cost_analyzer = cost_analyzer
        self.concurrency_analyzer = concurrency_analyzer
        self.differential = differential_analyzer

    # âœ… NEW ë©”ì„œë“œë“¤
    def analyze_cost(self, functions: list[str]) -> dict[str, CostResult]:
        """Cost ë¶„ì„ (ì „ì²´ ì»¨í…ìŠ¤íŠ¸)"""
        results = {}
        for func in functions:
            # Graphì—ì„œ IR ê°€ì ¸ì˜¤ê¸°
            ir_doc = self._get_ir_for_function(func)
            cost = self.cost_analyzer.analyze_ir(ir_doc)
            results[func] = cost
        return results

    def analyze_concurrency(self, async_functions: list[str]) -> ConcurrencyReport:
        """Concurrency ë¶„ì„"""
        races = []
        for func in async_functions:
            ir_doc = self._get_ir_for_function(func)
            func_races = self.concurrency_analyzer.analyze_ir(ir_doc)
            races.extend(func_races)
        return ConcurrencyReport(races=races)

    def analyze_pr_diff(self,
                        repo_id: str,
                        base_snapshot: str,
                        pr_snapshot: str,
                        changed_functions: list[str]) -> DiffReport:
        """Differential ë¶„ì„ (PR review)"""

        # 1. Scope í™•ì¥ (impact_closure)
        scope = self._compute_impact_closure(changed_functions)

        # 2. Taint diff
        taint_diff = self.differential.analyze_taint_diff(
            repo_id, base_snapshot, pr_snapshot, scope
        )

        # 3. Cost diff (Phase 1 ì™„ë£Œ í›„)
        cost_diff = self.differential.analyze_cost_diff(
            repo_id, base_snapshot, pr_snapshot, scope
        )

        # 4. Breaking change (ê¸°ì¡´)
        breaking = self.effect_differ.analyze_breaking(...)

        return DiffReport(
            security_regressions=taint_diff.new_vulnerabilities,
            sanitizer_removed=taint_diff.sanitizer_removed,  # CRITICAL
            performance_regressions=cost_diff.regressions,
            breaking_changes=breaking
        )

    def _get_ir_for_function(self, func_fqn: str):
        """Graphì—ì„œ IR ì¶”ì¶œ (ë˜ëŠ” ìºì‹œ/ì¬ìƒì„±)"""
        # Graphì— IRì´ ì €ì¥ë˜ì–´ ìˆê±°ë‚˜
        # íŒŒì¼ ê²½ë¡œë¥¼ ì°¾ì•„ì„œ ì¬íŒŒì‹±
        ...
```

**ìš©ë„**: PR ë¦¬ë·°, ì „ì²´ ê°ì‚¬
**Target**: 2-5ì´ˆ per PR (10-50 files)
**Mode**: Full + Incremental

---

#### **Point 3: API Routes (HTTP)** ğŸŒ External

**ìœ„ì¹˜**: `server/api_server/routes/agent.py`

**í†µí•© ë°©ì‹**: HTTP ì—”ë“œí¬ì¸íŠ¸
```python
# ê¸°ì¡´ Mock ì œê±°í•˜ê³  ì‹¤ì œ êµ¬í˜„

@router.post("/analyze", response_model=AnalyzeResponse)
async def analyze_code(request: AnalyzeRequest):
    """ì½”ë“œ ë¶„ì„ (Cost + Concurrency + Taint + Null)"""
    try:
        # 1. Get graph
        foundation = container._foundation
        graph = foundation.graph_store.get_latest_graph(request.repo_path)

        # 2. Create ReasoningPipeline
        pipeline = ReasoningPipeline(
            graph=graph,
            cost_analyzer=foundation.cost_analyzer,
            concurrency_analyzer=foundation.race_detector,
            differential_analyzer=foundation.differential_analyzer
        )

        # 3. Run analyses
        files = request.files or []

        # Cost
        cost_results = pipeline.analyze_cost(files)

        # Concurrency
        concurrency_results = pipeline.analyze_concurrency(files)

        # 4. Convert to issues
        issues = []

        for func, cost in cost_results.items():
            if cost.is_slow():
                issues.append({
                    "severity": cost.severity,
                    "type": "performance",
                    "message": cost.explanation,
                    "verdict": cost.verdict,  # â† proven/likely/heuristic
                    "evidence": cost.evidence.to_dict()
                })

        for race in concurrency_results.races:
            issues.append({
                "severity": "critical",
                "type": "race_condition",
                "message": race.explanation,
                "verdict": race.verdict,
                "evidence": race.evidence.to_dict()
            })

        return AnalyzeResponse(
            summary=f"Found {len(issues)} issues",
            issues=issues,
            recommendations=_generate_recommendations(issues)
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# âœ… NEW: PR Diff ì „ìš© ì—”ë“œí¬ì¸íŠ¸
@router.post("/analyze/pr-diff", response_model=DiffResponse)
async def analyze_pr_diff(request: PRDiffRequest):
    """PR Differential Analysis"""
    foundation = container._foundation
    graph = foundation.graph_store.get_graph(request.repo_id)

    pipeline = ReasoningPipeline(
        graph=graph,
        differential_analyzer=foundation.differential_analyzer
    )

    diff_report = pipeline.analyze_pr_diff(
        request.repo_id,
        request.base_snapshot,
        request.pr_snapshot,
        request.changed_files
    )

    return DiffResponse(
        security_regressions=diff_report.security_regressions,
        performance_regressions=diff_report.performance_regressions,
        sanitizer_removed=diff_report.sanitizer_removed,  # CRITICAL
        breaking_changes=diff_report.breaking_changes
    )
```

---

#### **Point 4: MCP Server (IDE í†µí•©)** ğŸ’¡ IDE

**ìœ„ì¹˜**: `server/mcp_server/handlers/`

**í†µí•© ë°©ì‹**: MCP í”„ë¡œí† ì½œ (VSCode/Cursor)
```python
# server/mcp_server/handlers/analyze_cost.py (ì‹ ê·œ)

from mcp.server import Server
from src.container import container

mcp = Server("semantica-cost")

@mcp.tool()
async def analyze_function_cost(
    file_path: str,
    function_name: str,
    line_number: int
) -> dict:
    """
    IDEì—ì„œ í•¨ìˆ˜ ìœ„ì— ì»¤ì„œ ë†“ìœ¼ë©´ ì¦‰ì‹œ ë¶„ì„

    Target: <
    Trigger: onHover, onSave
    """
    # 1. Get cached IR (ë¹ ë¦„)
    foundation = container._foundation
    ir_doc = foundation.ir_cache.get_or_build(file_path)

    # 2. Find function at line
    func = ir_doc.find_function_at_line(line_number)

    # 3. Cost analysis (cached, incremental)
    cost = foundation.cost_analyzer.analyze_function(func.fqn)

    # 4. Return for IDE tooltip
    return {
        "complexity": str(cost.complexity),
        "verdict": cost.verdict,
        "confidence": cost.confidence,
        "message": cost.explanation,
        "hotspots": [
            {"line": h.line, "reason": h.reason}
            for h in cost.evidence.hotspots
        ],
        # IDE tooltip
        "tooltip": f"âš ï¸  {cost.complexity} (í™•ì‹ ë„: {cost.confidence:.0%})"
    }

@mcp.tool()
async def check_race_conditions(
    file_path: str
) -> list[dict]:
    """
    íŒŒì¼ ì €ì¥ ì‹œ ìë™ ì²´í¬

    Target: <
    Trigger: onSave
    """
    foundation = container._foundation
    ir_doc = foundation.ir_cache.get_or_build(file_path)

    # Async functions only
    if not ir_doc.has_async:
        return []

    races = foundation.race_detector.analyze_file(ir_doc)

    return [
        {
            "line": race.line,
            "variable": race.shared_identity.var_name,
            "severity": "error" if race.verdict == "proven" else "warning",
            "message": race.explanation,
            "evidence": race.evidence.to_dict()
        }
        for race in races
    ]
```

---

### 6.3 Container Integration (DI)

**FoundationContainerì— ë“±ë¡** (í•µì‹¬):

```python
# src/contexts/code_foundation/infrastructure/di.py

class FoundationContainer:
    def __init__(self, settings, infra_container):
        self.settings = settings
        self._infra = infra_container

    # ============================================================
    # âœ… NEW: Analysis Components (RFC-028)
    # ============================================================

    @cached_property
    def cost_analyzer(self):
        """Cost Analyzer (RFC-028 Phase 1)"""
        from .analyzers.cost import CostAnalyzer

        return CostAnalyzer(
            sccp_engine=self.sccp_engine,
            ssa_builder=self.ssa_builder,
            cfg_provider=self.cfg_provider,
            cache=self._infra.redis  # ìºì‹œ ì¬ì‚¬ìš©
        )

    @cached_property
    def race_detector(self):
        """Concurrency Analyzer (RFC-028 Phase 2)"""
        from .analyzers.concurrency import AsyncRaceDetector

        return AsyncRaceDetector(
            call_graph=self.call_graph,
            dfg_builder=self.dfg_builder,
            alias_analyzer=self.alias_analyzer,  # âš ï¸  Pre-check í•„ìš”
            mode="ide"  # Default: IDE mode (FP ìµœì†Œ)
        )

    @cached_property
    def differential_analyzer(self):
        """Differential Analyzer (RFC-028 Phase 3)"""
        from ..reasoning_engine.infrastructure.differential import DifferentialAnalyzer

        return DifferentialAnalyzer(
            taint_engine=self.taint_engine,
            cost_analyzer=self.cost_analyzer,  # Phase 1 ì™„ë£Œ í›„
            semantic_differ=self.semantic_differ,
            impact_analyzer=self.impact_analyzer
        )

    # ============================================================
    # Existing Components (ì¬ì‚¬ìš©)
    # ============================================================

    @cached_property
    def sccp_engine(self):
        """SCCP Engine (ì¬ì‚¬ìš©)"""
        from .dfg.constant import ConstantPropagationAnalyzer
        return ConstantPropagationAnalyzer()

    @cached_property
    def alias_analyzer(self):
        """Alias Analyzer (ì¬ì‚¬ìš©, âš ï¸  Phase 2 ì „ ê²€ì¦)"""
        from .analyzers import AliasAnalyzer
        return AliasAnalyzer()

    # ... ê¸°íƒ€ ê¸°ì¡´ ì»´í¬ë„ŒíŠ¸
```

---

### 6.4 Mode-Specific Configuration

**ëª¨ë“œë³„ ë™ì‘ ì°¨ì´** (ì¤‘ìš”):

```python
# IDE Mode (ì‹¤ì‹œê°„, Point 1 + Point 4)
config = AnalysisConfig(
    mode="ide",
    timeout_ms=100,  # Cost
    enable_heuristic=True,
    heuristic_verdict_level="hidden",  # HeuristicëŠ” ìˆ¨ê¹€
    false_positive_tolerance="low"  # FP ìµœì†Œí™”
)

# PR Review Mode (Point 2 + Point 3)
config = AnalysisConfig(
    mode="pr",
    timeout_ms=5000,  # 5ì´ˆ
    enable_heuristic=True,
    heuristic_verdict_level="warning",  # Heuristic ê²½ê³ ë¡œ í‘œì‹œ
    false_negative_tolerance="low"  # FN ìµœì†Œí™” (ë³´ìˆ˜ì )
)

# Audit Mode (Deep, Point 2)
config = AnalysisConfig(
    mode="audit",
    timeout_ms=30000,  # 30ì´ˆ
    enable_full_biabduction=True,
    false_negative_tolerance="zero"  # FN ì ˆëŒ€ ë°©ì§€
)
```

**Analyzerì—ì„œ ì‚¬ìš©**:
```python
class AsyncRaceDetector:
    def __init__(self, ..., mode: str = "ide"):
        self.mode = mode

    def analyze_ir(self, ir_doc) -> list[RaceCondition]:
        races = self._detect_races(ir_doc)

        # Mode-specific filtering
        if self.mode == "ide":
            # Heuristic verdictëŠ” ìˆ¨ê¹€
            races = [r for r in races if r.verdict != "heuristic"]
        elif self.mode in ("pr", "audit"):
            # Heuristicë„ í‘œì‹œ (ë³´ìˆ˜ì )
            pass

        return races
```

---

## 7. Implementation Roadmap (ìˆ˜ì •)

### Week 1-2: Cost Analysis Foundation
```
Day 1-2:  Loop bound inference (pattern matching - Pythonic patterns)
Day 3:    âš ï¸  Unbounded loop handling (Heuristic + confidence)
Day 4-5:  SCCP integration (constant bounds ì¬ì‚¬ìš©)
Day 6-7:  Complexity calculator (O(n), O(nÂ²))
Day 8-9:  Cost cache + incremental
Day 10:   Unit tests (íŠ¹íˆ unbounded loop cases)
```

### Week 3-4: Cost Analysis Integration (4 Points)
```
Day 11:    FoundationContainerì— cost_analyzer ë“±ë¡
Day 12:    âœ… Point 1: IRStage í†µí•© (ì‹¤ì‹œê°„ ëª¨ë“œ)
Day 13:    âœ… Point 2: ReasoningPipeline í†µí•© (PR/Audit ëª¨ë“œ)
Day 14:    âœ… Point 3: API Routes í†µí•© (/agent/analyze)
Day 15:    âœ… Point 4: MCP Server í†µí•© (IDE)
Day 16:    Cost diff analyzer êµ¬í˜„
Day 17:    Mode-specific config (IDE/PR/Audit)
Day 18:    End-to-end testing + benchmarking
```

### Week 5-6: Concurrency Analysis
```
Day 19:    âš ï¸  Pre-check: AliasAnalyzer must-alias ì •í™•ë„ ì¸¡ì •
Day 20-21: Shared variable tracker (+ escape analysis)
Day 22-23: Lock region detector (with alias resolution)
Day 24-25: Await point analyzer (Python async íŠ¹í™”)
Day 26-27: Race detector (RacerD-inspired, lightweight)
Day 28:    âœ… 4-Point Integration (IRStage/Pipeline/API/MCP)
Day 29:    Mode-specific filtering (IDE/PR/Audit)
Day 30:    Testing (FastAPI/Django) + False Positive íŠœë‹
```

### Week 7-8: Differential Analysis + Integration
```
Day 31-32: Taint diff analyzer (sanitizer removal detection)
Day 33-34: Cost diff analyzer (performance regression)
Day 35-36: Scope í™•ì¥ (impact_closure ìë™ ê³„ì‚°)
Day 37:    SemanticDiffer enhancement
Day 38:    âœ… 4-Point Integration
Day 39:    Mode-specific behavior (PR/Audit)
Day 40:    End-to-end PR testing
Day 41:    MCP Server finalization (IDE tooltips)
Day 42:    Documentation + API docs
```

---

## 7. Success Metrics (Verdictë³„)

### Cost Analysis (Verdict-based KPI)
- [ ] **Proven** (pattern, sccp):
  - Precision: 95%+
  - Coverage: Simple loops (for, while with constant)
- [ ] **Likely** (widening):
  - Precision: 85%+
  - Coverage: Simple while loops
- [ ] **Heuristic** (unbounded fallback):
  - Warning acceptance rate: 20%+ (ê°œë°œìê°€ ìˆ˜ìš© ê°€ëŠ¥í•œ ë¹„ìœ¨)
  - Upper bound conservativeness: Actual < Predicted (90%+)
- [ ] **Performance**:
  - Real-time:  per function (incremental)
  - IDE integration: "ëŠë¦° ì½”ë“œ" ì‹¤ì‹œê°„ í‘œì‹œ

### Concurrency Analysis (Verdict-based KPI)
- [ ] **Proven** (must-alias resolved):
  - Precision: 90%+ (FP 10% ì´í•˜)
  - Recall: 85%+
- [ ] **Heuristic** (alias unresolved):
  - IDE ëª¨ë“œ: ê¸°ë³¸ ìˆ¨ê¹€ (noise ë°©ì§€)
  - PR/AUDIT ëª¨ë“œ: í‘œì‹œí•˜ë˜ severity ë‚®ì¶¤
- [ ] **Performance**:
  - Real-time:  per async function
  - FastAPI/Django async ì§€ì›

### Differential Analysis (Verdict-based KPI)
- [ ] **Sanitizer Removal** (proven):
  - Recall: 100% (ë†“ì¹˜ë©´ ì•ˆ ë¨)
  - Precision: 95%+
- [ ] **Performance Regression** (proven + likely):
  - Recall: 90%+ (O(n) â†’ O(nÂ²))
  - Precision: 85%+
- [ ] **Breaking Change** (proven):
  - Recall: 85%+
  - Precision: 90%+
- [ ] **Scope Coverage**:
  - Impact closure depth: 2-3 hops (BFS)
  - Coverage: changed + 80%+ of direct callers

---

## 8. API Surface (RFC-LLM-001 Integration)

### 8.1 Internal API (Phase ì™„ë£Œ í›„)

```python
# Cost Analysis
cost_analyzer.analyze_function("process_data")
â†’ CostResult(complexity=O(nÂ²), bottlenecks=[...])

# Concurrency Analysis
concurrency_analyzer.analyze_async_function("handle_request")
â†’ [RaceCondition(variable="cache", ...)]

# Differential Analysis
differential_analyzer.analyze_pr_diff(base_snapshot, pr_snapshot)
â†’ DiffResult(
    security_regressions=[...],
    performance_regressions=[...],
    sanitizer_removed=[...]  # CRITICAL
)
```

### 8.2 External API (RFC-LLM-001 ì—°ë™)

```python
# POST /execute with AnalyzeSpec
{
  "intent": "analyze",
  "template_id": "performance_regression",
  "scope": {
    "base_snapshot": "snap_before",
    "pr_snapshot": "snap_after",
    "changed_files": [...]
  }
}

# Response: ResultEnvelope
{
  "claims": [
    {
      "type": "performance_regression",
      "confidence_basis": "proven",  # Cost analysis proof
      "severity": "high",
      "proof_obligation": {
        "before_complexity": "O(n)",
        "after_complexity": "O(nÂ²)",
        "bottleneck_location": "line 42"
      }
    },
    {
      "type": "security_regression",
      "confidence_basis": "proven",  # Taint diff proof
      "severity": "critical",
      "proof_obligation": {
        "sanitizer_removed": "escape() call removed",
        "vulnerable_path": "request â†’ execute"
      }
    }
  ],
  "evidences": [...]
}
```

---

## 9. Testing Strategy

### Unit Tests
```
src/contexts/code_foundation/tests/analyzers/cost/
â”œâ”€â”€ test_loop_bound_inference.py
â”œâ”€â”€ test_complexity_calculator.py
â””â”€â”€ test_cost_cache.py

src/contexts/code_foundation/tests/analyzers/concurrency/
â”œâ”€â”€ test_race_detector.py
â”œâ”€â”€ test_lock_analyzer.py
â””â”€â”€ test_async_race.py

src/contexts/reasoning_engine/tests/differential/
â”œâ”€â”€ test_taint_diff.py
â”œâ”€â”€ test_cost_diff.py
â””â”€â”€ test_sanitizer_removal.py
```

### Integration Tests
```
tests/integration/
â”œâ”€â”€ test_cost_analysis_end_to_end.py
â”œâ”€â”€ test_concurrency_fastapi.py
â””â”€â”€ test_pr_diff_analysis.py
```

### Benchmark
```
benchmark/_external_benchmark/
â”œâ”€â”€ cost_analysis_benchmark.py    # Inferì™€ ë¹„êµ
â”œâ”€â”€ concurrency_benchmark.py      # RacerDì™€ ë¹„êµ
â””â”€â”€ diff_analysis_benchmark.py    # Manual reviewì™€ ë¹„êµ
```

---

## 10. Dependencies & Risks

### Dependencies

| Component | Status | Must-Check Before Use |
|-----------|--------|----------------------|
| SCCP Engine | âœ… Ready | None |
| SSA Builder | âœ… Ready | None |
| CFG Builder | âœ… Ready | None |
| Call Graph | âœ… Ready | None |
| Taint Engine | âœ… Ready | None |
| Semantic Differ | âœ… Ready | None |
| **Alias Analyzer** | âš ï¸  Exists | **Phase 2 ì „ must-alias ì •í™•ë„ ì¸¡ì • í•„ìˆ˜** |
| Impact Analyzer | âœ… Ready | Scope expansionìš© ì¬ì‚¬ìš© |
| Escape Analysis | âŒ Needed | Concurrencyì—ì„œ êµ¬í˜„ í•„ìš” |

### Risks & Mitigations

1. **Cost Analysis: Unbounded Loop** (High) â­ CRITICAL
   - **Risk**: `while True:`, ë³µì¡í•œ ì¬ê·€ â†’ Bound ì¶”ë¡  ì‹¤íŒ¨
   - âŒ **BAD Mitigation**: "Unknown" ë¦¬í„´ â†’ IDEì—ì„œ "ë¶„ì„ ë¶ˆê°€"
   - âœ… **GOOD Mitigation**: Heuristic Bound (O(n)) + `confidence: 0.2-0.3`
   - **Rationale**: IDE UX ê´€ì ì—ì„œ "ëª¨ë¥´ê² ë‹¤" < "ìœ„í—˜í•  ìˆ˜ ìˆë‹¤" (actionable)
   - **Fallback**: Conservative O(nÂ²) ê°€ì • + Warning

2. **Concurrency: Context Sensitivity** (High) â­ CRITICAL
   - **Risk**: Lockì´ í•¨ìˆ˜ ì¸ìë¡œ ì „ë‹¬ â†’ Alias ë¶„ì„ ì‹¤íŒ¨ â†’ False Positive
   - **Pre-check**: Phase 2 ì‹œì‘ ì „ `alias_analyzer.py` must-alias ì •í™•ë„ ì¸¡ì •
   - **Mitigation**: Must-alias ì‹¤íŒ¨ ì‹œ Conservative (Protectedë¡œ ê°„ì£¼)
   - **Fallback**: Lock pattern í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: `self._lock` í•„ë“œë§Œ)

3. **Differential ë…¸ì´ì¦ˆ** (Low)
   - **Risk**: ì‚¬ì†Œí•œ ë³€ê²½ì—ë„ ê³¼ë„í•œ ê²½ê³ 
   - **Mitigation**: Severity-based filtering (CRITICALë§Œ ê¸°ë³¸ í‘œì‹œ)
   - **Fallback**: User feedback loop (false alarm í•™ìŠµ)

---

## 11. Best Practices & Critical Checkpoints

### ğŸ† Best Highlights (ì‹ ì˜ í•œ ìˆ˜)

**A. Cost Analysis: Loop Bound Inference**
- Pattern matchingìœ¼ë¡œ Pythonic íŒ¨í„´ (`range(n)`, `len(arr)`) ì¶”ë¡ 
- SCCP ìƒìˆ˜ ì¬ì‚¬ìš© (SMT Solver ì•ˆ ì¨ë„ ë¨)
- **Why Good**: ì‹¤ì‹œê°„ì„±() ë³´ì¥ + ê°€ì„±ë¹„ ìµœê³ 

**B. Concurrency: Await Point Detection**
- Python async íŠ¹ì„±: `await` ì§€ì ì—ì„œë§Œ ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­
- ëª¨ë“  ëª…ë ¹ì–´ ê²€ì‚¬ X, await ì „í›„ë§Œ ì²´í¬
- **Why Good**: False Positive íšê¸°ì  ê°ì†Œ

**C. Differential: Sanitizer Removal Detection**
- ë‹¨ìˆœ ì·¨ì•½ì  ê°œìˆ˜ ë¹„êµ X
- "ë°©ì–´ë§‰(Sanitizer)ì´ ì‚¬ë¼ì¡ŒëŠ”ê°€?" ì²´í¬
- **Why Good**: ë³´ì•ˆ íŒ€ God Feature

### âš ï¸ Critical Checkpoints (êµ¬í˜„ ì‹œ ì£¼ì˜ì‚¬í•­)

**Checkpoint 1: Cost Analysis - Unbounded Loop Handling**

**Risk**: `while True:`, ë³µì¡í•œ ì¬ê·€ â†’ Bound ì¶”ë¡  ì‹¤íŒ¨
```python
# ì¶”ë¡  ì–´ë ¤ìš´ ì¼€ì´ìŠ¤
while True:
    if complex_condition():
        break

def recursive_func(n):
    if random_condition():
        return recursive_func(n - 1)
```

**âŒ BAD Approach**:
```python
return CostResult(complexity=ComplexityClass.UNKNOWN)
# â†’ IDE: "ë¶„ì„ ë¶ˆê°€(ë³µì¡í•¨)" (not actionable)
```

**âœ… GOOD Approach**:
```python
return CostResult(
    complexity=ComplexityClass.LINEAR,  # Heuristic: O(n) ê°€ì •
    confidence=0.2,  # Low confidence
    explanation="ì¶”ë¡  ì‹¤íŒ¨, ë³´ìˆ˜ì ìœ¼ë¡œ O(n) ê°€ì •"
)
# â†’ IDE: "ì ì¬ì  ì„±ëŠ¥ ìœ„í—˜ (í™•ì‹ ë„ ë‚®ìŒ)" (actionable)
```

**Implementation**:
```python
# src/contexts/code_foundation/infrastructure/analyzers/cost/loop_bound_analyzer.py

def _infer_loop_bound(self, loop: LoopNode) -> BoundResult:
    # 1. Pattern matching (Fast path) â†’ proven
    if loop.is_for_range():
        return BoundResult(
            bound=loop.range_arg(),
            verdict="proven",
            confidence=1.0,
            method="pattern",
            evidence=CostEvidence(
                loop_bounds=[LoopBound(
                    loop_id=loop.id,
                    bound_expr=str(loop.range_arg()),
                    method="pattern",
                    confidence=1.0,
                    location=(loop.file, loop.line)
                )],
                cost_term=CostTerm("symbol", value=str(loop.range_arg())),
                hotspots=[],
                inference_method="pattern"
            )
        )

    # 2. SCCP constant (Fast path) â†’ proven
    if loop.condition_is_constant():
        const = self.sccp.get_constant(loop.limit_var)
        return BoundResult(
            bound=const,
            verdict="proven",
            confidence=0.95,
            method="sccp",
            evidence=CostEvidence(...)
        )

    # 3. Widening (Medium path) â†’ likely
    if loop.is_simple_while():
        return BoundResult(
            bound=Symbolic("n"),
            verdict="likely",
            confidence=0.8,
            method="widening",
            evidence=CostEvidence(...)
        )

    # 4. âš ï¸  FALLBACK: Unbounded â†’ heuristic + upper_bound_hint
    # âŒ BAD: return BoundResult(bound=Symbolic("n"), confidence=0.2)
    # âœ… GOOD: UNKNOWN + conservative upper bound
    return BoundResult(
        bound=Unknown(),
        verdict="heuristic",
        confidence=0.2,
        method="heuristic",
        upper_bound_hint="O(nÂ²)",  # Conservative (worst-case)
        warning="Unbounded loop: worst-case O(nÂ²) assumed",
        evidence=CostEvidence(
            loop_bounds=[LoopBound(
                loop_id=loop.id,
                bound_expr="unknown",
                method="heuristic",
                confidence=0.2,
                location=(loop.file, loop.line)
            )],
            cost_term=CostTerm("unknown"),
            hotspots=[],
            inference_method="heuristic"
        ),
        explanation="Unknown termination: ë³´ìˆ˜ì  O(nÂ²) ê²½ê³ "
    )
```

**UX Mapping** (IDE):
```python
if result.verdict == "proven":
    show_warning(severity="HIGH", color="red")
elif result.verdict == "likely":
    show_warning(severity="MEDIUM", color="yellow")
elif result.verdict == "heuristic":
    show_hint(severity="INFO", color="blue",
              message=f"ìƒí•œ ë¯¸í™•ì •: worst-case {result.upper_bound_hint}")
```

**Checkpoint 2: Concurrency - Context Sensitivity (Alias ì˜ì¡´ì„±)**

**Risk**: Lock ê°ì²´ê°€ í•¨ìˆ˜ ì¸ìë¡œ ì „ë‹¬ â†’ Alias ì‹¤íŒ¨ â†’ False Positive

```python
async def process(self, lock: asyncio.Lock):
    async with lock:        # â† lock ë³€ìˆ˜
        self.count += 1     # Protected?

async def worker(self):
    my_lock = asyncio.Lock()
    await self.process(my_lock)  # lock === my_lock? (Must-alias needed)
```

**Pre-check Required** (Phase 2 ì‹œì‘ ì „):
```python
# Verify alias_analyzer.py accuracy
def test_must_alias_accuracy():
    """
    Must-alias ì •í™•ë„ ì¸¡ì •

    Target: 90%+ for parameter aliasing
    """
    test_cases = [
        ("lock === my_lock", True),   # Parameter passing
        ("self._lock === lock", False), # Field vs parameter
        ...
    ]

    for case, expected in test_cases:
        result = alias_analyzer.must_alias(case.lhs, case.rhs)
        assert result == expected
```

**Mitigation** (Alias ì •í™•ë„ ë‚®ì„ ì‹œ) â€” **ëª¨ë“œë³„ Verdict ì¡°ì •**:
```python
class AsyncRaceDetector:
    def __init__(self, ..., mode: Literal["ide", "pr", "audit"]):
        self.mode = mode

    def _is_protected_by_lock(self, access: VarAccess, locks: list[Lock]) -> ProtectionResult:
        for lock in locks:
            # Must-alias check (CRITICAL)
            if self.alias.must_alias(access.in_scope, lock.scope):
                return ProtectionResult(
                    protected=True,
                    verdict="proven",
                    confidence=0.95
                )

        # âš ï¸  Alias ì‹¤íŒ¨ ì‹œ â€” Mode-specific policy
        if self.alias.resolve_failed(access.in_scope, locks):
            if self.mode == "ide":
                # IDE: False Positive ì¤„ì´ê¸° â†’ verdict ë‚®ì¶¤
                return ProtectionResult(
                    protected=True,  # ë³´í˜¸ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ (ê²½ê³  ìˆ¨ê¹€)
                    verdict="heuristic",
                    confidence=0.3,
                    explanation="Alias ë¯¸í•´ê²°: IDE ëª¨ë“œì—ì„œ ê²½ê³  ìˆ¨ê¹€"
                )
            else:  # pr, audit
                # PR/AUDIT: False Negative ë°©ì§€ â†’ ë³´ìˆ˜ì 
                return ProtectionResult(
                    protected=False,  # ë³´í˜¸ ì•ˆ ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
                    verdict="heuristic",
                    confidence=0.4,
                    explanation="Alias ë¯¸í•´ê²°: ë³´ìˆ˜ì ìœ¼ë¡œ unprotected íŒì •",
                    evidence=ConcurrencyEvidence(
                        shared_identity=...,
                        lock_regions=[
                            LockRegion(
                                ...,
                                resolved_alias=False  # â† Evidenceì— ê¸°ë¡!
                            )
                        ]
                    )
                )

        return ProtectionResult(protected=False, verdict="proven", confidence=0.95)
```

**í•µì‹¬**: ê²°ë¡ (protected=True/False)ì„ ë°”ê¾¸ì§€ ë§ê³ , **verdictë¥¼ ì¡°ì •**í•´ì„œ ëª¨ë“œë³„ ì²˜ë¦¬

---

## 12. Conclusion

### Why This Matters
1. **Cost Analysis**: IDE ì‹¤ì‹œê°„ ì„±ëŠ¥ ê²½ê³  â†’ ê°œë°œì ìƒì‚°ì„± â†‘
2. **Concurrency**: Python async ì•ˆì „ì„± â†’ í”„ë¡œë•ì…˜ ë²„ê·¸ â†“
3. **Differential**: PR ìë™ ë¦¬ë·° â†’ ë³´ì•ˆ/ì„±ëŠ¥ íšŒê·€ ì¡°ê¸° ë°œê²¬

### Timeline Summary
- **Week 1-2**: Cost Analysis êµ¬í˜„
- **Week 3-4**: Cost 4-Point Integration (IRStage, Pipeline, API, MCP)
- **Week 5-6**: Concurrency (alias pre-check + 4-Point Integration)
- **Week 7-8**: Differential (scope í™•ì¥ + 4-Point Integration)
- **Total**: 6-8ì£¼

### Critical Success Factors
1. âš ï¸  **Unbounded loop**: UNKNOWN + upper_bound_hint (not O(n) ê³ ì •)
2. âš ï¸  **Alias accuracy**: Phase 2 ì „ must-alias ì •í™•ë„ ì¸¡ì • í•„ìˆ˜
3. âš ï¸  **Mode separation**: IDE(FP ìµœì†Œ) vs PR/Audit(FN ìµœì†Œ)
4. âœ… **4-Point Integration**: IRStage, ReasoningPipeline, API, MCP
5. âœ… **Incremental**: ê¸°ì¡´ ìºì‹± ì¸í”„ë¼ ì¬ì‚¬ìš©
6. âœ… **Low Hanging Fruit**: Cost Analysisë¶€í„° (ì‰½ê³  íš¨ê³¼ í¼)

### Integration Checklist (ê° Phaseë§ˆë‹¤)
- [ ] **Point 1**: IRStage (ì‹¤ì‹œê°„ ì¦ë¶„,  ëª©í‘œ)
- [ ] **Point 2**: ReasoningPipeline (PR/Audit, 2-5ì´ˆ ëª©í‘œ)
- [ ] **Point 3**: API Routes (HTTP, Mock ì œê±°)
- [ ] **Point 4**: MCP Server (IDE tooltip, < ëª©í‘œ)

### Next Steps
1. **Day 1**: FoundationContainerì— DI ì¤€ë¹„
2. **Week 1-2**: Cost Analysis êµ¬í˜„
3. **Day 11**: âš ï¸  4-Point Integration ì‹œì‘
4. **Day 19**: âš ï¸  Alias pre-check (Concurrency ì „)
5. **Week 7**: Differential 4-Point Integration

---

---

## 14. RFC-027 Integration Status

### âœ… Evidence ìŠ¤í‚¤ë§ˆ í™•ì • ì™„ë£Œ (Phase 0)

**íŒŒì¼**:
- `src/agent/domain/rfc_specs/evidence.py` (êµ¬í˜„ ì™„ë£Œ)
- `src/agent/domain/rfc_specs/claim.py` (êµ¬í˜„ ì™„ë£Œ)
- `src/agent/adapters/rfc/mappings.py` (ë§¤í•‘ í…Œì´ë¸”)
- `tests/agent/domain/rfc_specs/test_evidence.py` (í†µê³¼)

**ë³‘í–‰ ì‘ì—…**: âœ… **ê°€ëŠ¥** (ì‹œë®¬ë ˆì´ì…˜ ì„±ê³µ)

**Sync Points**: Week 2, 4, 8 (ì´ 3íšŒ)

**ì°¸ê³ **: `_docs/_backlog/RFC-027-028-PARALLEL-WORK-PLAN.md`

---

**RFC-028 â€” READY FOR IMPLEMENTATION**
**Review Feedback: INCORPORATED (Unbounded Loop, Alias Dependency)**
**RFC-027 Integration: COMPLETE (Evidence Schema Locked)**
