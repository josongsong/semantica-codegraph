# RFC-063: ChunkBuilder Rust ìµœì í™”

**Status**: Draft  
**Author**: Semantica Team  
**Created**: 2024-12-26  
**Target**: Phase 3 ìµœì í™” (87s â†’ ~15s)

---

## 1. Executive Summary

Phase 3 (Chunk Build)ê°€ ì „ì²´ ì¸ë±ì‹±ì˜ 72%ë¥¼ ì°¨ì§€í•˜ëŠ” ìµœëŒ€ ë³‘ëª©ì…ë‹ˆë‹¤.
ChunkBuilderë¥¼ Rustë¡œ ì´ì „í•˜ì—¬ **~80% ì„±ëŠ¥ í–¥ìƒ**ì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

```
í˜„ì¬ ì„±ëŠ¥ (Python):
  Phase 3: 87ì´ˆ / ì „ì²´ 120ì´ˆ = 72%
  ì²˜ë¦¬ëŸ‰: 152 files/s

ëª©í‘œ ì„±ëŠ¥ (Rust):
  Phase 3: ~15ì´ˆ / ì „ì²´ ~48ì´ˆ = 31%
  ì²˜ë¦¬ëŸ‰: 880+ files/s
```

---

## 2. SOTA ì‹œìŠ¤í…œ ë¹„êµ ë¶„ì„

### 2.1 ì—…ê³„ SOTA ì²­í‚¹ ì‹œìŠ¤í…œ

| ì‹œìŠ¤í…œ | ì–¸ì–´ | ì²­í‚¹ ë°©ì‹ | íŠ¹ì§• |
|--------|------|-----------|------|
| **Sourcegraph SCIP** | Rust/Go | AST + Semantic | SCIP í”„ë¡œí† ì½œ, ì‹¬ë³¼ ê¸°ë°˜ |
| **GitHub Code Search** | Rust | Tree-sitter + BM25 | ë³‘ë ¬ ì¸ë±ì‹±, ìŠ¤íŠ¸ë¦¬ë° |
| **Cursor** | TypeScript/Rust | Tree-sitter + LLM | RAG ìµœì í™” ì²­í‚¹ |
| **Continue.dev** | TypeScript | Tree-sitter | Function/Class ë‹¨ìœ„ |
| **LlamaIndex** | Python | AST Splitter | Configurable boundaries |
| **Aider** | Python | Tree-sitter | Diff ê¸°ë°˜ ì²­í‚¹ |

### 2.2 SOTA ì²­í‚¹ í•µì‹¬ ê¸°ë²•

```
1. AST-Aware Chunking (í•„ìˆ˜)
   - Function/Class/Method ê²½ê³„ ì¡´ì¤‘
   - Nested structure ë³´ì¡´
   
2. Semantic Hierarchy (SOTA)
   - Repo â†’ Project â†’ Module â†’ File â†’ Class â†’ Function
   - 6-level hierarchyë¡œ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
   
3. Content-Addressable (ê³ ê¸‰)
   - SHA256/MD5 ê¸°ë°˜ ì¤‘ë³µ ì œê±°
   - Incremental update ì§€ì›
   
4. Parallel Processing (í•„ìˆ˜)
   - Rayon/Tokio ê¸°ë°˜ ë³‘ë ¬í™”
   - Lock-free data structures
   
5. Zero-Copy (ê³ ê¸‰)
   - Cow<str> í™œìš©
   - Arena allocation
```

### 2.3 ìš°ë¦¬ ì‹œìŠ¤í…œ vs SOTA

| ê¸°ëŠ¥ | ìš°ë¦¬ (í˜„ì¬) | SOTA | ìƒíƒœ |
|------|-------------|------|------|
| AST-Aware Chunking | âœ… Tree-sitter + IR | âœ… | ë™ë“± |
| 6-Level Hierarchy | âœ… Repoâ†’Function | âœ… | SOTAê¸‰ |
| Content Hash | âœ… MD5 | SHA256 | ê°œì„  ê°€ëŠ¥ |
| Symbol Visibility | âœ… Public/Private | âœ… | ë™ë“± |
| Test Detection | âœ… TestDetector | âœ… | ë™ë“± |
| Docstring Chunking | âœ… ë³„ë„ ì²­í¬ | âœ… | SOTAê¸‰ |
| Skeleton Generation | âœ… TypeStub | âœ… | SOTAê¸‰ |
| **êµ¬í˜„ ì–¸ì–´** | âŒ Python | Rust | **ë³‘ëª©** |
| **ë³‘ë ¬ ì²˜ë¦¬** | âŒ Sequential | Rayon | **ë³‘ëª©** |

**ê²°ë¡ **: ê¸°ëŠ¥ì ìœ¼ë¡œ SOTAê¸‰ì´ë‚˜, êµ¬í˜„ ì–¸ì–´(Python)ê°€ ë³‘ëª©

---

## 3. ìµœì í™” ì „ëµ

### 3.1 Phase 1: Core Types & Models (Week 1, Day 1-2)

```rust
// codegraph-ir/src/features/chunk/models.rs

use serde::{Deserialize, Serialize};
use std::borrow::Cow;

/// Chunk ì¢…ë¥˜ - 6-level hierarchy + semantic types
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
#[serde(rename_all = "PascalCase")]
pub enum ChunkKind {
    // Hierarchy levels
    Repo,
    Project,
    Module,
    File,
    Class,
    Function,
    Method,
    
    // Semantic types
    Docstring,
    Skeleton,
    FileHeader,
    Import,
    Variable,
    Field,
    Block,
    Expression,
}

/// ì½”ë“œ ì²­í¬ - SOTAê¸‰ ë©”íƒ€ë°ì´í„° í¬í•¨
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Chunk {
    pub chunk_id: String,
    pub repo_id: String,
    pub snapshot_id: String,
    pub kind: ChunkKind,
    
    // Location
    pub file_path: String,
    pub start_line: u32,
    pub end_line: u32,
    
    // Identity
    pub fqn: String,
    pub content_hash: Option<String>,
    
    // Hierarchy
    pub parent_id: Option<String>,
    
    // Attributes (flexible metadata)
    pub attrs: ChunkAttrs,
}

/// ì²­í¬ ì†ì„± - í™•ì¥ ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„°
#[derive(Debug, Clone, Default, Serialize, Deserialize)]
pub struct ChunkAttrs {
    pub visibility: Option<String>,      // public, private, protected
    pub decorators: Vec<String>,         // @staticmethod, @property
    pub is_test: bool,                   // í…ŒìŠ¤íŠ¸ íŒŒì¼/í•¨ìˆ˜ ì—¬ë¶€
    pub docstring_length: Option<u32>,   // ë¬¸ì„œí™” ìˆ˜ì¤€
    pub complexity: Option<u32>,         // ìˆœí™˜ ë³µì¡ë„
    pub language: Option<String>,        // python, javascript
}

/// IR â†’ Chunk ë§¤í•‘ ê²°ê³¼
#[derive(Debug, Clone, Default)]
pub struct ChunkToIR {
    pub mappings: Vec<(String, String)>,  // (chunk_id, node_id)
}

/// Chunk â†’ Graph ë§¤í•‘ ê²°ê³¼  
#[derive(Debug, Clone, Default)]
pub struct ChunkToGraph {
    pub mappings: Vec<(String, String)>,  // (chunk_id, graph_node_id)
}
```

### 3.2 Phase 2: ChunkIdGenerator (Week 1, Day 3)

```rust
// codegraph-ir/src/features/chunk/id_generator.rs

use sha2::{Sha256, Digest};
use std::sync::atomic::{AtomicU64, Ordering};

/// ID ìƒì„± ì»¨í…ìŠ¤íŠ¸
pub struct ChunkIdContext {
    pub repo_id: String,
    pub snapshot_id: String,
    pub file_path: String,
    counter: AtomicU64,
}

impl ChunkIdContext {
    pub fn new(repo_id: &str, snapshot_id: &str, file_path: &str) -> Self {
        Self {
            repo_id: repo_id.to_string(),
            snapshot_id: snapshot_id.to_string(),
            file_path: file_path.to_string(),
            counter: AtomicU64::new(0),
        }
    }
    
    /// ê³ ìœ  ì²­í¬ ID ìƒì„± (deterministic)
    pub fn generate_id(&self, kind: ChunkKind, fqn: &str) -> String {
        let seq = self.counter.fetch_add(1, Ordering::SeqCst);
        
        // Deterministic ID: repo:snapshot:file:kind:fqn:seq
        let input = format!(
            "{}:{}:{}:{:?}:{}:{}",
            self.repo_id, self.snapshot_id, self.file_path, kind, fqn, seq
        );
        
        let mut hasher = Sha256::new();
        hasher.update(input.as_bytes());
        let result = hasher.finalize();
        
        // First 16 bytes as hex = 32 chars
        hex::encode(&result[..16])
    }
}

/// Content-addressable hash ìƒì„±
pub fn compute_content_hash(content: &str) -> String {
    let mut hasher = Sha256::new();
    hasher.update(content.as_bytes());
    hex::encode(hasher.finalize())
}
```

### 3.3 Phase 3: ChunkBuilder Core (Week 1, Day 4-5)

```rust
// codegraph-ir/src/features/chunk/builder.rs

use rayon::prelude::*;
use dashmap::DashMap;
use crate::shared::models::{IRDocument, Node, NodeKind};

pub struct ChunkBuilder {
    config: ChunkBuilderConfig,
}

pub struct ChunkBuilderConfig {
    pub min_chunk_lines: u32,      // ìµœì†Œ ì²­í¬ í¬ê¸° (ê¸°ë³¸: 1)
    pub max_chunk_lines: u32,      // ìµœëŒ€ ì²­í¬ í¬ê¸° (ê¸°ë³¸: 500)
    pub include_docstrings: bool,  // ë…ìŠ¤íŠ¸ë§ ë³„ë„ ì²­í¬í™”
    pub include_skeletons: bool,   // íƒ€ì… ìŠ¤ì¼ˆë ˆí†¤ ìƒì„±
    pub compute_complexity: bool,  // ë³µì¡ë„ ê³„ì‚°
}

impl Default for ChunkBuilderConfig {
    fn default() -> Self {
        Self {
            min_chunk_lines: 1,
            max_chunk_lines: 500,
            include_docstrings: true,
            include_skeletons: true,
            compute_complexity: true,
        }
    }
}

impl ChunkBuilder {
    pub fn new(config: ChunkBuilderConfig) -> Self {
        Self { config }
    }
    
    /// IR ë¬¸ì„œì—ì„œ ì²­í¬ ìƒì„± (ë³‘ë ¬)
    pub fn build_from_ir(
        &self,
        repo_id: &str,
        snapshot_id: &str,
        ir_doc: &IRDocument,
        file_content: &str,
    ) -> ChunkBuildResult {
        let ctx = ChunkIdContext::new(repo_id, snapshot_id, &ir_doc.file_path);
        let lines: Vec<&str> = file_content.lines().collect();
        
        // Phase 1: Build hierarchy chunks (Repo â†’ Project â†’ Module â†’ File)
        let mut chunks = self.build_hierarchy_chunks(&ctx, ir_doc, &lines);
        
        // Phase 2: Build code chunks (parallel over nodes)
        let code_chunks: Vec<Chunk> = ir_doc.nodes
            .par_iter()
            .filter_map(|node| self.build_node_chunk(&ctx, node, &lines))
            .collect();
        
        chunks.extend(code_chunks);
        
        // Phase 3: Build docstring chunks (parallel)
        if self.config.include_docstrings {
            let doc_chunks: Vec<Chunk> = ir_doc.nodes
                .par_iter()
                .filter_map(|node| self.build_docstring_chunk(&ctx, node, &lines))
                .collect();
            chunks.extend(doc_chunks);
        }
        
        // Phase 4: Build skeleton chunks
        if self.config.include_skeletons {
            let skeleton_chunks: Vec<Chunk> = ir_doc.nodes
                .par_iter()
                .filter(|n| matches!(n.kind, NodeKind::Class | NodeKind::Function | NodeKind::Method))
                .map(|node| self.build_skeleton_chunk(&ctx, node, &lines))
                .collect();
            chunks.extend(skeleton_chunks);
        }
        
        // Build mappings
        let chunk_to_ir = self.build_ir_mapping(&chunks, ir_doc);
        
        ChunkBuildResult {
            chunks,
            chunk_to_ir,
            chunk_to_graph: ChunkToGraph::default(),
        }
    }
    
    fn build_node_chunk(
        &self,
        ctx: &ChunkIdContext,
        node: &Node,
        lines: &[&str],
    ) -> Option<Chunk> {
        // Skip non-chunkable nodes
        let kind = match node.kind {
            NodeKind::Class => ChunkKind::Class,
            NodeKind::Function => ChunkKind::Function,
            NodeKind::Method => ChunkKind::Method,
            NodeKind::Module => ChunkKind::Module,
            NodeKind::File => ChunkKind::File,
            NodeKind::Variable => ChunkKind::Variable,
            NodeKind::Field => ChunkKind::Field,
            _ => return None,
        };
        
        let start = node.span.start_line as usize;
        let end = node.span.end_line as usize;
        
        // Validate bounds
        if start >= lines.len() || end > lines.len() || start > end {
            return None;
        }
        
        // Extract content
        let content: String = lines[start..end].join("\n");
        
        // Compute content hash
        let content_hash = compute_content_hash(&content);
        
        Some(Chunk {
            chunk_id: ctx.generate_id(kind, &node.fqn),
            repo_id: ctx.repo_id.clone(),
            snapshot_id: ctx.snapshot_id.clone(),
            kind,
            file_path: ctx.file_path.clone(),
            start_line: node.span.start_line,
            end_line: node.span.end_line,
            fqn: node.fqn.clone(),
            content_hash: Some(content_hash),
            parent_id: node.parent_id.clone(),
            attrs: self.extract_attrs(node),
        })
    }
    
    fn extract_attrs(&self, node: &Node) -> ChunkAttrs {
        ChunkAttrs {
            visibility: node.attrs.get("visibility").map(|v| v.to_string()),
            decorators: node.attrs.get("decorators")
                .and_then(|v| v.as_array())
                .map(|arr| arr.iter().filter_map(|v| v.as_str().map(String::from)).collect())
                .unwrap_or_default(),
            is_test: node.attrs.get("is_test")
                .and_then(|v| v.as_bool())
                .unwrap_or(false),
            docstring_length: node.attrs.get("docstring")
                .and_then(|v| v.as_str())
                .map(|s| s.len() as u32),
            complexity: if self.config.compute_complexity {
                node.attrs.get("cyclomatic_complexity")
                    .and_then(|v| v.as_u64())
                    .map(|v| v as u32)
            } else {
                None
            },
            language: Some("python".to_string()),
        }
    }
}
```

### 3.4 Phase 4: PyO3 Bindings (Week 2, Day 1-2)

```rust
// codegraph-ir/src/lib.rs (ì¶”ê°€)

/// Pythonì—ì„œ í˜¸ì¶œ ê°€ëŠ¥í•œ ì²­í¬ ë¹Œë“œ í•¨ìˆ˜
#[pyfunction]
#[pyo3(signature = (repo_id, snapshot_id, ir_docs, file_contents))]
fn build_chunks_py(
    py: Python,
    repo_id: &str,
    snapshot_id: &str,
    ir_docs: &PyList,
    file_contents: &PyDict,
) -> PyResult<Py<PyList>> {
    init_rayon();
    
    // Convert Python IR docs to Rust
    let rust_irs: Vec<IRDocument> = ir_docs
        .iter()
        .filter_map(|doc| IRDocument::from_py_dict(doc.downcast::<PyDict>().ok()?).ok())
        .collect();
    
    // Convert file contents
    let contents: HashMap<String, String> = file_contents
        .iter()
        .filter_map(|(k, v)| {
            Some((k.extract::<String>().ok()?, v.extract::<String>().ok()?))
        })
        .collect();
    
    // Build chunks (releases GIL for parallel processing)
    let builder = ChunkBuilder::new(ChunkBuilderConfig::default());
    
    let all_chunks: Vec<Vec<Chunk>> = py.allow_threads(|| {
        rust_irs
            .par_iter()
            .filter_map(|ir| {
                let content = contents.get(&ir.file_path)?;
                Some(builder.build_from_ir(repo_id, snapshot_id, ir, content).chunks)
            })
            .collect()
    });
    
    // Flatten and convert to Python
    let flat_chunks: Vec<Chunk> = all_chunks.into_iter().flatten().collect();
    
    // Convert to Python list
    let py_list = PyList::empty(py);
    for chunk in flat_chunks {
        py_list.append(chunk.to_py_dict(py)?)?;
    }
    
    Ok(py_list.into())
}
```

### 3.5 Phase 5: Integration & Benchmarking (Week 2, Day 3-5)

```python
# packages/codegraph-shared/.../handlers/chunk_handler.py

class ChunkBuildHandler(BaseJobHandler):
    async def execute(self, job: Job) -> JobResult:
        ir_docs = await self._load_ir_docs(job.ir_cache_key)
        file_contents = await self._load_file_contents(ir_docs)
        
        # ğŸš€ Rust ì§ì ‘ í˜¸ì¶œ!
        try:
            import codegraph_ir
            
            chunks = codegraph_ir.build_chunks_py(
                repo_id=job.repo_id,
                snapshot_id=job.snapshot_id,
                ir_docs=[doc.to_dict() for doc in ir_docs.values()],
                file_contents=file_contents,
            )
            
            logger.info("rust_chunk_build_success", count=len(chunks))
            
        except ImportError:
            # Fallback to Python
            logger.warning("rust_unavailable_fallback_python")
            builder = ChunkBuilder(ChunkIdGenerator())
            chunks = self._build_with_python(builder, ir_docs, file_contents)
        
        return JobResult(
            success=True,
            data={"chunks": chunks, "count": len(chunks)},
        )
```

---

## 4. ë ˆí¬ì§€í† ë¦¬ êµ¬ì¡°

### 4.1 ìƒˆë¡œ ì¶”ê°€ë  Rust íŒŒì¼

```
codegraph-rust/codegraph-ir/src/features/
â”œâ”€â”€ chunk/                        # ğŸ†• ìƒˆ ëª¨ë“ˆ
â”‚   â”œâ”€â”€ mod.rs                   # ëª¨ë“ˆ ì„ ì–¸
â”‚   â”œâ”€â”€ models.rs                # Chunk, ChunkKind, ChunkAttrs
â”‚   â”œâ”€â”€ builder.rs               # ChunkBuilder í•µì‹¬
â”‚   â”œâ”€â”€ id_generator.rs          # ChunkIdContext, ID ìƒì„±
â”‚   â”œâ”€â”€ hierarchy.rs             # Repoâ†’File ê³„ì¸µ ë¹Œë“œ
â”‚   â”œâ”€â”€ docstring.rs             # Docstring ì²­í¬ ìƒì„±
â”‚   â”œâ”€â”€ skeleton.rs              # Type skeleton ìƒì„±
â”‚   â”œâ”€â”€ visibility.rs            # Public/Private ì¶”ì¶œ
â”‚   â””â”€â”€ test_detector.rs         # í…ŒìŠ¤íŠ¸ íŒŒì¼ ê°ì§€
â”œâ”€â”€ cross_file/                  # âœ… ê¸°ì¡´
â”œâ”€â”€ data_flow/                   # âœ… ê¸°ì¡´
â”œâ”€â”€ flow_graph/                  # âœ… ê¸°ì¡´
â”œâ”€â”€ ir_generation/               # âœ… ê¸°ì¡´
â”œâ”€â”€ parsing/                     # âœ… ê¸°ì¡´
â”œâ”€â”€ pdg/                         # âœ… ê¸°ì¡´
â”œâ”€â”€ slicing/                     # âœ… ê¸°ì¡´
â”œâ”€â”€ ssa/                         # âœ… ê¸°ì¡´
â”œâ”€â”€ taint_analysis/              # âœ… ê¸°ì¡´
â”œâ”€â”€ type_resolution/             # âœ… ê¸°ì¡´
â””â”€â”€ mod.rs                       # chunk ì¶”ê°€
```

### 4.2 ìˆ˜ì •ë  Python íŒŒì¼

```
packages/codegraph-shared/.../handlers/
â”œâ”€â”€ chunk_handler.py             # ğŸ”„ Rust í˜¸ì¶œë¡œ ë³€ê²½
â””â”€â”€ __init__.py                  # ğŸ”„ export ì¶”ê°€

packages/codegraph-engine/.../chunk/
â”œâ”€â”€ builder.py                   # ğŸ”„ Rust fallback ì¶”ê°€
â””â”€â”€ models.py                    # âœ… ìœ ì§€ (Python ì¸í„°í˜ì´ìŠ¤)
```

### 4.3 ì „ì²´ ë ˆí¬ êµ¬ì¡° (ìµœì¢…)

```
codegraph/
â”œâ”€â”€ packages/
â”‚   â”œâ”€â”€ codegraph-rust/
â”‚   â”‚   â”œâ”€â”€ codegraph-ir/
â”‚   â”‚   â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ chunk/          # ğŸ†• Week 1-2
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ cross_file/     # âœ… ì™„ë£Œ
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ir_generation/  # âœ… ì™„ë£Œ
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ parsing/        # âœ… ì™„ë£Œ
â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ lib.rs              # ğŸ”„ build_chunks_py ì¶”ê°€
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â”‚   â””â”€â”€ Cargo.toml
â”‚   â”‚   â””â”€â”€ codegraph-core/
â”‚   â”‚       â””â”€â”€ src/
â”‚   â”‚           â””â”€â”€ types.rs            # âœ… NodeKind ë™ê¸°í™”ë¨
â”‚   â”‚
â”‚   â”œâ”€â”€ codegraph-engine/
â”‚   â”‚   â””â”€â”€ codegraph_engine/
â”‚   â”‚       â””â”€â”€ code_foundation/
â”‚   â”‚           â””â”€â”€ infrastructure/
â”‚   â”‚               â””â”€â”€ chunk/
â”‚   â”‚                   â”œâ”€â”€ builder.py   # ğŸ”„ Rust fallback
â”‚   â”‚                   â””â”€â”€ models.py    # âœ… ìœ ì§€
â”‚   â”‚
â”‚   â””â”€â”€ codegraph-shared/
â”‚       â””â”€â”€ codegraph_shared/
â”‚           â””â”€â”€ infra/
â”‚               â””â”€â”€ jobs/
â”‚                   â””â”€â”€ handlers/
â”‚                       â””â”€â”€ chunk_handler.py  # ğŸ”„ Rust í˜¸ì¶œ
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ rfcs/
â”‚       â””â”€â”€ RFC-063-ChunkBuilder-Rust-Optimization.md  # ğŸ†• ë³¸ ë¬¸ì„œ
â”‚
â””â”€â”€ tools/
    â””â”€â”€ benchmark/
        â””â”€â”€ bench_indexing_dag.py  # ğŸ”„ ì„±ëŠ¥ ì¸¡ì •
```

---

## 5. ì„±ëŠ¥ ëª©í‘œ ë° ì¸¡ì •

### 5.1 ë²¤ì¹˜ë§ˆí¬ ëŒ€ìƒ

| ê·œëª¨ | íŒŒì¼ ìˆ˜ | LOC | í˜„ì¬ (Python) | ëª©í‘œ (Rust) |
|------|---------|-----|---------------|-------------|
| Small | 100 | 10K | 0.6s | <0.1s |
| Medium | 1,000 | 100K | 6s | <1s |
| Large | 10,000 | 1M | 60s | <10s |
| **XL (codegraph)** | **13,217** | **1.95M** | **87s** | **<15s** |

### 5.2 ì„±ëŠ¥ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸

```bash
# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python tools/benchmark/bench_indexing_dag.py \
    /Users/songmin/Documents/code-jo/semantica-v2/codegraph \
    --output benchmark/artifacts/reports/chunk_rust_benchmark.txt

# ê¸°ëŒ€ ê²°ê³¼
# Phase 3 (Chunk): 87s â†’ ~15s (5.8x faster)
# ì „ì²´: 120s â†’ ~48s (2.5x faster)
```

---

## 6. íƒ€ì„ë¼ì¸

### Week 1: Core Implementation

| Day | Task | Deliverable | Hours |
|-----|------|-------------|-------|
| 1 | Models ì •ì˜ | `models.rs` | 4h |
| 2 | ID Generator | `id_generator.rs` | 3h |
| 3 | Hierarchy Builder | `hierarchy.rs` | 4h |
| 4 | Node Chunk Builder | `builder.rs` (core) | 6h |
| 5 | Docstring/Skeleton | `docstring.rs`, `skeleton.rs` | 4h |

### Week 2: Integration & Testing

| Day | Task | Deliverable | Hours |
|-----|------|-------------|-------|
| 1 | PyO3 Bindings | `lib.rs` í™•ì¥ | 4h |
| 2 | Python Handler | `chunk_handler.py` | 3h |
| 3 | Unit Tests | `tests/chunk/` | 4h |
| 4 | Integration Tests | `tests/integration/` | 4h |
| 5 | Benchmark & Docs | Reports, RFC ì—…ë°ì´íŠ¸ | 4h |

**ì´ ì˜ˆìƒ ì‹œê°„: 40ì‹œê°„ (2ì£¼)**

---

## 7. ë¦¬ìŠ¤í¬ ë° ëŒ€ì‘

| ë¦¬ìŠ¤í¬ | í™•ë¥  | ì˜í–¥ | ëŒ€ì‘ |
|--------|------|------|------|
| PyO3 ë°ì´í„° ë³€í™˜ ì˜¤ë²„í—¤ë“œ | ì¤‘ | ì¤‘ | Msgpack ë°”ì´ë„ˆë¦¬ ì§ë ¬í™” |
| Python fallback í˜¸í™˜ì„± | ë‚® | ë‚® | ê¸°ì¡´ Python ì½”ë“œ ìœ ì§€ |
| ì²­í¬ ID ë¶ˆì¼ì¹˜ | ì¤‘ | ë†’ | ë™ì¼ ì•Œê³ ë¦¬ì¦˜ ì ìš© |
| ë³µì¡ë„ ê³„ì‚° ì°¨ì´ | ë‚® | ë‚® | Python ë¡œì§ í¬íŒ… |

---

## 8. ê²°ë¡ 

### SOTA ê²€ì¦ ê²°ê³¼

| ê¸°ì¤€ | ìƒíƒœ |
|------|------|
| AST-Aware Chunking | âœ… SOTAê¸‰ |
| 6-Level Hierarchy | âœ… SOTAê¸‰ |
| Content-Addressable | âœ… SOTAê¸‰ |
| Parallel Processing | â³ êµ¬í˜„ í•„ìš” |
| Zero-Copy | â³ êµ¬í˜„ í•„ìš” |

**ê²°ë¡ **: ê¸°ëŠ¥ì ìœ¼ë¡œ SOTAê¸‰ì´ë©°, Rust ì´ì „ìœ¼ë¡œ ì„±ëŠ¥ë„ SOTAê¸‰ ë‹¬ì„± ê°€ëŠ¥

### ì˜ˆìƒ ROI

```
íˆ¬ì: 40ì‹œê°„ (2ì£¼)
íš¨ê³¼: Phase 3 87s â†’ 15s (5.8x)
      ì „ì²´ 120s â†’ 48s (2.5x)
      
ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸:
  - 100ë§Œ LOC: 1ë¶„ â†’ 24ì´ˆ
  - 500ë§Œ LOC: 5ë¶„ â†’ 2ë¶„
```

---

## Appendix A: ì˜ì¡´ì„±

```toml
# Cargo.toml ì¶”ê°€
[dependencies]
sha2 = "0.10"          # Content hash
hex = "0.4"            # Hex encoding
rayon = "1.8"          # Parallel iteration
dashmap = "5.5"        # Concurrent HashMap
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
```

---

## Appendix B: ì°¸ê³  ìë£Œ

1. Sourcegraph SCIP Protocol: https://github.com/sourcegraph/scip
2. Tree-sitter: https://tree-sitter.github.io/tree-sitter/
3. LlamaIndex CodeSplitter: https://docs.llamaindex.ai/en/stable/module_guides/loading/node_parsers/modules/code_splitter/
4. Cursor Technical Blog: https://cursor.sh/blog
5. Rayon Data Parallelism: https://docs.rs/rayon/latest/rayon/

