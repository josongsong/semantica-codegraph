# RFC-045: Unified Incremental Update System

| í•­ëª© | ë‚´ìš© |
|------|------|
| **ìƒíƒœ** | Draft |
| **ì‘ì„±ì¼** | 2025-12-26 |
| **ì‘ì„±ì** | Semantica Team |
| **ê´€ë ¨ RFC** | RFC-031 (Stable ID), RFC-039 (L0 Cache), ADR-003 (Workflow) |

## 1. Executive Summary

í˜„ì¬ Semantica v2ì˜ ì¦ë¶„ ì—…ë°ì´íŠ¸ ê´€ë ¨ ì»´í¬ë„ŒíŠ¸ë“¤ì€ ê°œë³„ì ìœ¼ë¡œ SOTAê¸‰ì´ì§€ë§Œ, **78ê°œì˜ ì¤‘ë³µ í´ë˜ìŠ¤**ì™€ **íŒ¨í‚¤ì§€ ê°„ ë¶„ì‚°**ìœ¼ë¡œ ì¸í•´ í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ì´ ë¶€ì¡±í•œ ìƒíƒœì…ë‹ˆë‹¤.

ë³¸ RFCëŠ” `codegraph-incremental` íŒ¨í‚¤ì§€ë¥¼ ì‹ ì„¤í•˜ì—¬ ëª¨ë“  ì¦ë¶„ ê´€ë ¨ ê¸°ìˆ ì„ í†µí•©í•˜ê³ , **MVCC íŠ¸ëœì­ì…˜ ê¸°ë°˜ì˜ ì›ìì  íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.

### í•µì‹¬ ëª©í‘œ
1. **ì¤‘ë³µ ì œê±°**: 33ê°œ ì¤‘ë³µ í´ë˜ìŠ¤ í†µí•©
2. **ì›ìì„± ë³´ì¥**: IRTransactionManager ê¸°ë°˜ ACID íŒŒì´í”„ë¼ì¸
3. **ì˜ë¯¸ë¡ ì  ê°€ì§€ì¹˜ê¸°**: Semantic Pruningìœ¼ë¡œ ë¶ˆí•„ìš”í•œ ì¬ë¹Œë“œ 70% ê°ì†Œ
4. **ìê°€ ì¹˜ìœ **: ConsistencyChecker ê¸°ë°˜ ë“œë¦¬í”„íŠ¸ ìë™ ë³µêµ¬

---

## 2. Background & Problem Statement

### 2.1 í˜„ì¬ ìƒíƒœ ë¶„ì„

#### êµ¬í˜„ ì™„ë£Œëœ SOTAê¸‰ ì»´í¬ë„ŒíŠ¸

| ì»´í¬ë„ŒíŠ¸ | ìœ„ì¹˜ | ìƒíƒœ |
|----------|------|------|
| FileWatcher + Debouncer | `analysis_indexing/` | âœ… Production-ready |
| IRTransactionManager (MVCC) | `runtime/shadowfs/` | âœ… SOTA |
| Body Hash Service | `semantic_ir/body_hash_service.py` | âœ… êµ¬í˜„ë¨ |
| Stable ID (RFC-031) | `ir/id_strategy.py` | âœ… êµ¬í˜„ë¨ |
| ConsistencyChecker | `multi_index/consistency_checker.py` | âœ… êµ¬í˜„ë¨ |
| GraphSimulator (Speculative) | `reasoning_engine/speculative/` | âœ… SOTA |
| Compaction Scheduler | `lexical/compaction/scheduler.py` | âœ… êµ¬í˜„ë¨ |
| Distributed Lock | `cache/distributed_lock.py` | âœ… êµ¬í˜„ë¨ |
| WorkflowStateMachine | `apps/orchestrator/workflow/` | âœ… êµ¬í˜„ë¨ |

#### ë¬¸ì œì 

**1. ì‹¬ê°í•œ ì¤‘ë³µ (33ê°œ í´ë˜ìŠ¤)**
```
CacheEntry: 8ê³³ì— ì •ì˜
LRUCache: 4ê³³ì— ì •ì˜
DiffHunk: 3ê³³ì— ì •ì˜
IncrementalIRBuilder: 2ê³³ì— ì •ì˜ (ë‹¤ë¥¸ ì—­í• , ê°™ì€ ì´ë¦„)
DistributedLock: 2ê³³ì— ì •ì˜
```

**2. apps/orchestrator â†” packages ê°„ 78ê°œ ì¤‘ë³µ**
- `FuzzyPatcherAdapter`, `ArbitrationEngine`, `AuditStore` ë“± í•µì‹¬ í´ë˜ìŠ¤ê°€ ë³µì œë¨

**3. í†µí•© ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë¶€ì¬**
- ê°œë³„ ì»´í¬ë„ŒíŠ¸ëŠ” ìš°ìˆ˜í•˜ë‚˜ ì—°ê²°í•˜ëŠ” íŒŒì´í”„ë¼ì¸ ì—†ìŒ
- ì›ìì  ì»¤ë°‹ ë³´ì¥ ë©”ì»¤ë‹ˆì¦˜ ë¶€ì¡±

**4. ëˆ„ë½ëœ SOTA ê¸°ëŠ¥**
- Semantic Pruning (ì˜ì¡´ì„± ì „íŒŒ ì¤‘ë‹¨)
- Identity Migration (ì‹¬ë³¼ ì´ë™ ì¶”ì )
- Self-Healing (ìë™ ë³µêµ¬) ì™„ì„±
- Vector Index Compaction

---

## 3. Proposed Solution

### 3.1 ì‹ ê·œ íŒ¨í‚¤ì§€: `codegraph-incremental`

```
packages/codegraph-incremental/
â””â”€â”€ codegraph_incremental/
    â”œâ”€â”€ __init__.py
    â”‚
    â”œâ”€â”€ core/                         # ë„ë©”ì¸ ëª¨ë¸ & í¬íŠ¸
    â”‚   â”œâ”€â”€ models.py                 # ChangeSet, Delta, RebuildPlan
    â”‚   â”œâ”€â”€ ports.py                  # IChangeDetector, IBuilder, ICache
    â”‚   â”œâ”€â”€ events.py                 # ChangeEvent, CommitEvent, RollbackEvent
    â”‚   â””â”€â”€ errors.py                 # IncrementalError, TransactionError
    â”‚
    â”œâ”€â”€ detection/                    # Stage 1: ë³€ê²½ ê°ì§€
    â”‚   â”œâ”€â”€ file_watcher.py           # â† analysis_indexing/file_watcher.py
    â”‚   â”œâ”€â”€ watcher_debouncer.py      # â† analysis_indexing/watcher_debouncer.py
    â”‚   â”œâ”€â”€ git_detector.py           # Git diff ê¸°ë°˜ ê°ì§€
    â”‚   â”œâ”€â”€ hash_detector.py          # Content hash ê¸°ë°˜ ê°ì§€
    â”‚   â””â”€â”€ composite_detector.py     # ë³µí•© ê°ì§€ê¸°
    â”‚
    â”œâ”€â”€ semantics/                    # Stage 2: ì˜ë¯¸ë¡ ì  ë¶„ì„ (ì‹ ê·œ)
    â”‚   â”œâ”€â”€ fingerprint_manager.py    # ì‹œê·¸ë‹ˆì²˜ í•´ì‹œ ê¸°ë°˜ Pruning
    â”‚   â”œâ”€â”€ identity_tracker.py       # ì‹¬ë³¼ ì´ë™/ì´ë¦„ ë³€ê²½ ì¶”ì 
    â”‚   â”œâ”€â”€ affected_calculator.py    # ì˜í–¥ ë²”ìœ„ ê³„ì‚°
    â”‚   â””â”€â”€ pruning_engine.py         # ì˜ì¡´ì„± ì „íŒŒ ì¤‘ë‹¨
    â”‚
    â”œâ”€â”€ tracking/                     # ìƒíƒœ ì¶”ì 
    â”‚   â”œâ”€â”€ change_tracker.py         # â† incremental/change_tracker.py
    â”‚   â”œâ”€â”€ file_state.py             # íŒŒì¼ ìƒíƒœ ê´€ë¦¬
    â”‚   â””â”€â”€ dependency_graph.py       # ì˜ì¡´ì„± ê·¸ë˜í”„
    â”‚
    â”œâ”€â”€ parsing/                      # íŒŒì‹± (ì¤‘ë³µ í†µí•©)
    â”‚   â”œâ”€â”€ diff_parser.py            # â† 3ê³³ í†µí•©
    â”‚   â”œâ”€â”€ diff_hunk.py              # DiffHunk ëª¨ë¸
    â”‚   â”œâ”€â”€ edit_calculator.py        # Tree-sitter Edit ë³€í™˜
    â”‚   â””â”€â”€ incremental_parser.py     # â† 2ê³³ í†µí•©
    â”‚
    â”œâ”€â”€ builders/                     # Stage 4: ë¹Œë”
    â”‚   â”œâ”€â”€ file_builder.py           # â† incremental/incremental_builder.py (ì´ë¦„ ë³€ê²½)
    â”‚   â”œâ”€â”€ ir_delta_builder.py       # â† ir/incremental.py (ì´ë¦„ ë³€ê²½)
    â”‚   â”œâ”€â”€ chunk_builder.py          # â† chunk/incremental.py
    â”‚   â”œâ”€â”€ semantic_builder.py       # â† semantic_ir/incremental_updater.py
    â”‚   â””â”€â”€ protocol.py               # IIncrementalBuilder ì¸í„°í˜ì´ìŠ¤
    â”‚
    â”œâ”€â”€ transaction/                  # Stage 3 & 5: íŠ¸ëœì­ì…˜ (í•µì‹¬)
    â”‚   â”œâ”€â”€ manager.py                # â† shadowfs/ir_transaction_manager.py
    â”‚   â”œâ”€â”€ state.py                  # TransactionState (MVCC)
    â”‚   â”œâ”€â”€ snapshot.py               # FileSnapshot
    â”‚   â”œâ”€â”€ conflict_registry.py      # â† conflict_registry.py
    â”‚   â””â”€â”€ graph_transaction.py      # Graph DB íŠ¸ëœì­ì…˜
    â”‚
    â”œâ”€â”€ shadowfs/                     # ShadowFS (Buffer Layer)
    â”‚   â”œâ”€â”€ core.py                   # â† shadowfs/core.py (í†µí•©)
    â”‚   â”œâ”€â”€ unified.py                # UnifiedShadowFS
    â”‚   â”œâ”€â”€ event_bus.py              # ì´ë²¤íŠ¸ ë²„ìŠ¤
    â”‚   â””â”€â”€ plugins/
    â”‚       â””â”€â”€ incremental_plugin.py
    â”‚
    â”œâ”€â”€ cache/                        # ìºì‹œ ê³„ì¸µ
    â”‚   â”œâ”€â”€ hierarchy.py              # HierarchicalCache (L0-L3)
    â”‚   â”œâ”€â”€ l0_metadata.py            # íŒŒì¼ ë©”íƒ€ë°ì´í„°
    â”‚   â”œâ”€â”€ l1_memory.py              # â† cache_global.py
    â”‚   â”œâ”€â”€ l2_redis.py               # Redis (optional)
    â”‚   â”œâ”€â”€ l3_disk.py                # â† semantic_cache.py
    â”‚   â””â”€â”€ invalidation.py           # ì˜ì¡´ì„± ê¸°ë°˜ ë¬´íš¨í™”
    â”‚
    â”œâ”€â”€ indexing/                     # ì¸ë±ì‹±
    â”‚   â”œâ”€â”€ incremental_indexer.py    # â† multi_index/incremental_indexer.py
    â”‚   â”œâ”€â”€ tombstone.py              # ì‚­ì œ ì¶”ì 
    â”‚   â””â”€â”€ batch_processor.py        # ë°°ì¹˜ ì²˜ë¦¬
    â”‚
    â”œâ”€â”€ compaction/                   # Stage 6: ì •ë¦¬
    â”‚   â”œâ”€â”€ scheduler.py              # â† lexical/compaction/scheduler.py
    â”‚   â”œâ”€â”€ delta_merger.py           # ë¸íƒ€ ë³‘í•©
    â”‚   â”œâ”€â”€ vector_compactor.py       # Vector DB ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•© (ì‹ ê·œ)
    â”‚   â””â”€â”€ gc.py                     # Garbage Collection
    â”‚
    â”œâ”€â”€ consistency/                  # ì¼ê´€ì„± ê´€ë¦¬ (ì‹ ê·œ ê°•í™”)
    â”‚   â”œâ”€â”€ checker.py                # â† consistency_checker.py
    â”‚   â”œâ”€â”€ drift_detector.py         # ë“œë¦¬í”„íŠ¸ ê°ì§€
    â”‚   â”œâ”€â”€ self_healer.py            # ìë™ ë³µêµ¬ (ì‹ ê·œ)
    â”‚   â””â”€â”€ verification.py           # ê²€ì¦ ë¡œì§
    â”‚
    â”œâ”€â”€ lock/                         # ë¶„ì‚° ì ê¸ˆ
    â”‚   â”œâ”€â”€ distributed_lock.py       # â† 2ê³³ í†µí•©
    â”‚   â”œâ”€â”€ lock_key_generator.py
    â”‚   â””â”€â”€ noop_lock.py              # í…ŒìŠ¤íŠ¸ìš©
    â”‚
    â”œâ”€â”€ jobs/                         # Job ê´€ë¦¬
    â”‚   â”œâ”€â”€ orchestrator.py           # â† handlers/orchestrator.py
    â”‚   â”œâ”€â”€ models.py                 # JobState, JobStatus í†µí•©
    â”‚   â”œâ”€â”€ checkpoint.py             # ì²´í¬í¬ì¸íŠ¸
    â”‚   â””â”€â”€ retry.py                  # ì¬ì‹œë„ ë¡œì§
    â”‚
    â”œâ”€â”€ pipeline/                     # í†µí•© íŒŒì´í”„ë¼ì¸ (í•µì‹¬)
    â”‚   â”œâ”€â”€ orchestrator.py           # IncrementalOrchestrator
    â”‚   â”œâ”€â”€ stages.py                 # 6ë‹¨ê³„ Stage ì •ì˜
    â”‚   â”œâ”€â”€ strategies.py             # FULL/PARTIAL/MINIMAL
    â”‚   â””â”€â”€ metrics.py                # ì„±ëŠ¥ ë©”íŠ¸ë¦­
    â”‚
    â””â”€â”€ config.py                     # ì¤‘ì•™í™”ëœ ì„¤ì •
```

### 3.2 í†µí•© íŒŒì´í”„ë¼ì¸ ì„¤ê³„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        IncrementalOrchestrator                              â”‚
â”‚                    (WorkflowStateMachine + TransactionManager)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â–¼                                â–¼                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Trigger â”‚                    â”‚ Trigger â”‚                      â”‚ Trigger â”‚
â”‚  File   â”‚                    â”‚ Shadow  â”‚                      â”‚   Git   â”‚
â”‚ Watcher â”‚                    â”‚   FS    â”‚                      â”‚  Event  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                              â”‚                                â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 1: DETECT (ê°ì§€)                                                       â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚ â”‚  FileWatcher    â”‚  â”‚  GitDetector    â”‚  â”‚  HashDetector   â”‚              â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â–¼                                             â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚                    â”‚  WatcherDebouncer   â”‚ (300ms debounce, 5s batch)       â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
â”‚                               â–¼                                             â”‚
â”‚                         ChangeSet { added, modified, deleted, renamed }     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 2: ANALYZE & PRUNE (ë¶„ì„ ë° ê°€ì§€ì¹˜ê¸°) â­ í•µì‹¬                           â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      AffectedCalculator                                 â”‚ â”‚
â”‚ â”‚  - Call Graph ê¸°ë°˜ ì˜í–¥ ë²”ìœ„ ê³„ì‚°                                        â”‚ â”‚
â”‚ â”‚  - BFS íƒìƒ‰ (depth limit)                                               â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      FingerprintManager (ì‹ ê·œ)                          â”‚ â”‚
â”‚ â”‚  - signature_hash ë¹„êµ: í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ê°€ ê°™ìœ¼ë©´ ì „íŒŒ ì¤‘ë‹¨                   â”‚ â”‚
â”‚ â”‚  - body_hash ë¹„êµ: ë³¸ë¬¸ì´ ê°™ìœ¼ë©´ ìŠ¤í‚µ                                     â”‚ â”‚
â”‚ â”‚  - ğŸ¯ ëª©í‘œ: ë¶ˆí•„ìš”í•œ ì¬ë¹Œë“œ 70% ê°ì†Œ                                      â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      IdentityTracker (ì‹ ê·œ)                             â”‚ â”‚
â”‚ â”‚  - íŒŒì¼ ì´ë™ ê°ì§€ (Git similarity + content hash)                        â”‚ â”‚
â”‚ â”‚  - ì‹¬ë³¼ ì´ë¦„ ë³€ê²½ ì¶”ì  (FQN lifecycle)                                    â”‚ â”‚
â”‚ â”‚  - ID Migration: ê¸°ì¡´ ì¸ë±ìŠ¤ ì¬ì‚¬ìš©                                       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚                      RebuildPlan { strategy, files, symbols }               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 3: ISOLATE (ê²©ë¦¬ ë° íŠ¸ëœì­ì…˜ ì‹œì‘)                                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      DistributedLock                                    â”‚ â”‚
â”‚ â”‚  - Redis ê¸°ë°˜ (TTL 300s, 60s ìë™ ê°±ì‹ )                                  â”‚ â”‚
â”‚ â”‚  - Lock key: repo_id:snapshot_id                                        â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      IRTransactionManager                               â”‚ â”‚
â”‚ â”‚  - txn_id ìƒì„±                                                          â”‚ â”‚
â”‚ â”‚  - MVCC Snapshot ìº¡ì²˜                                                    â”‚ â”‚
â”‚ â”‚  - TransactionState ê²©ë¦¬                                                 â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚                         TransactionContext { txn_id, snapshot, state }      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 4: BUILD (ë³‘ë ¬ ë¹Œë“œ)                                                   â”‚
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                          â”‚
â”‚  â”‚ WorkerPool   â”‚ (msgpack protocol, 5-10x faster)                         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                                          â”‚
â”‚         â”‚                                                                   â”‚
â”‚    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                   â”‚
â”‚    â–¼         â–¼            â–¼            â–¼                                   â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”                                  â”‚
â”‚ â”‚  L1  â”‚ â”‚  L2  â”‚    â”‚  L3  â”‚    â”‚  L4  â”‚                                  â”‚
â”‚ â”‚  IR  â”‚ â”‚Chunk â”‚    â”‚Lexical    â”‚Vectorâ”‚                                  â”‚
â”‚ â”‚Build â”‚ â”‚Build â”‚    â”‚Index â”‚    â”‚Index â”‚                                  â”‚
â”‚ â””â”€â”€â”¬â”€â”€â”€â”˜ â””â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”˜    â””â”€â”€â”¬â”€â”€â”€â”˜                                  â”‚
â”‚    â”‚        â”‚           â”‚           â”‚                                       â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                       â”‚
â”‚                    â–¼                                                        â”‚
â”‚         TransactionState { ir_cache, chunks, indexes }                      â”‚
â”‚         (ì‹¤ì œ DBì— ì“°ì§€ ì•Šê³  ì„ì‹œ ì €ì¥)                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 5: COMMIT (ì›ìì  ì»¤ë°‹)                                                â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      ConflictRegistry                                   â”‚ â”‚
â”‚ â”‚  - ì¶©ëŒ ì—¬ë¶€ ìµœì¢… í™•ì¸                                                    â”‚ â”‚
â”‚ â”‚  - Strategy: SKIP / QUEUE / CANCEL_OLD / LAST_WRITE_WINS                â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                      â”‚
â”‚                      â”‚ ì¶©ëŒ ì—†ìŒ?    â”‚                                      â”‚
â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                      â”‚
â”‚                     Yes      â”‚      No                                      â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚              â–¼                               â–¼                              â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚    â”‚ txn.commit()    â”‚             â”‚ txn.rollback()  â”‚                      â”‚
â”‚    â”‚ - Graph DB ë°˜ì˜ â”‚             â”‚ - ìƒíƒœ íê¸°     â”‚                      â”‚
â”‚    â”‚ - Vector DB ë°˜ì˜â”‚             â”‚ - AutoRetryLoop â”‚                      â”‚
â”‚    â”‚ - Lexical ë°˜ì˜  â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Stage 6: CLEANUP (ì •ë¦¬ ë° ê²€ì¦)                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      ConsistencyChecker                                 â”‚ â”‚
â”‚ â”‚  - ì¸ë±ìŠ¤ ê°„ ì¼ê´€ì„± ê²€ì¦ (ìƒ˜í”Œë§)                                         â”‚ â”‚
â”‚ â”‚  - Drift ê°ì§€                                                           â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      SelfHealer (ì‹ ê·œ)                                  â”‚ â”‚
â”‚ â”‚  - ë¶ˆì¼ì¹˜ ë°œê²¬ ì‹œ í•´ë‹¹ ë¶€ë¶„ë§Œ ìë™ ì¬ë¹Œë“œ                                  â”‚ â”‚
â”‚ â”‚  - ë°±ê·¸ë¼ìš´ë“œ ë¶€ë¶„ í’€ ë¹Œë“œ                                                â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚                      Compaction (ë°±ê·¸ë¼ìš´ë“œ)                            â”‚ â”‚
â”‚ â”‚  - Lexical: ì„¸ê·¸ë¨¼íŠ¸ ë³‘í•©                                                â”‚ â”‚
â”‚ â”‚  - Vector: Qdrant ìµœì í™” (ì‹ ê·œ)                                          â”‚ â”‚
â”‚ â”‚  - SnapshotGC: ì˜¤ë˜ëœ ìŠ¤ëƒ…ìƒ· ì •ë¦¬                                         â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â–¼                                              â”‚
â”‚                      CacheInvalidation + Metrics                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.3 í•µì‹¬ êµ¬í˜„: IncrementalOrchestrator

```python
# codegraph_incremental/pipeline/orchestrator.py

from enum import Enum
from dataclasses import dataclass
from typing import Protocol

class PipelineStage(Enum):
    DETECT = "detect"
    ANALYZE = "analyze"
    ISOLATE = "isolate"
    BUILD = "build"
    COMMIT = "commit"
    CLEANUP = "cleanup"

class RebuildStrategy(Enum):
    FULL = "full"          # ì „ì²´ ì¬ë¹Œë“œ (>50 files)
    PARTIAL = "partial"    # ì˜í–¥ë°›ëŠ” íŒŒì¼ë§Œ (5-50 files)
    MINIMAL = "minimal"    # ë³€ê²½ëœ ì‹¬ë³¼ë§Œ (<5 files)

@dataclass
class PipelineResult:
    success: bool
    strategy: RebuildStrategy
    files_processed: int
    files_skipped: int  # Pruningìœ¼ë¡œ ìŠ¤í‚µëœ íŒŒì¼
    elapsed_ms: float
    metrics: dict

class IncrementalOrchestrator:
    """
    í†µí•© ì¦ë¶„ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°.

    WorkflowStateMachineê³¼ IRTransactionManagerë¥¼ ê²°í•©í•˜ì—¬
    6ë‹¨ê³„ ì›ìì  íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        # Detection
        file_watcher: IFileWatcher,
        git_detector: IGitDetector,
        debouncer: IDebouncer,
        # Semantics
        fingerprint_manager: IFingerprintManager,
        identity_tracker: IIdentityTracker,
        affected_calculator: IAffectedCalculator,
        # Transaction
        lock: IDistributedLock,
        txn_manager: ITransactionManager,
        conflict_registry: IConflictRegistry,
        # Builders
        ir_builder: IIncrementalBuilder,
        chunk_builder: IIncrementalBuilder,
        lexical_indexer: IIncrementalIndexer,
        vector_indexer: IIncrementalIndexer,
        # Cleanup
        consistency_checker: IConsistencyChecker,
        self_healer: ISelfHealer,
        compactor: ICompactor,
        # Config
        config: IncrementalConfig,
    ):
        self.watcher = file_watcher
        self.git_detector = git_detector
        self.debouncer = debouncer
        self.fingerprint = fingerprint_manager
        self.identity = identity_tracker
        self.affected = affected_calculator
        self.lock = lock
        self.txn = txn_manager
        self.conflicts = conflict_registry
        self.builders = {
            "L1_IR": ir_builder,
            "L2_CHUNK": chunk_builder,
            "L3_LEXICAL": lexical_indexer,
            "L4_VECTOR": vector_indexer,
        }
        self.checker = consistency_checker
        self.healer = self_healer
        self.compactor = compactor
        self.config = config
        self._metrics = PipelineMetrics()

    async def execute(
        self,
        trigger: TriggerEvent,
        strategy: RebuildStrategy = RebuildStrategy.PARTIAL,
    ) -> PipelineResult:
        """
        6ë‹¨ê³„ ì¦ë¶„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰.

        Args:
            trigger: íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ (FileWatcher, Git, ShadowFS)
            strategy: ë¹Œë“œ ì „ëµ (AUTOë©´ ìë™ ê²°ì •)

        Returns:
            PipelineResult: ì‹¤í–‰ ê²°ê³¼
        """
        start_time = time.perf_counter()

        try:
            # Stage 1: DETECT
            change_set = await self._stage_detect(trigger)
            if change_set.is_empty():
                return PipelineResult(success=True, files_processed=0, ...)

            # Stage 2: ANALYZE & PRUNE
            rebuild_plan = await self._stage_analyze(change_set)
            self._metrics.record("files_pruned", rebuild_plan.pruned_count)

            # ì „ëµ ê²°ì •
            strategy = self._determine_strategy(rebuild_plan, strategy)

            # Stage 3: ISOLATE
            async with self.lock.acquire(rebuild_plan.repo_id, rebuild_plan.snapshot_id):
                async with self.txn.begin() as txn_ctx:
                    try:
                        # Stage 4: BUILD
                        build_results = await self._stage_build(txn_ctx, rebuild_plan, strategy)

                        # Stage 5: COMMIT
                        await self._stage_commit(txn_ctx, build_results)

                    except Exception as e:
                        await txn_ctx.rollback()
                        raise

            # Stage 6: CLEANUP (íŠ¸ëœì­ì…˜ ì™¸ë¶€)
            await self._stage_cleanup(rebuild_plan)

            elapsed = (time.perf_counter() - start_time) * 1000
            return PipelineResult(
                success=True,
                strategy=strategy,
                files_processed=rebuild_plan.file_count,
                files_skipped=rebuild_plan.pruned_count,
                elapsed_ms=elapsed,
                metrics=self._metrics.snapshot(),
            )

        except Exception as e:
            self._metrics.record("pipeline_error", str(e))
            raise

    async def _stage_detect(self, trigger: TriggerEvent) -> ChangeSet:
        """Stage 1: ë³€ê²½ ê°ì§€"""
        if trigger.type == TriggerType.FILE_WATCHER:
            raw_events = await self.watcher.get_events()
            return await self.debouncer.process(raw_events)
        elif trigger.type == TriggerType.GIT:
            return await self.git_detector.detect(trigger.base_commit, trigger.head_commit)
        elif trigger.type == TriggerType.SHADOWFS:
            return trigger.change_set
        else:
            raise ValueError(f"Unknown trigger type: {trigger.type}")

    async def _stage_analyze(self, change_set: ChangeSet) -> RebuildPlan:
        """Stage 2: ë¶„ì„ ë° ê°€ì§€ì¹˜ê¸° (í•µì‹¬)"""
        # 1. ì˜í–¥ ë²”ìœ„ ê³„ì‚°
        affected_files = await self.affected.calculate(
            changed=change_set.all_files,
            call_graph=self._get_call_graph(),
        )

        # 2. Fingerprint ê¸°ë°˜ Pruning â­
        pruned_files = set()
        for file in affected_files:
            if await self.fingerprint.can_skip(file):
                pruned_files.add(file)

        rebuild_files = affected_files - pruned_files

        # 3. Identity ì¶”ì  (ì´ë™/ì´ë¦„ë³€ê²½)
        migrations = await self.identity.track_migrations(change_set.renamed)

        return RebuildPlan(
            files=rebuild_files,
            pruned_count=len(pruned_files),
            migrations=migrations,
            change_set=change_set,
        )

    async def _stage_build(
        self,
        txn_ctx: TransactionContext,
        plan: RebuildPlan,
        strategy: RebuildStrategy,
    ) -> BuildResults:
        """Stage 4: ë³‘ë ¬ ë¹Œë“œ"""
        # ì „ëµì— ë”°ë¥¸ ë¹Œë“œ ë²”ìœ„ ê²°ì •
        if strategy == RebuildStrategy.MINIMAL:
            # L1 (IR)ë§Œ ë¹Œë“œ
            ir_result = await self.builders["L1_IR"].build(plan.files, txn_ctx)
            return BuildResults(ir=ir_result)

        # PARTIAL/FULL: ë³‘ë ¬ ë¹Œë“œ
        async with asyncio.TaskGroup() as tg:
            ir_task = tg.create_task(self.builders["L1_IR"].build(plan.files, txn_ctx))
            lexical_task = tg.create_task(self.builders["L3_LEXICAL"].build(plan.files, txn_ctx))

        ir_result = ir_task.result()

        # L2ëŠ” L1 ì™„ë£Œ í›„
        chunk_result = await self.builders["L2_CHUNK"].build(plan.files, txn_ctx, ir=ir_result)

        # L4ëŠ” L2 ì™„ë£Œ í›„
        vector_result = await self.builders["L4_VECTOR"].build(plan.files, txn_ctx, chunks=chunk_result)

        return BuildResults(
            ir=ir_result,
            chunks=chunk_result,
            lexical=lexical_task.result(),
            vector=vector_result,
        )

    async def _stage_commit(self, txn_ctx: TransactionContext, results: BuildResults):
        """Stage 5: ì›ìì  ì»¤ë°‹"""
        # ì¶©ëŒ í™•ì¸
        conflict = await self.conflicts.check(txn_ctx.txn_id)
        if conflict:
            if conflict.strategy == ConflictStrategy.CANCEL_OLD:
                await self.conflicts.cancel_old(conflict.old_job_id)
            elif conflict.strategy == ConflictStrategy.SKIP:
                raise ConflictSkipError(conflict)

        # ì»¤ë°‹ ì‹¤í–‰
        await txn_ctx.commit()

    async def _stage_cleanup(self, plan: RebuildPlan):
        """Stage 6: ì •ë¦¬ ë° ê²€ì¦"""
        # 1. ì¼ê´€ì„± ê²€ì¦ (ìƒ˜í”Œë§)
        report = await self.checker.check(plan.repo_id, sample_rate=0.1)

        # 2. ë“œë¦¬í”„íŠ¸ ë°œê²¬ ì‹œ ìë™ ë³µêµ¬
        if report.has_drift:
            await self.healer.heal(report.drifted_files)

        # 3. ë°±ê·¸ë¼ìš´ë“œ ì»´íŒ©ì…˜ ìŠ¤ì¼€ì¤„
        if self.compactor.should_run():
            asyncio.create_task(self.compactor.run_background())

    def _determine_strategy(
        self,
        plan: RebuildPlan,
        requested: RebuildStrategy,
    ) -> RebuildStrategy:
        """ìµœì  ì „ëµ ìë™ ê²°ì •"""
        if requested != RebuildStrategy.PARTIAL:
            return requested

        file_count = len(plan.files)
        if file_count < 5:
            return RebuildStrategy.MINIMAL
        elif file_count <= 50:
            return RebuildStrategy.PARTIAL
        else:
            return RebuildStrategy.FULL
```

### 3.4 ì‹ ê·œ ì»´í¬ë„ŒíŠ¸: FingerprintManager

```python
# codegraph_incremental/semantics/fingerprint_manager.py

class FingerprintManager:
    """
    Semantic Pruningì„ ìœ„í•œ Fingerprint ê´€ë¦¬ì.

    í•¨ìˆ˜ì˜ ì‹œê·¸ë‹ˆì²˜ í•´ì‹œê°€ ë³€ê²½ë˜ì§€ ì•Šì•˜ë‹¤ë©´,
    í•´ë‹¹ í•¨ìˆ˜ë¥¼ ì°¸ì¡°í•˜ëŠ” ìƒìœ„ ì˜ì¡´ì„±ì˜ ì¬ë¹Œë“œë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤.

    ì´ ê¸°ìˆ  í•˜ë‚˜ë¡œ ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ì˜ ì¬ë¹Œë“œ ë²”ìœ„ë¥¼ 70% ì´ìƒ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    """

    def __init__(
        self,
        body_hash_service: BodyHashService,
        signature_store: ISignatureStore,
        cache: ICache,
    ):
        self.body_hash = body_hash_service
        self.signatures = signature_store
        self.cache = cache

    async def can_skip(self, file_path: str) -> bool:
        """
        í•´ë‹¹ íŒŒì¼ì˜ ì¬ë¹Œë“œë¥¼ ìŠ¤í‚µí•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨.

        ì¡°ê±´:
        1. íŒŒì¼ì˜ ëª¨ë“  í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ê°€ ì´ì „ê³¼ ë™ì¼
        2. ë˜ëŠ” ë³¸ë¬¸ë§Œ ë³€ê²½ë˜ê³  ì‹œê·¸ë‹ˆì²˜ëŠ” ë™ì¼ (private í•¨ìˆ˜)

        Returns:
            True if ì¬ë¹Œë“œ ë¶ˆí•„ìš”
        """
        # ìºì‹œ í™•ì¸
        cache_key = f"fingerprint:{file_path}"
        cached = await self.cache.get(cache_key)
        if cached:
            return cached.can_skip

        # ì´ì „ ì‹œê·¸ë‹ˆì²˜ ë¡œë“œ
        old_signatures = await self.signatures.get(file_path)
        if not old_signatures:
            return False  # ì‹ ê·œ íŒŒì¼

        # í˜„ì¬ ì‹œê·¸ë‹ˆì²˜ ê³„ì‚°
        new_signatures = await self._compute_signatures(file_path)

        # ë¹„êµ
        for func_id, new_sig in new_signatures.items():
            old_sig = old_signatures.get(func_id)
            if not old_sig:
                return False  # ì‹ ê·œ í•¨ìˆ˜

            # ì‹œê·¸ë‹ˆì²˜ í•´ì‹œ ë¹„êµ (ì´ë¦„, íŒŒë¼ë¯¸í„°, ë¦¬í„´ íƒ€ì…)
            if new_sig.signature_hash != old_sig.signature_hash:
                return False  # ì‹œê·¸ë‹ˆì²˜ ë³€ê²½ë¨ â†’ ìƒìœ„ ì˜ì¡´ì„± ì˜í–¥

        # ëª¨ë“  ì‹œê·¸ë‹ˆì²˜ê°€ ë™ì¼ â†’ ìŠ¤í‚µ ê°€ëŠ¥
        await self.cache.set(cache_key, FingerprintResult(can_skip=True))
        return True

    async def get_changed_signatures(self, file_path: str) -> set[str]:
        """ì‹œê·¸ë‹ˆì²˜ê°€ ë³€ê²½ëœ í•¨ìˆ˜ ID ë°˜í™˜"""
        old_signatures = await self.signatures.get(file_path)
        new_signatures = await self._compute_signatures(file_path)

        changed = set()
        for func_id, new_sig in new_signatures.items():
            old_sig = old_signatures.get(func_id)
            if not old_sig or new_sig.signature_hash != old_sig.signature_hash:
                changed.add(func_id)

        return changed
```

### 3.5 ì‹ ê·œ ì»´í¬ë„ŒíŠ¸: IdentityTracker

```python
# codegraph_incremental/semantics/identity_tracker.py

class IdentityTracker:
    """
    ì‹¬ë³¼ ì •ì²´ì„± ì¶”ì ê¸°.

    íŒŒì¼ ì´ë™ì´ë‚˜ ì´ë¦„ ë³€ê²½ì„ 'ì‚­ì œ í›„ ìƒì„±'ì´ ì•„ë‹Œ
    'ìœ„ì¹˜ ë³€ê²½'ìœ¼ë¡œ ì¸ì‹í•˜ì—¬ ê¸°ì¡´ ì¸ë±ìŠ¤ë¥¼ ì¬ì‚¬ìš©í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        content_hasher: IContentHasher,
        fqn_resolver: IFQNResolver,
        similarity_threshold: float = 0.85,
    ):
        self.hasher = content_hasher
        self.fqn = fqn_resolver
        self.threshold = similarity_threshold

    async def track_migrations(
        self,
        renamed: dict[str, str],  # {old_path: new_path}
    ) -> list[IdentityMigration]:
        """
        íŒŒì¼ ì´ë™/ì´ë¦„ ë³€ê²½ì— ëŒ€í•œ ID ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìƒì„±.

        Returns:
            ë§ˆì´ê·¸ë ˆì´ì…˜ ëª©ë¡ (old_id â†’ new_id ë§¤í•‘)
        """
        migrations = []

        for old_path, new_path in renamed.items():
            # 1. íŒŒì¼ ë‚´ìš© ìœ ì‚¬ë„ í™•ì¸
            old_hash = await self.hasher.hash(old_path)
            new_hash = await self.hasher.hash(new_path)

            if old_hash == new_hash:
                # ì™„ì „ ë™ì¼ â†’ ë‹¨ìˆœ ì´ë™
                migrations.append(IdentityMigration(
                    type=MigrationType.MOVE,
                    old_path=old_path,
                    new_path=new_path,
                    confidence=1.0,
                ))
            else:
                # ë‚´ìš© ë³€ê²½ë¨ â†’ ì‹¬ë³¼ë³„ ë§¤ì¹­
                symbol_migrations = await self._match_symbols(old_path, new_path)
                migrations.extend(symbol_migrations)

        return migrations

    async def _match_symbols(
        self,
        old_path: str,
        new_path: str,
    ) -> list[IdentityMigration]:
        """ì‹¬ë³¼ ë ˆë²¨ ë§¤ì¹­"""
        old_symbols = await self.fqn.get_symbols(old_path)
        new_symbols = await self.fqn.get_symbols(new_path)

        migrations = []
        matched_new = set()

        for old_sym in old_symbols:
            best_match = None
            best_score = 0.0

            for new_sym in new_symbols:
                if new_sym.id in matched_new:
                    continue

                score = self._compute_similarity(old_sym, new_sym)
                if score > best_score and score >= self.threshold:
                    best_match = new_sym
                    best_score = score

            if best_match:
                matched_new.add(best_match.id)
                migrations.append(IdentityMigration(
                    type=MigrationType.RENAME if old_sym.name != best_match.name else MigrationType.MOVE,
                    old_id=old_sym.id,
                    new_id=best_match.id,
                    confidence=best_score,
                ))

        return migrations
```

### 3.6 ì‹ ê·œ ì»´í¬ë„ŒíŠ¸: SelfHealer

```python
# codegraph_incremental/consistency/self_healer.py

class SelfHealer:
    """
    ì¦ë¶„ ë“œë¦¬í”„íŠ¸ ìë™ ë³µêµ¬ê¸°.

    ì¦ë¶„ ì—…ë°ì´íŠ¸ê°€ ë°˜ë³µë˜ë©´ ë¬¼ë¦¬ì  ì¸ë±ìŠ¤(Vector DB)ì™€
    ë…¼ë¦¬ì  ìƒíƒœ(Graph) ì‚¬ì´ì— ë¯¸ì„¸í•œ ë“œë¦¬í”„íŠ¸ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

    ì´ ì»´í¬ë„ŒíŠ¸ëŠ” ìœ íœ´ ì‹œê°„ì— ë°±ê·¸ë¼ìš´ë“œë¡œ ë¶€ë¶„ í’€ ë¹Œë“œë¥¼ ìˆ˜í–‰í•˜ì—¬
    ì¼ê´€ì„±ì„ ë³µêµ¬í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        full_builder: IFullBuilder,
        incremental_builder: IIncrementalBuilder,
        scheduler: IBackgroundScheduler,
        config: SelfHealConfig,
    ):
        self.full_builder = full_builder
        self.incremental_builder = incremental_builder
        self.scheduler = scheduler
        self.config = config

    async def heal(self, drifted_files: set[str]) -> HealResult:
        """
        ë“œë¦¬í”„íŠ¸ëœ íŒŒì¼ë“¤ì„ ë³µêµ¬.

        ì „ëµ:
        1. íŒŒì¼ ìˆ˜ê°€ ì ìœ¼ë©´ (< threshold) ì¦‰ì‹œ ì¬ë¹Œë“œ
        2. íŒŒì¼ ìˆ˜ê°€ ë§ìœ¼ë©´ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„
        """
        if len(drifted_files) <= self.config.immediate_threshold:
            return await self._heal_immediate(drifted_files)
        else:
            return await self._schedule_background_heal(drifted_files)

    async def _heal_immediate(self, files: set[str]) -> HealResult:
        """ì¦‰ì‹œ ë³µêµ¬"""
        results = []
        for file in files:
            result = await self.incremental_builder.rebuild_full(file)
            results.append(result)

        return HealResult(
            healed_count=len(results),
            failed_count=sum(1 for r in results if not r.success),
            mode="immediate",
        )

    async def _schedule_background_heal(self, files: set[str]) -> HealResult:
        """ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ì¼€ì¤„"""
        job_id = await self.scheduler.schedule(
            task=BackgroundHealTask(files=files),
            priority=Priority.LOW,
            delay_seconds=self.config.background_delay,
        )

        return HealResult(
            healed_count=0,
            scheduled_job_id=job_id,
            mode="background",
        )

    async def run_periodic_verification(self):
        """
        ì£¼ê¸°ì  ë¬´ì‘ìœ„ ìƒ˜í”Œë§ ê²€ì¦.

        ì „ì²´ íŒŒì¼ ì¤‘ ì¼ë¶€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì„ íƒí•˜ì—¬
        í’€ ë¹Œë“œ ê²°ê³¼ì™€ ì¦ë¶„ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
        """
        while True:
            await asyncio.sleep(self.config.verification_interval)

            # ë¬´ì‘ìœ„ ìƒ˜í”Œë§
            all_files = await self._get_all_indexed_files()
            sample = random.sample(all_files, min(len(all_files), self.config.sample_size))

            # í’€ ë¹Œë“œ ê²°ê³¼ì™€ ë¹„êµ
            drifted = []
            for file in sample:
                if await self._check_drift(file):
                    drifted.append(file)

            if drifted:
                await self.heal(set(drifted))
```

---

## 4. Migration Plan

### Phase 0: Dead Code ì •ë¦¬ (Week 1)

| ì‘ì—… | íŒŒì¼ | ì•¡ì…˜ |
|------|------|------|
| `parsing/incremental.py` | DiffHunk, DiffParser ì¤‘ë³µ | ì œê±° |
| `parsing/incremental_parser.py` | ìœ ì¼ êµ¬í˜„ ìœ ì§€ | ë¦¬íŒ©í† ë§ |
| ë¯¸ì‚¬ìš© imports | ì „ì²´ | ì •ë¦¬ |

### Phase 1: codegraph-core ì¶”ì¶œ (Week 2-3)

ê³µìš© ëª¨ë¸/ì˜ˆì™¸/í¬íŠ¸ë¥¼ `codegraph-core` íŒ¨í‚¤ì§€ë¡œ ì¶”ì¶œ:

```
CacheEntry (8ê³³) â†’ codegraph_core/cache/entry.py
LRUCache (4ê³³) â†’ codegraph_core/cache/lru.py
DiffHunk (3ê³³) â†’ codegraph_core/diff/hunk.py
Patch (5ê³³) â†’ codegraph_core/patch/models.py
DistributedLock (2ê³³) â†’ codegraph_core/lock/distributed.py
```

### Phase 2: codegraph-incremental ìƒì„± (Week 4-6)

1. **íŒ¨í‚¤ì§€ ìƒì„± ë° êµ¬ì¡° ì„¤ì •**
2. **ê¸°ì¡´ ì½”ë“œ ì´ë™** (import ê²½ë¡œ ìœ ì§€í•˜ë©° ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜)
3. **IncrementalOrchestrator êµ¬í˜„**
4. **ì‹ ê·œ ì»´í¬ë„ŒíŠ¸ êµ¬í˜„**:
   - FingerprintManager
   - IdentityTracker
   - SelfHealer

### Phase 3: íŒŒì´í”„ë¼ì¸ í†µí•© (Week 7-8)

1. **Stage 1-6 ì—°ê²°**
2. **IRTransactionManagerì™€ StateMachine í†µí•©**
3. **í…ŒìŠ¤íŠ¸ ì‘ì„±**

### Phase 4: apps/orchestrator ì •ë¦¬ (Week 9-10)

1. **78ê°œ ì¤‘ë³µ í´ë˜ìŠ¤ â†’ packages importë¡œ êµì²´**
2. **ì˜ì¡´ì„± ì—…ë°ì´íŠ¸**
3. **í†µí•© í…ŒìŠ¤íŠ¸**

---

## 5. Performance Targets

| ì§€í‘œ | í˜„ì¬ | ëª©í‘œ | ê°œì„  |
|------|------|------|------|
| ì¬ë¹Œë“œ íŒŒì¼ ìˆ˜ | 100% ì˜í–¥ ë²”ìœ„ | 30% (Pruning) | **70% ê°ì†Œ** |
| ì¦ë¶„ ë¹Œë“œ ì‹œê°„ (100 files) | ~10s | ~3s | **3x ë¹ ë¦„** |
| ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ë†’ìŒ (ì¤‘ë³µ) | ë‚®ìŒ | **40% ê°ì†Œ** |
| ë“œë¦¬í”„íŠ¸ ë³µêµ¬ | ìˆ˜ë™ | ìë™ | **100% ìë™í™”** |

---

## 6. Success Criteria

1. **ì¤‘ë³µ ì œê±°**: 33ê°œ â†’ 0ê°œ
2. **ì›ìì„±**: ëª¨ë“  ì¦ë¶„ ì—…ë°ì´íŠ¸ê°€ ACID ë³´ì¥
3. **Pruning íš¨ìœ¨**: ë¶ˆí•„ìš”í•œ ì¬ë¹Œë“œ 70% ê°ì†Œ
4. **ìê°€ ì¹˜ìœ **: ë“œë¦¬í”„íŠ¸ ìë™ ê°ì§€ ë° ë³µêµ¬
5. **í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€**: 80% ì´ìƒ

---

## 7. Risks & Mitigations

| ë¦¬ìŠ¤í¬ | ì˜í–¥ | ì™„í™” ì „ëµ |
|--------|------|-----------|
| ëŒ€ê·œëª¨ ë§ˆì´ê·¸ë ˆì´ì…˜ | ê¸°ì¡´ ê¸°ëŠ¥ íŒŒì† | ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜ + Feature flag |
| ì„±ëŠ¥ ì €í•˜ | íŒŒì´í”„ë¼ì¸ ì˜¤ë²„í—¤ë“œ | ë²¤ì¹˜ë§ˆí¬ ê¸°ë°˜ ìµœì í™” |
| ë³µì¡ì„± ì¦ê°€ | ìœ ì§€ë³´ìˆ˜ ì–´ë ¤ì›€ | ëª…í™•í•œ ë ˆì´ì–´ ë¶„ë¦¬ + ë¬¸ì„œí™” |

---

## 8. Open Questions

1. **Cross-repo ì˜ì¡´ì„±**: ëª¨ë…¸ë ˆí¬ ì§€ì› ë²”ìœ„?
2. **Predictive Prefetch**: êµ¬í˜„ ìš°ì„ ìˆœìœ„?
3. **Vector Compaction**: Qdrant ë„¤ì´í‹°ë¸Œ ê¸°ëŠ¥ vs ìì²´ êµ¬í˜„?

---

## 9. Advanced Features (ë³´ì™„ ì‚¬í•­)

### 9.1 Incremental Lineage & Debuggability (ì¶”ì  ê°€ëŠ¥ì„±)

ì¦ë¶„ ì—…ë°ì´íŠ¸ëŠ” "ì™œ ì´ íŒŒì¼ì´ ì¬ë¹Œë“œë˜ì—ˆëŠ”ê°€?" í˜¹ì€ "ì™œ ìŠ¤í‚µë˜ì—ˆëŠ”ê°€?"ë¥¼ ë””ë²„ê¹…í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

#### DecisionLog (ê²°ì • ë¡œê·¸)

```python
# codegraph_incremental/observability/decision_log.py

@dataclass
class PruningDecision:
    """Pruning ê²°ì • ê·¼ê±° ê¸°ë¡"""
    file_path: str
    decision: Literal["REBUILD", "SKIP", "PARTIAL"]
    reason: str  # e.g., "signature_hash_match", "body_only_change"
    old_hash: str | None
    new_hash: str | None
    affected_by: list[str]  # ì–´ë–¤ íŒŒì¼ì˜ ë³€ê²½ìœ¼ë¡œ ì˜í–¥ë°›ì•˜ëŠ”ì§€
    timestamp: datetime

class LineageStore:
    """
    ì¦ë¶„ ì—…ë°ì´íŠ¸ì˜ ê²°ì • ê·¼ê±°ë¥¼ ì €ì¥í•˜ëŠ” ì €ì¥ì†Œ.

    ë‚˜ì¤‘ì— ì¸ë±ì‹± ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¶”ì ì˜ ê·¼ê±°ë¡œ í™œìš©í•©ë‹ˆë‹¤.
    """

    async def record_decision(self, decision: PruningDecision) -> None:
        """ê²°ì • ê¸°ë¡"""

    async def get_file_history(self, file_path: str, limit: int = 100) -> list[PruningDecision]:
        """íŠ¹ì • íŒŒì¼ì˜ ê²°ì • íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""

    async def explain_skip(self, file_path: str, txn_id: str) -> str:
        """ì™œ ìŠ¤í‚µë˜ì—ˆëŠ”ì§€ ì„¤ëª… ìƒì„±"""
```

#### Pipeline Tracer (OpenTelemetry í†µí•©)

```python
# codegraph_incremental/observability/tracer.py

class PipelineTracer:
    """
    6ë‹¨ê³„ ì „ ê³¼ì •ì˜ ì„±ëŠ¥ ë° ê²°ì • ê·¼ê±° ë¡œê¹….

    OpenTelemetry Trace IDë¡œ í•˜ë‚˜ì˜ ë³€ê²½ ì´ë²¤íŠ¸ê°€
    Detectë¶€í„° Cleanupê¹Œì§€ í˜ëŸ¬ê°€ëŠ” ì „ ê³¼ì •ì„ ì¶”ì í•©ë‹ˆë‹¤.
    """

    def __init__(self, exporter: ITraceExporter):
        self.exporter = exporter

    @contextmanager
    def trace_stage(self, stage: PipelineStage, context: dict) -> TraceSpan:
        """ìŠ¤í…Œì´ì§€ ë‹¨ìœ„ ì¶”ì """
        span = self.exporter.start_span(
            name=f"incremental.{stage.value}",
            attributes=context,
        )
        try:
            yield span
        finally:
            span.end()

    def tag_pruning_reason(self, span: TraceSpan, file: str, reason: str):
        """Pruning ì´ìœ  íƒœê¹… (Jaegerì—ì„œ í™•ì¸ ê°€ëŠ¥)"""
        span.set_attribute(f"pruning.{file}", reason)
```

---

### 9.2 Resource Quota & Backpressure (ìì› ì œì–´)

ëŒ€ê·œëª¨ ë¦¬íŒ©í† ë§(ì˜ˆ: í´ë” ì´ë¦„ ë³€ê²½) ì‹œ ìˆ˜ì²œ ê°œì˜ ì´ë²¤íŠ¸ê°€ ë™ì‹œì— ë°œìƒí•©ë‹ˆë‹¤.

#### ResourceManager (ë™ì  ë³‘ë ¬ë„ ì¡°ì ˆ)

```python
# codegraph_incremental/pipeline/resource_manager.py

class ResourceManager:
    """
    ì‹œìŠ¤í…œ ìì›ì— ë”°ë¥¸ ë™ì  ë³‘ë ¬ë„ ì¡°ì ˆ.

    CPU/Memory ë¶€í•˜ì— ë”°ë¼ WorkerPoolì˜ ë³‘ë ¬ë„ë¥¼ ì¡°ì ˆí•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        max_workers: int = 8,
        memory_threshold_mb: int = 4096,
        cpu_threshold_percent: float = 80.0,
    ):
        self.max_workers = max_workers
        self.memory_threshold = memory_threshold_mb
        self.cpu_threshold = cpu_threshold_percent
        self._semaphore = asyncio.Semaphore(max_workers)

    async def get_available_workers(self) -> int:
        """í˜„ì¬ ê°€ìš© ì›Œì»¤ ìˆ˜ ê³„ì‚°"""
        memory_usage = psutil.virtual_memory().percent
        cpu_usage = psutil.cpu_percent()

        if memory_usage > 90 or cpu_usage > self.cpu_threshold:
            return max(1, self.max_workers // 4)  # ìµœì†Œ 1ê°œ
        elif memory_usage > 70:
            return self.max_workers // 2
        else:
            return self.max_workers

    async def throttle_if_needed(self):
        """ìì› ë¶€ì¡± ì‹œ ëŒ€ê¸°"""
        while psutil.virtual_memory().percent > 95:
            await asyncio.sleep(0.5)

class PriorityScheduler:
    """
    ì‘ì—… ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ëŸ¬.

    Priority Levels:
    - HIGH: ìœ ì €ê°€ ì—ë””í„°ì—ì„œ ì§ì ‘ ìˆ˜ì •í•œ íŒŒì¼ (ì¦‰ì‹œ ì²˜ë¦¬)
    - MEDIUM: Git Pull/Mergeë¡œ ì¸í•œ ë³€ê²½ (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬)
    - LOW: SelfHealerì— ì˜í•œ ìë™ ë³µêµ¬ (Idle íƒ€ì„ ì²˜ë¦¬)
    """

    async def schedule(self, task: BuildTask, priority: Priority) -> str:
        """ìš°ì„ ìˆœìœ„ ê¸°ë°˜ ìŠ¤ì¼€ì¤„ë§"""
```

---

### 9.3 Partial Vector Update (ë¸íƒ€ ë²¡í„° ê´€ë¦¬)

íŒŒì¼ ë‚´ì˜ íŠ¹ì • í•¨ìˆ˜(Symbol)ë§Œ ë³€ê²½ë˜ì—ˆì„ ë•Œ, ëª¨ë“  ì²­í¬ë¥¼ ë‹¤ì‹œ ì„ë² ë”©í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.

#### Atomic Chunk Swapping

```python
# codegraph_incremental/indexing/atomic_chunk_swap.py

class AtomicChunkSwapper:
    """
    ë³€ê²½ëœ ì²­í¬ë§Œ ì›ìì ìœ¼ë¡œ êµì²´.

    ì „ì²´ íŒŒì¼ì˜ ëª¨ë“  ì²­í¬ë¥¼ ë‹¤ì‹œ ì„ë² ë”©í•˜ëŠ” ëŒ€ì‹ ,
    ë³€ê²½ëœ ì²­í¬ë§Œ ì‹ë³„í•˜ì—¬ êµì²´í•©ë‹ˆë‹¤.
    """

    async def swap_chunks(
        self,
        file_path: str,
        old_chunks: list[Chunk],
        new_chunks: list[Chunk],
        txn_ctx: TransactionContext,
    ) -> SwapResult:
        """
        ì²­í¬ ë ˆë²¨ ì¦ë¶„ ì—…ë°ì´íŠ¸.

        1. ë³€ê²½ëœ ì²­í¬ ì‹ë³„ (content_hash ë¹„êµ)
        2. ì‚­ì œëœ ì²­í¬ Tombstone ì²˜ë¦¬
        3. ì‹ ê·œ/ë³€ê²½ëœ ì²­í¬ë§Œ ì„ë² ë”©
        4. ì›ìì  êµì²´
        """
        # 1. ë³€ê²½ ë¶„ì„
        added, removed, modified = self._diff_chunks(old_chunks, new_chunks)

        # 2. ë³€ê²½ëœ ê²ƒë§Œ ì„ë² ë”©
        to_embed = added + modified
        if to_embed:
            embeddings = await self._embed_chunks(to_embed)

        # 3. Staging areaì— ì“°ê¸°
        await txn_ctx.stage_chunk_updates(
            add=[(c, e) for c, e in zip(to_embed, embeddings)],
            remove=[c.id for c in removed],
        )

        return SwapResult(
            added=len(added),
            removed=len(removed),
            modified=len(modified),
            skipped=len(new_chunks) - len(added) - len(modified),
        )
```

---

### 9.4 Multi-Engine Atomic Commit (ë¶„ì‚° íŠ¸ëœì­ì…˜)

ì„œë¡œ ë‹¤ë¥¸ DB(Graph DB, Vector DB, Lexical Index)ì— ëŒ€í•œ ì—…ë°ì´íŠ¸ë¥¼ ì›ìì ìœ¼ë¡œ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

#### Distributed Commit Coordinator (2PC ìœ ì‚¬ íŒ¨í„´)

```python
# codegraph_incremental/transaction/distributed_coordinator.py

class DistributedCommitCoordinator:
    """
    ë¶„ì‚° íŠ¸ëœì­ì…˜ ì¡°ì •ì.

    2PC(Two-Phase Commit) ìœ ì‚¬ íŒ¨í„´ìœ¼ë¡œ
    ì—¬ëŸ¬ ì €ì¥ì†Œì— ëŒ€í•œ ì›ìì  ì»¤ë°‹ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        graph_store: IGraphStore,
        vector_store: IVectorStore,
        lexical_store: ILexicalStore,
    ):
        self.stores = {
            "graph": graph_store,
            "vector": vector_store,
            "lexical": lexical_store,
        }

    async def commit(self, txn_ctx: TransactionContext) -> CommitResult:
        """
        2PC ìŠ¤íƒ€ì¼ ë¶„ì‚° ì»¤ë°‹.

        Phase 1 (Prepare): ê° ì—”ì§„ì— Staging Areaì— ì“°ê¸°
        Phase 2 (Commit): ëª¨ë“  ì—”ì§„ì´ ì¤€ë¹„ë˜ë©´ í¬ì¸í„° êµì²´
        Compensation: ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰
        """
        prepared = {}

        try:
            # Phase 1: Prepare
            for name, store in self.stores.items():
                prep_result = await store.prepare(txn_ctx)
                if not prep_result.success:
                    raise PrepareFailedError(name, prep_result.error)
                prepared[name] = prep_result

            # Phase 2: Commit (ëª¨ë“  Prepare ì„±ê³µ)
            for name, store in self.stores.items():
                await store.commit(prepared[name].staging_id)

            return CommitResult(success=True)

        except Exception as e:
            # Compensation: ë¡¤ë°±
            for name, prep in prepared.items():
                await self.stores[name].rollback(prep.staging_id)
            raise
```

---

### 9.5 JIT Shadow Indexing (ì‹¤ì‹œê°„ì„± ë³´ì¥)

Debouncerê°€ 5ì´ˆ ë°°ì¹˜ë¥¼ ê¸°ë‹¤ë¦¬ëŠ” ë™ì•ˆ ì‚¬ìš©ìê°€ ìµœì‹  ì½”ë“œì— ëŒ€í•´ ì§ˆë¬¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Virtual Delta View

```python
# codegraph_incremental/query/virtual_delta_view.py

class VirtualDeltaView:
    """
    ì‹¤ì‹œê°„ ê²€ìƒ‰ì„ ìœ„í•œ ê°€ìƒ ë¸íƒ€ ë·°.

    ì•„ì§ ë¬¼ë¦¬ì ìœ¼ë¡œ ì¸ë±ì‹±ë˜ì§€ ì•Šì€ ShadowFS ë‚´ì˜
    ë³€ê²½ ì‚¬í•­ì„ ëŸ°íƒ€ì„ì— ê²°í•©í•˜ì—¬ ê²°ê³¼ë¥¼ ë³´ì •í•©ë‹ˆë‹¤.
    """

    async def query_with_delta(
        self,
        query: str,
        base_results: list[SearchResult],
        pending_changes: ChangeSet,
    ) -> list[SearchResult]:
        """
        ê²€ìƒ‰ ê²°ê³¼ì— ì‹¤ì‹œê°„ ë³€ê²½ë¶„ ë°˜ì˜.

        1. ê¸°ì¡´ ê²€ìƒ‰ ê²°ê³¼ íšë“
        2. ì‚­ì œëœ íŒŒì¼ì˜ ê²°ê³¼ ì œê±°
        3. ë³€ê²½ëœ íŒŒì¼ì˜ ê²°ê³¼ ì—…ë°ì´íŠ¸ (in-memory diff ì ìš©)
        4. ì‹ ê·œ íŒŒì¼ ê²€ìƒ‰ ì¶”ê°€
        """
        # ì‚­ì œëœ íŒŒì¼ ì œì™¸
        filtered = [r for r in base_results if r.file_path not in pending_changes.deleted]

        # ë³€ê²½ëœ íŒŒì¼ ì—…ë°ì´íŠ¸
        for result in filtered:
            if result.file_path in pending_changes.modified:
                result = await self._apply_in_memory_patch(result, pending_changes)

        # ì‹ ê·œ íŒŒì¼ ê²€ìƒ‰ (ê²½ëŸ‰ in-memory ê²€ìƒ‰)
        if pending_changes.added:
            new_results = await self._search_new_files(query, pending_changes.added)
            filtered.extend(new_results)

        return filtered
```

---

### 9.6 Partial Failure Policy (ë¶€ë¶„ ì‹¤íŒ¨ ì²˜ë¦¬)

1,000ê°œ íŒŒì¼ ë¹Œë“œ ì¤‘ 1ê°œë§Œ ì—ëŸ¬ë‚˜ë„ ì „ì²´ ë¡¤ë°±í•˜ëŠ” ê²ƒì€ ë¹„íš¨ìœ¨ì ì…ë‹ˆë‹¤.

#### BuildErrorPolicy

```python
# codegraph_incremental/pipeline/error_policy.py

class BuildErrorPolicy(Enum):
    FAIL_ALL = "fail_all"          # í•˜ë‚˜ë§Œ ì—ëŸ¬ ë‚˜ë„ ì „ì²´ ë¡¤ë°± (Critical)
    SKIP_AND_REPORT = "skip_and_report"  # ì—ëŸ¬ íŒŒì¼ë§Œ ì œì™¸í•˜ê³  ì»¤ë°‹
    RETRY_LATER = "retry_later"    # ì—ëŸ¬ íŒŒì¼ë§Œ ë³„ë„ íë¡œ ê²©ë¦¬

@dataclass
class PartialBuildResult:
    succeeded: list[str]
    failed: list[tuple[str, Exception]]
    policy_applied: BuildErrorPolicy

class ErrorHandler:
    """
    ë¶€ë¶„ ì‹¤íŒ¨ ì²˜ë¦¬ê¸°.
    """

    def __init__(self, policy: BuildErrorPolicy):
        self.policy = policy

    async def handle_build_errors(
        self,
        results: list[BuildResult],
        txn_ctx: TransactionContext,
    ) -> PartialBuildResult:
        succeeded = [r.file for r in results if r.success]
        failed = [(r.file, r.error) for r in results if not r.success]

        if not failed:
            return PartialBuildResult(succeeded, failed, self.policy)

        if self.policy == BuildErrorPolicy.FAIL_ALL:
            raise BuildFailedError(f"{len(failed)} files failed")

        elif self.policy == BuildErrorPolicy.SKIP_AND_REPORT:
            # ì‹¤íŒ¨í•œ íŒŒì¼ì€ Tombstone ì²˜ë¦¬
            for file, _ in failed:
                await txn_ctx.mark_as_stale(file)
            return PartialBuildResult(succeeded, failed, self.policy)

        elif self.policy == BuildErrorPolicy.RETRY_LATER:
            # ë³„ë„ ì¬ì‹œë„ íì— ì¶”ê°€
            for file, error in failed:
                await self._schedule_retry(file, error)
            return PartialBuildResult(succeeded, failed, self.policy)
```

---

### 9.7 Watcher Continuity (ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‹œ ë³µêµ¬)

ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‹œ FileWatcherê°€ ì¤‘ë‹¨ëœ ì‹œì ë¶€í„° í˜„ì¬ê¹Œì§€ì˜ ë³€ê²½ì‚¬í•­ì„ ë†“ì¹  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

#### Checkpoint Manager (WAL ê¸°ë°˜)

```python
# codegraph_incremental/tracking/checkpoint_manager.py

class CheckpointManager:
    """
    Watcher ì—°ì†ì„± ë³´ì¥ì„ ìœ„í•œ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬ì.

    ê°ì§€ëœ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬ ì „ ë¨¼ì € WALì— ê¸°ë¡í•˜ê³ ,
    ë¶€íŒ… ì‹œ ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ ì´í›„ ë³€ê²½ë¶„ì„ ë³µêµ¬í•©ë‹ˆë‹¤.
    """

    def __init__(self, wal_path: Path, snapshot_store: ISnapshotStore):
        self.wal = WriteAheadLog(wal_path)
        self.snapshots = snapshot_store

    async def record_event(self, event: FileEvent) -> None:
        """ì´ë²¤íŠ¸ë¥¼ WALì— ê¸°ë¡ (ì²˜ë¦¬ ì „)"""
        await self.wal.append(event)

    async def commit_checkpoint(self, snapshot_id: str) -> None:
        """ì²˜ë¦¬ ì™„ë£Œëœ ì‹œì  ê¸°ë¡"""
        await self.snapshots.save_checkpoint(
            snapshot_id=snapshot_id,
            timestamp=datetime.utcnow(),
            wal_position=self.wal.position,
        )

    async def recover_on_startup(self) -> ChangeSet:
        """
        ë¶€íŒ… ì‹œ ëˆ„ë½ëœ ë³€ê²½ë¶„ ë³µêµ¬.

        1. ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
        2. WALì—ì„œ ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ë³µêµ¬
        3. íŒŒì¼ ì‹œìŠ¤í…œ mtimeê³¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ë¶„ ê°ì§€
        """
        last_checkpoint = await self.snapshots.get_last_checkpoint()

        # WAL ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸
        pending_events = await self.wal.read_after(last_checkpoint.wal_position)

        # íŒŒì¼ ì‹œìŠ¤í…œ ìŠ¤ìº” (Range Scan)
        missed_changes = await self._scan_changes_since(last_checkpoint.timestamp)

        return ChangeSet.merge(
            ChangeSet.from_events(pending_events),
            missed_changes,
        )
```

---

### 9.8 Schema Versioning (IR í˜¸í™˜ì„±)

íŒ¨í‚¤ì§€ ë²„ì „ì´ ì˜¬ë¼ê°€ê±°ë‚˜ IR êµ¬ì¡°ê°€ ë³€ê²½ë˜ì—ˆì„ ë•Œ ê¸°ì¡´ ìºì‹œì™€ì˜ í˜¸í™˜ì„± ë¬¸ì œê°€ ë°œìƒí•©ë‹ˆë‹¤.

#### VersionController

```python
# codegraph_incremental/core/version_controller.py

class VersionController:
    """
    IR ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬ ë° í˜¸í™˜ì„± ì²´í¬.
    """

    CURRENT_SCHEMA_VERSION = "2.1.0"

    async def check_compatibility(self, cache_entry: CacheEntry) -> CompatibilityResult:
        """ìºì‹œ ì—”íŠ¸ë¦¬ì˜ í˜¸í™˜ì„± í™•ì¸"""
        entry_version = cache_entry.schema_version

        if entry_version == self.CURRENT_SCHEMA_VERSION:
            return CompatibilityResult.COMPATIBLE

        if self._can_migrate(entry_version, self.CURRENT_SCHEMA_VERSION):
            return CompatibilityResult.NEEDS_MIGRATION

        return CompatibilityResult.INCOMPATIBLE

    async def migrate_if_needed(
        self,
        cache_entry: CacheEntry,
        txn_ctx: TransactionContext,
    ) -> CacheEntry | None:
        """í•„ìš”ì‹œ on-the-fly ë§ˆì´ê·¸ë ˆì´ì…˜"""
        compat = await self.check_compatibility(cache_entry)

        if compat == CompatibilityResult.COMPATIBLE:
            return cache_entry

        if compat == CompatibilityResult.NEEDS_MIGRATION:
            migrated = await self._migrate(cache_entry)
            await txn_ctx.update_cache(migrated)
            return migrated

        # INCOMPATIBLE: ì¬ë¹Œë“œ í•„ìš”
        return None
```

---

### 9.9 Differential Testing Framework (ê²€ì¦ ìë™í™”)

ì¦ë¶„ ì—…ë°ì´íŠ¸ì˜ "ë…¼ë¦¬ì  ëˆ„ë½"ì„ ê²€ì¦í•˜ê¸° ìœ„í•œ ìë™í™” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.

#### Differential Verifier

```python
# codegraph_incremental/testing/differential_verifier.py

class DifferentialVerifier:
    """
    ì¦ë¶„ vs í’€ë¹Œë“œ ê²°ê³¼ ë¹„êµ ê²€ì¦ê¸°.

    í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ë™ì¼í•œ ì½”ë“œ ë³€ê²½ì— ëŒ€í•´
    Full Buildì™€ Incremental Buildë¥¼ ë™ì‹œì— ìˆ˜í–‰í•˜ê³ 
    ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.
    """

    async def verify(
        self,
        change_set: ChangeSet,
        full_builder: IFullBuilder,
        incremental_builder: IIncrementalBuilder,
    ) -> VerificationReport:
        """
        Dual-Path ê²€ì¦.

        1. Full Build ì‹¤í–‰
        2. Incremental Build ì‹¤í–‰
        3. ê²°ê³¼ ë¹„êµ (Graph edges, Vector scores ë“±)
        4. ì˜¤ì°¨ìœ¨ ê³„ì‚°
        """
        # ë³‘ë ¬ ë¹Œë“œ
        async with asyncio.TaskGroup() as tg:
            full_task = tg.create_task(full_builder.build(change_set.all_files))
            incr_task = tg.create_task(incremental_builder.build(change_set))

        full_result = full_task.result()
        incr_result = incr_task.result()

        # ë¹„êµ
        discrepancies = await self._compare_results(full_result, incr_result)

        return VerificationReport(
            full_edge_count=full_result.edge_count,
            incr_edge_count=incr_result.edge_count,
            discrepancies=discrepancies,
            parity_score=1.0 - (len(discrepancies) / max(full_result.edge_count, 1)),
        )
```

---

### 9.10 Graceful Degradation (ë‹¨ê³„ì  ì„±ëŠ¥ ì €í•˜)

ì¦ë¶„ ì‹œìŠ¤í…œ ì‹¤íŒ¨ ì‹œ ìë™ìœ¼ë¡œ Full ì „ëµìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.

#### Fallback Strategy

```python
# codegraph_incremental/pipeline/fallback.py

class FallbackStrategy:
    """
    ì¦ë¶„ ì‹¤íŒ¨ ì‹œ ìë™ Full ì „í™˜.

    TransactionErrorë‚˜ Consistency Driftê°€ ì„ê³„ì¹˜ë¥¼ ë„˜ìœ¼ë©´
    í•´ë‹¹ íŒŒì¼êµ°ì— ëŒ€í•´ FULL ì „ëµìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        drift_threshold: float = 0.05,  # 5% ì´ìƒ ë“œë¦¬í”„íŠ¸ì‹œ ì „í™˜
        error_threshold: int = 3,        # ì—°ì† 3íšŒ ì—ëŸ¬ì‹œ ì „í™˜
    ):
        self.drift_threshold = drift_threshold
        self.error_threshold = error_threshold
        self._error_counts: dict[str, int] = {}

    async def should_fallback(
        self,
        repo_id: str,
        last_result: PipelineResult | None,
    ) -> bool:
        """Full ì „ëµìœ¼ë¡œ ì „í™˜í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨"""
        if last_result and not last_result.success:
            self._error_counts[repo_id] = self._error_counts.get(repo_id, 0) + 1
            if self._error_counts[repo_id] >= self.error_threshold:
                return True
        else:
            self._error_counts[repo_id] = 0

        # ë“œë¦¬í”„íŠ¸ ë¹„ìœ¨ í™•ì¸
        drift_rate = await self._get_drift_rate(repo_id)
        return drift_rate > self.drift_threshold

    def reset_on_success(self, repo_id: str):
        """ì„±ê³µ ì‹œ ì—ëŸ¬ ì¹´ìš´íŠ¸ ë¦¬ì…‹"""
        self._error_counts[repo_id] = 0
```

---

### 9.11 FingerprintManager ë³´ì™„: Global Variable ì²˜ë¦¬

í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ëŠ” ê·¸ëŒ€ë¡œì§€ë§Œ ì°¸ì¡°í•˜ëŠ” ìƒìˆ˜ê°€ ë³€ê²½ëœ ê²½ìš°ë¥¼ ì²˜ë¦¬í•´ì•¼ í•©ë‹ˆë‹¤.

```python
# codegraph_incremental/semantics/fingerprint_manager.py (ë³´ì™„)

class FingerprintManager:
    async def can_skip(self, file_path: str) -> bool:
        # ... ê¸°ì¡´ ë¡œì§ ...

        # ì¶”ê°€: Global Variable/Constant ì°¸ì¡° í™•ì¸
        referenced_globals = await self._get_referenced_globals(file_path)
        for global_ref in referenced_globals:
            if await self._is_global_changed(global_ref):
                return False  # ìƒìˆ˜ ë³€ê²½ë¨ â†’ ì¬ë¹Œë“œ í•„ìš”

        return True

    async def _get_referenced_globals(self, file_path: str) -> list[str]:
        """Data Flow Graphì—ì„œ ì°¸ì¡°í•˜ëŠ” ìƒìˆ˜/ì „ì—­ë³€ìˆ˜ ì¶”ì¶œ"""

    async def _is_global_changed(self, global_ref: str) -> bool:
        """ìƒìˆ˜/ì „ì—­ë³€ìˆ˜ ê°’ì´ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸"""
```

---

## 10. Updated Package Structure

í”¼ë“œë°±ì„ ë°˜ì˜í•œ ìµœì¢… íŒ¨í‚¤ì§€ êµ¬ì¡°:

```
packages/codegraph-incremental/
â””â”€â”€ codegraph_incremental/
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ models.py
    â”‚   â”œâ”€â”€ ports.py
    â”‚   â”œâ”€â”€ events.py
    â”‚   â”œâ”€â”€ errors.py
    â”‚   â””â”€â”€ version_controller.py       # ğŸ†• ìŠ¤í‚¤ë§ˆ ë²„ì „ ê´€ë¦¬
    â”‚
    â”œâ”€â”€ detection/
    â”‚   â”œâ”€â”€ file_watcher.py
    â”‚   â”œâ”€â”€ watcher_debouncer.py
    â”‚   â”œâ”€â”€ git_detector.py
    â”‚   â””â”€â”€ composite_detector.py
    â”‚
    â”œâ”€â”€ semantics/
    â”‚   â”œâ”€â”€ fingerprint_manager.py      # Global Variable ì°¸ì¡° ì¶”ê°€
    â”‚   â”œâ”€â”€ identity_tracker.py
    â”‚   â”œâ”€â”€ affected_calculator.py
    â”‚   â””â”€â”€ pruning_engine.py
    â”‚
    â”œâ”€â”€ tracking/
    â”‚   â”œâ”€â”€ change_tracker.py
    â”‚   â”œâ”€â”€ checkpoint_manager.py       # ğŸ†• WAL ê¸°ë°˜ ë³µêµ¬
    â”‚   â””â”€â”€ dependency_graph.py
    â”‚
    â”œâ”€â”€ transaction/
    â”‚   â”œâ”€â”€ manager.py
    â”‚   â”œâ”€â”€ distributed_coordinator.py  # ğŸ†• 2PC ë¶„ì‚° ì»¤ë°‹
    â”‚   â”œâ”€â”€ state.py
    â”‚   â””â”€â”€ conflict_registry.py
    â”‚
    â”œâ”€â”€ builders/
    â”‚   â”œâ”€â”€ file_builder.py
    â”‚   â”œâ”€â”€ ir_delta_builder.py
    â”‚   â”œâ”€â”€ chunk_builder.py
    â”‚   â””â”€â”€ protocol.py
    â”‚
    â”œâ”€â”€ indexing/
    â”‚   â”œâ”€â”€ incremental_indexer.py
    â”‚   â”œâ”€â”€ atomic_chunk_swap.py        # ğŸ†• ì²­í¬ ë ˆë²¨ ì¦ë¶„
    â”‚   â””â”€â”€ tombstone.py
    â”‚
    â”œâ”€â”€ consistency/
    â”‚   â”œâ”€â”€ checker.py
    â”‚   â”œâ”€â”€ self_healer.py
    â”‚   â””â”€â”€ drift_detector.py
    â”‚
    â”œâ”€â”€ query/
    â”‚   â””â”€â”€ virtual_delta_view.py       # ğŸ†• ì‹¤ì‹œê°„ ê²€ìƒ‰ ì§€ì›
    â”‚
    â”œâ”€â”€ pipeline/
    â”‚   â”œâ”€â”€ orchestrator.py
    â”‚   â”œâ”€â”€ resource_manager.py         # ğŸ†• ìì› ì œì–´
    â”‚   â”œâ”€â”€ priority_scheduler.py       # ğŸ†• ìš°ì„ ìˆœìœ„ ìŠ¤ì¼€ì¤„ë§
    â”‚   â”œâ”€â”€ error_policy.py             # ğŸ†• ë¶€ë¶„ ì‹¤íŒ¨ ì²˜ë¦¬
    â”‚   â”œâ”€â”€ fallback.py                 # ğŸ†• Graceful Degradation
    â”‚   â”œâ”€â”€ stages.py
    â”‚   â””â”€â”€ strategies.py
    â”‚
    â”œâ”€â”€ observability/
    â”‚   â”œâ”€â”€ decision_log.py             # ğŸ†• ê²°ì • ê·¼ê±° ë¡œê¹…
    â”‚   â”œâ”€â”€ lineage_store.py            # ğŸ†• ì¶”ì  ì €ì¥ì†Œ
    â”‚   â”œâ”€â”€ tracer.py                   # ğŸ†• OpenTelemetry í†µí•©
    â”‚   â””â”€â”€ metrics.py
    â”‚
    â”œâ”€â”€ testing/
    â”‚   â””â”€â”€ differential_verifier.py    # ğŸ†• ì¦ë¶„ vs í’€ë¹Œë“œ ê²€ì¦
    â”‚
    â””â”€â”€ config.py
```

---

## 11. Updated Success Criteria

| ê¸°ì¤€ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| ì¤‘ë³µ ì œê±° | 33ê°œ â†’ 0ê°œ | ì½”ë“œ ë¶„ì„ |
| ì›ìì„± | 100% ACID | ë¶„ì‚° íŠ¸ëœì­ì…˜ í…ŒìŠ¤íŠ¸ |
| Pruning íš¨ìœ¨ | 70% ê°ì†Œ | ë²¤ì¹˜ë§ˆí¬ |
| ìê°€ ì¹˜ìœ  | 100% ìë™ | ë“œë¦¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ |
| ë¶€ë¶„ ì‹¤íŒ¨ ë³µêµ¬ | 99% ì„±ê³µ | ì—ëŸ¬ ì£¼ì… í…ŒìŠ¤íŠ¸ |
| ì¬ì‹œì‘ ë³µêµ¬ | <1ì´ˆ | ì„œë¹„ìŠ¤ ì¬ì‹œì‘ í…ŒìŠ¤íŠ¸ |
| ì‹¤ì‹œê°„ ì¿¼ë¦¬ | <100ms ì§€ì—° | Virtual Delta View í…ŒìŠ¤íŠ¸ |
| Differential Parity | 100% ì¼ì¹˜ | ìë™í™” ê²€ì¦ |

---

## 12. Open Questions (Updated)

1. **Cross-repo ì˜ì¡´ì„±**: ì´ˆê¸° ë²„ì „ì€ ë‹¨ì¼ ë ˆí¬ì— ì§‘ì¤‘. `repo_id`ë¥¼ ìƒìœ„ í•„ë“œë¡œ ë‘ì–´ í–¥í›„ í™•ì¥ ê°€ëŠ¥í•˜ê²Œ ì¸í„°í˜ì´ìŠ¤ë§Œ ì—´ì–´ë‘ .

2. **Predictive Prefetch**: Stage 1 ì§í›„ Stage 2ì™€ ë³‘ë ¬ë¡œ ìˆ˜í–‰. ê´€ë ¨ ì˜ì¡´ì„± íŒŒì¼ì„ ë¯¸ë¦¬ L0/L1 ìºì‹œì— ë¡œë“œ.

3. **Vector Compaction**: Qdrant ë„¤ì´í‹°ë¸Œ ê¸°ëŠ¥ ìµœëŒ€ í™œìš© + Semanticaì˜ Tombstone ê´€ë¦¬ì™€ ë™ê¸°í™”í•˜ëŠ” **Compaction Coordinator**ë§Œ ì§ì ‘ êµ¬í˜„.

---

## 13. Critical Considerations (ì‹¤ë¬´ì  ì œì•½ ì‚¬í•­)

### 13.1 ë¶„ì‚° íŠ¸ëœì­ì…˜(2PC)ì˜ í˜„ì‹¤ì  ì œì•½

9.4ì ˆì˜ `DistributedCommitCoordinator`ëŠ” ì´ìƒì ì´ì§€ë§Œ, ì‹¤ì œ ì‚¬ìš©í•˜ëŠ” ì—”ì§„ë“¤(Qdrant, Memgraph, Tantivy)ì´ ë„¤ì´í‹°ë¸Œ XA íŠ¸ëœì­ì…˜ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

**ë¦¬ìŠ¤í¬**: QdrantëŠ” "Prepare" ë‹¨ê³„ì—ì„œ ì“°ê¸° ì ê¸ˆì„ ì™„ë²½íˆ ì œì–´í•˜ê¸° ì–´ë µê³ , ì»¤ë°‹ ì§ì „ ë„¤íŠ¸ì›Œí¬ ì¥ì•  ì‹œ ì •í•©ì„±ì´ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•´ê²°ì±…: Saga íŒ¨í„´ + Outbox íŒ¨í„´**

```python
# codegraph_incremental/transaction/saga_coordinator.py

class SagaCoordinator:
    """
    2PC ëŒ€ì‹  Saga íŒ¨í„´ì„ ì‚¬ìš©í•œ ë¶„ì‚° íŠ¸ëœì­ì…˜.

    ê° ë‹¨ê³„ì˜ ì„±ê³µ/ì‹¤íŒ¨ë¥¼ Outbox í…Œì´ë¸”ì— ê¸°ë¡í•˜ê³ ,
    ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜(Compensating Transaction)ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    """

    async def execute_saga(self, txn_ctx: TransactionContext) -> SagaResult:
        saga_id = str(uuid4())
        steps_completed = []

        try:
            # Step 1: Graph DB
            await self._execute_step(saga_id, "graph", self.graph_store.apply, txn_ctx)
            steps_completed.append("graph")

            # Step 2: Vector DB
            await self._execute_step(saga_id, "vector", self.vector_store.apply, txn_ctx)
            steps_completed.append("vector")

            # Step 3: Lexical Index
            await self._execute_step(saga_id, "lexical", self.lexical_store.apply, txn_ctx)
            steps_completed.append("lexical")

            # ëª¨ë“  ë‹¨ê³„ ì„±ê³µ â†’ Outboxì— COMPLETED ê¸°ë¡
            await self.outbox.mark_completed(saga_id)
            return SagaResult(success=True)

        except Exception as e:
            # ì‹¤íŒ¨ ì‹œ ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰
            await self._compensate(saga_id, steps_completed, txn_ctx)
            await self.outbox.mark_failed(saga_id, str(e))
            raise

    async def _compensate(self, saga_id: str, completed: list[str], txn_ctx):
        """ì—­ìˆœìœ¼ë¡œ ë³´ìƒ íŠ¸ëœì­ì…˜ ì‹¤í–‰"""
        for step in reversed(completed):
            store = getattr(self, f"{step}_store")
            await store.rollback(txn_ctx.snapshot_id)

    async def recover_incomplete_sagas(self):
        """ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‹œ ë¯¸ì™„ë£Œ Saga ë³µêµ¬"""
        incomplete = await self.outbox.get_incomplete()
        for saga in incomplete:
            if saga.should_retry:
                await self.execute_saga(saga.txn_ctx)
            else:
                await self._compensate(saga.id, saga.completed_steps, saga.txn_ctx)
```

---

### 13.2 JIT Shadow Indexingì˜ ìŠ¤ì½”ì–´ ì •ê·œí™”

`VirtualDeltaView`ì—ì„œ ê¸°ì¡´ Vector DB ê²°ê³¼ì™€ ë©”ëª¨ë¦¬ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë³‘í•©í•  ë•Œ, ìœ ì‚¬ë„ ì ìˆ˜ ì²´ê³„ê°€ ë‹¤ë¦…ë‹ˆë‹¤.

**ë¦¬ìŠ¤í¬**: Cosine Similarityì™€ Keyword ë§¤ì¹­ ì ìˆ˜ì˜ ê°€ì¤‘ì¹˜ê°€ ë‹¬ë¼ ìƒìœ„ ê²°ê³¼ê°€ ì™œê³¡ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•´ê²°ì±…: RRF(Reciprocal Rank Fusion) ê¸°ë°˜ ë³‘í•©**

```python
# codegraph_incremental/query/virtual_delta_view.py (ë³´ì™„)

class VirtualDeltaView:
    async def query_with_delta(
        self,
        query: str,
        base_results: list[SearchResult],
        pending_changes: ChangeSet,
    ) -> list[SearchResult]:
        # ... ê¸°ì¡´ ë¡œì§ ...

        # ì‹ ê·œ íŒŒì¼ ê²€ìƒ‰
        if pending_changes.added:
            new_results = await self._search_new_files(query, pending_changes.added)

            # RRF ê¸°ë°˜ ë³‘í•© (ì ìˆ˜ê°€ ì•„ë‹Œ ìˆœìœ„ ê¸°ë°˜)
            merged = self._rrf_merge(filtered, new_results, k=60)
            return merged

        return filtered

    def _rrf_merge(
        self,
        list_a: list[SearchResult],
        list_b: list[SearchResult],
        k: int = 60,
    ) -> list[SearchResult]:
        """
        Reciprocal Rank Fusionìœ¼ë¡œ ë‘ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ë³‘í•©.

        RRF Score = Î£ 1 / (k + rank)

        ì ìˆ˜ ì²´ê³„ê°€ ë‹¬ë¼ë„ ìˆœìœ„ ê¸°ë°˜ìœ¼ë¡œ ê³µì •í•˜ê²Œ ë³‘í•©ë©ë‹ˆë‹¤.
        """
        scores = defaultdict(float)

        for rank, result in enumerate(list_a):
            scores[result.id] += 1 / (k + rank + 1)

        for rank, result in enumerate(list_b):
            scores[result.id] += 1 / (k + rank + 1)

        # ê²°ê³¼ ì¬ì •ë ¬
        all_results = {r.id: r for r in list_a + list_b}
        sorted_ids = sorted(scores.keys(), key=lambda x: scores[x], reverse=True)

        return [all_results[id] for id in sorted_ids]
```

---

### 13.3 FingerprintManagerì˜ ë¶„ì„ ë¹„ìš© ìµœì í™”

Global Variable/Constant ì°¸ì¡° í™•ì¸ì€ ì •ì  ë¶„ì„ ë¹„ìš©ì´ í½ë‹ˆë‹¤.

**ë¦¬ìŠ¤í¬**: ëª¨ë“  íŒŒì¼ ë³€ê²½ë§ˆë‹¤ ì „ì²´ í”„ë¡œì íŠ¸ì˜ Data Flowë¥¼ ê³„ì‚°í•˜ë©´ Pruningì˜ ì˜ë¯¸ê°€ í‡´ìƒ‰ë©ë‹ˆë‹¤.

**í•´ê²°ì±…: Pre-computed Dependency Map**

```python
# codegraph_incremental/semantics/fingerprint_manager.py (ë³´ì™„)

class FingerprintManager:
    """
    Global Variable ì˜ì¡´ì„± ë§µì„ Stage 6ì—ì„œ ë¯¸ë¦¬ ë¹Œë“œí•˜ê³ ,
    Stage 2ì—ì„œëŠ” Lookupë§Œ ìˆ˜í–‰í•˜ì—¬ Critical Path ë¶€í•˜ë¥¼ ìµœì†Œí™”í•©ë‹ˆë‹¤.
    """

    def __init__(self, global_dep_map: IGlobalDependencyMap):
        self.global_deps = global_dep_map  # Pre-computed map

    async def can_skip(self, file_path: str) -> bool:
        # ... ê¸°ì¡´ ë¡œì§ ...

        # O(1) Lookupìœ¼ë¡œ Global Variable ì°¸ì¡° í™•ì¸
        referenced_globals = self.global_deps.get_references(file_path)
        changed_globals = self.global_deps.get_changed_since(self._last_txn_id)

        if referenced_globals & changed_globals:
            return False  # ìƒìˆ˜ ë³€ê²½ë¨ â†’ ì¬ë¹Œë“œ í•„ìš”

        return True

class GlobalDependencyMapBuilder:
    """
    Stage 6 (Cleanup)ì—ì„œ ë°±ê·¸ë¼ìš´ë“œë¡œ ì˜ì¡´ì„± ë§µ ë¹Œë“œ.
    """

    async def build_incrementally(self, changed_files: set[str]) -> None:
        """ë³€ê²½ëœ íŒŒì¼ë§Œ ë¶„ì„í•˜ì—¬ ë§µ ì—…ë°ì´íŠ¸"""
        for file in changed_files:
            refs = await self._analyze_global_refs(file)
            await self.map.update(file, refs)

    async def run_background(self):
        """ìœ íœ´ ì‹œê°„ì— ì „ì²´ ë§µ ìµœì í™”"""
        await self.map.compact()
```

---

### 13.4 Watcher Continuityì˜ Race Condition ë°©ì§€

ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì§í›„, ë³µêµ¬ ìŠ¤ìº”ê³¼ ì‹¤ì‹œê°„ ì´ë²¤íŠ¸ê°€ ë™ì‹œì— ë°œìƒí•˜ë©´ ì¤‘ë³µ ì²˜ë¦¬ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•´ê²°ì±…: LSN(Log Sequence Number) ê¸°ë°˜ ë©±ë“±ì„± ë³´ì¥**

```python
# codegraph_incremental/tracking/checkpoint_manager.py (ë³´ì™„)

class CheckpointManager:
    def __init__(self, ...):
        self._processed_lsn: int = 0  # ë§ˆì§€ë§‰ ì²˜ë¦¬ëœ ì‹œí€€ìŠ¤ ë²ˆí˜¸
        self._lock = asyncio.Lock()

    async def record_event(self, event: FileEvent) -> None:
        """ì´ë²¤íŠ¸ì— LSN ë¶€ì—¬"""
        event.lsn = await self._get_next_lsn()
        await self.wal.append(event)

    async def process_event(self, event: FileEvent) -> bool:
        """
        ë©±ë“±ì„± ë³´ì¥: ì´ë¯¸ ì²˜ë¦¬ëœ ì´ë²¤íŠ¸ëŠ” ìŠ¤í‚µ.
        """
        async with self._lock:
            if event.lsn <= self._processed_lsn:
                return False  # ì´ë¯¸ ì²˜ë¦¬ë¨

            # ì²˜ë¦¬ ë¡œì§ ...

            self._processed_lsn = event.lsn
            return True

    async def recover_on_startup(self) -> ChangeSet:
        """ë³µêµ¬ ì‹œ LSN ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µ ì œê±°"""
        last_checkpoint = await self.snapshots.get_last_checkpoint()
        self._processed_lsn = last_checkpoint.lsn

        # ì‹¤ì‹œê°„ Watcher ì‹œì‘ ì „ì— ë³µêµ¬ ì™„ë£Œ
        async with self._lock:
            pending_events = await self.wal.read_after(last_checkpoint.lsn)
            # Watcherê°€ ë™ì‹œì— ë˜ì§€ëŠ” ì´ë²¤íŠ¸ëŠ” LSN ì²´í¬ë¡œ ìë™ í•„í„°ë§
            return ChangeSet.from_events(pending_events)
```

---

## 14. Advanced Features (ì¶”ê°€)

### 14.1 Semantic Garbage Collection (ë…¼ë¦¬ì  íŒŒí¸ ì •ë¦¬)

ì¦ë¶„ ì—…ë°ì´íŠ¸ê°€ ë°˜ë³µë˜ë©´ Graph DBì— **ê³ ë¦½ëœ ì‹¬ë³¼(Orphaned Nodes)**ì´ë‚˜ **ìœ ë ¹ ê´€ê³„(Dangling Edges)**ê°€ ë‚¨ìŠµë‹ˆë‹¤.

```python
# codegraph_incremental/compaction/semantic_gc.py

class SemanticGarbageCollector:
    """
    Mark-and-Sweep ê¸°ë°˜ Graph GC.

    Stage 6ì˜ Compactor ë‚´ë¶€ì—ì„œ ì‹¤í–‰ë©ë‹ˆë‹¤.
    """

    def __init__(
        self,
        graph_store: IGraphStore,
        gc_threshold_txns: int = 100,  # 100íšŒ íŠ¸ëœì­ì…˜ë§ˆë‹¤ GC
        retention_period: timedelta = timedelta(days=7),
    ):
        self.graph = graph_store
        self.threshold = gc_threshold_txns
        self.retention = retention_period

    async def run_gc(self, current_txn_id: int) -> GCResult:
        """
        Mark-and-Sweep GC ì‹¤í–‰.

        1. Mark: ì‹¤ì œ ì†ŒìŠ¤ì½”ë“œì—ì„œ ë„ë‹¬ ê°€ëŠ¥í•œ ì‹¬ë³¼ì— last_seen_txn_id ë§ˆí‚¹
        2. Sweep: retention_period ë™ì•ˆ ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì€ ë…¸ë“œ/ì—£ì§€ ì‚­ì œ
        """
        if current_txn_id % self.threshold != 0:
            return GCResult(skipped=True)

        # Phase 1: Mark
        reachable_symbols = await self._collect_reachable_symbols()
        await self.graph.mark_seen(reachable_symbols, current_txn_id)

        # Phase 2: Sweep
        cutoff_txn = current_txn_id - self.threshold * 2
        orphaned = await self.graph.find_orphaned(
            last_seen_before=cutoff_txn,
            retention=self.retention,
        )

        deleted_count = 0
        for batch in chunked(orphaned, 1000):
            deleted_count += await self.graph.delete_nodes(batch)

        # Dangling edges ì •ë¦¬
        dangling_edges = await self.graph.find_dangling_edges()
        await self.graph.delete_edges(dangling_edges)

        return GCResult(
            deleted_nodes=deleted_count,
            deleted_edges=len(dangling_edges),
        )
```

---

### 14.2 Copy-on-Write Branch Snapshot (ë©€í‹° ë¸Œëœì¹˜ ì§€ì›)

ë¸Œëœì¹˜ë¥¼ ë¹ˆë²ˆí•˜ê²Œ ì „í™˜í•  ë•Œ, ë§¤ë²ˆ ëŒ€ê·œëª¨ ì¦ë¶„ ì—…ë°ì´íŠ¸ë¥¼ í•˜ëŠ” ê²ƒì€ ë‚­ë¹„ì…ë‹ˆë‹¤.

```python
# codegraph_incremental/branching/cow_index.py

class CopyOnWriteIndexManager:
    """
    Branch-aware Copy-on-Write ì¸ë±ì‹±.

    Gitì˜ ì˜¤ë¸Œì íŠ¸ ì €ì¥ ë°©ì‹ê³¼ ìœ ì‚¬í•˜ê²Œ,
    ë¸Œëœì¹˜ ì „í™˜ ì‹œ ë³€ê²½ëœ ë¶€ë¶„ë§Œ ìƒˆ ë ˆì´ì–´ì— ê¸°ë¡í•©ë‹ˆë‹¤.
    """

    def __init__(self, base_index: IIndex, layer_store: ILayerStore):
        self.base = base_index
        self.layers = layer_store

    async def checkout_branch(self, branch_name: str) -> BranchIndex:
        """
        ë¸Œëœì¹˜ ì „í™˜ ì‹œ CoW ë ˆì´ì–´ ìƒì„±.

        1. ë¶€ëª¨ ë¸Œëœì¹˜ì˜ ìŠ¤ëƒ…ìƒ·ì„ Read-only Layerë¡œ ê³ ì •
        2. ìƒˆ ë¸Œëœì¹˜ìš© Writable Layer ìƒì„±
        3. ê²€ìƒ‰ ì‹œì—ëŠ” ë ˆì´ì–´ë¥¼ ë³‘í•©í•˜ì—¬ ë°˜í™˜
        """
        # ê¸°ì¡´ ë¸Œëœì¹˜ ë ˆì´ì–´ ì°¾ê¸°
        existing = await self.layers.get(branch_name)
        if existing:
            return BranchIndex(
                branch=branch_name,
                base_layer=existing.parent,
                delta_layer=existing,
            )

        # ìƒˆ ë¸Œëœì¹˜: í˜„ì¬ ìƒíƒœë¥¼ ë¶€ëª¨ë¡œ ê³ ì •
        parent_snapshot = await self.base.snapshot()
        new_layer = await self.layers.create(
            branch=branch_name,
            parent=parent_snapshot,
        )

        return BranchIndex(
            branch=branch_name,
            base_layer=parent_snapshot,
            delta_layer=new_layer,
        )

    async def search(self, query: str, branch: str) -> list[SearchResult]:
        """ë ˆì´ì–´ ë³‘í•© ê²€ìƒ‰"""
        branch_idx = await self.checkout_branch(branch)

        # ë¸íƒ€ ë ˆì´ì–´ ìš°ì„  ê²€ìƒ‰
        delta_results = await branch_idx.delta_layer.search(query)

        # ë² ì´ìŠ¤ ë ˆì´ì–´ ê²€ìƒ‰ (ë¸íƒ€ì—ì„œ ì‚­ì œëœ ê²ƒ ì œì™¸)
        deleted_ids = await branch_idx.delta_layer.get_deleted_ids()
        base_results = await branch_idx.base_layer.search(
            query,
            exclude=deleted_ids,
        )

        # RRF ë³‘í•©
        return self._rrf_merge(delta_results, base_results)

    async def merge_branch(self, source: str, target: str) -> MergeResult:
        """
        ë¸Œëœì¹˜ ë³‘í•©.

        ì†ŒìŠ¤ ë¸Œëœì¹˜ì˜ ë¸íƒ€ ë ˆì´ì–´ë¥¼ íƒ€ê²Ÿì— ì ìš©í•©ë‹ˆë‹¤.
        """
        source_delta = await self.layers.get(source)
        target_idx = await self.checkout_branch(target)

        # ì¶©ëŒ ê°ì§€
        conflicts = await self._detect_conflicts(source_delta, target_idx)
        if conflicts:
            return MergeResult(success=False, conflicts=conflicts)

        # ë¸íƒ€ ì ìš©
        await target_idx.delta_layer.apply(source_delta.changes)

        return MergeResult(success=True)
```

---

### 14.3 Branch Snapshot ì‹œê°í™”

```
main (base snapshot)
â”œâ”€â”€ feature-a (delta: +50 files, -10 files)
â”‚   â””â”€â”€ feature-a-fix (delta: +3 files)
â””â”€â”€ feature-b (delta: +20 files)

ê²€ìƒ‰ ì‹œ:
feature-a-fix ë¸Œëœì¹˜ â†’ feature-a-fix delta + feature-a delta + main base
```

---

## 15. Updated Package Structure (Final)

```
packages/codegraph-incremental/
â””â”€â”€ codegraph_incremental/
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ models.py
    â”‚   â”œâ”€â”€ ports.py
    â”‚   â”œâ”€â”€ events.py
    â”‚   â”œâ”€â”€ errors.py
    â”‚   â””â”€â”€ version_controller.py
    â”‚
    â”œâ”€â”€ detection/
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ semantics/
    â”‚   â”œâ”€â”€ fingerprint_manager.py      # Pre-computed map ì‚¬ìš©
    â”‚   â”œâ”€â”€ global_dep_map.py           # ğŸ†• Global Variable ì˜ì¡´ì„± ë§µ
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ tracking/
    â”‚   â”œâ”€â”€ checkpoint_manager.py       # LSN ê¸°ë°˜ ë©±ë“±ì„±
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ transaction/
    â”‚   â”œâ”€â”€ saga_coordinator.py         # ğŸ†• Saga íŒ¨í„´ (2PC ëŒ€ì²´)
    â”‚   â”œâ”€â”€ outbox.py                   # ğŸ†• Outbox íŒ¨í„´
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ compaction/
    â”‚   â”œâ”€â”€ semantic_gc.py              # ğŸ†• Mark-and-Sweep GC
    â”‚   â””â”€â”€ ...
    â”‚
    â”œâ”€â”€ branching/                       # ğŸ†• ë©€í‹° ë¸Œëœì¹˜ ì§€ì›
    â”‚   â”œâ”€â”€ cow_index.py                # Copy-on-Write ì¸ë±ì‹±
    â”‚   â”œâ”€â”€ layer_store.py              # ë ˆì´ì–´ ì €ì¥ì†Œ
    â”‚   â””â”€â”€ merge.py                    # ë¸Œëœì¹˜ ë³‘í•©
    â”‚
    â”œâ”€â”€ query/
    â”‚   â””â”€â”€ virtual_delta_view.py       # RRF ë³‘í•© ì¶”ê°€
    â”‚
    â””â”€â”€ ...
```

---

## 16. Final Success Criteria

| ê¸°ì¤€ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| ì¤‘ë³µ ì œê±° | 33ê°œ â†’ 0ê°œ | ì½”ë“œ ë¶„ì„ |
| ì›ìì„± (Saga) | 99.9% ì„±ê³µ | Outbox ë³µêµ¬ í…ŒìŠ¤íŠ¸ |
| Pruning íš¨ìœ¨ | 70% ê°ì†Œ | ë²¤ì¹˜ë§ˆí¬ |
| ìê°€ ì¹˜ìœ  | 100% ìë™ | ë“œë¦¬í”„íŠ¸ í…ŒìŠ¤íŠ¸ |
| Semantic GC | Orphan 0% | Graph ì •í•©ì„± ê²€ì¦ |
| ë¸Œëœì¹˜ ì „í™˜ | <500ms | CoW ë ˆì´ì–´ í…ŒìŠ¤íŠ¸ |
| ë¶€ë¶„ ì‹¤íŒ¨ ë³µêµ¬ | 99% ì„±ê³µ | ì—ëŸ¬ ì£¼ì… í…ŒìŠ¤íŠ¸ |
| ì¬ì‹œì‘ ë³µêµ¬ (LSN) | <1ì´ˆ, ì¤‘ë³µ 0% | ë©±ë“±ì„± í…ŒìŠ¤íŠ¸ |
| ì‹¤ì‹œê°„ ì¿¼ë¦¬ (RRF) | <100ms | Virtual Delta View í…ŒìŠ¤íŠ¸ |
| Differential Parity | 100% ì¼ì¹˜ | ìë™í™” ê²€ì¦ |

---

## 17. References

- RFC-031: Stable ID Generation
- RFC-039: L0 Cache Architecture
- ADR-003: Workflow State Machine
- [Tree-sitter Incremental Parsing](https://tree-sitter.github.io/tree-sitter/)
- [MVCC in Databases](https://en.wikipedia.org/wiki/Multiversion_concurrency_control)
- [Saga Pattern](https://microservices.io/patterns/data/saga.html)
- [Transactional Outbox Pattern](https://microservices.io/patterns/data/transactional-outbox.html)
- [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf)
- [Copy-on-Write Data Structures](https://en.wikipedia.org/wiki/Copy-on-write)
- [OpenTelemetry Tracing](https://opentelemetry.io/docs/concepts/signals/traces/)
