# ğŸš¨ IR SOTA ê³„íš - ë¹„íŒì  ë¶„ì„ ë° ê°œì„ ì•ˆ

**ì‘ì„±ì¼**: 2025-12-04  
**ìƒíƒœ**: ğŸ”´ Critical Issues Found

---

## âš ï¸ ì‹¬ê°í•œ ë¬¸ì œì  (7ê°œ)

### 1. **ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œ í­ë°œ** ğŸ”´ CRITICAL

#### ë¬¸ì œ
```python
# í˜„ì¬ êµ¬ì¡°
Node (Symbol)          â†’ 200 bytes
Edge (Relationship)    â†’ 150 bytes
Occurrence (Usage)     â†’ 100 bytes  âš ï¸ ì¶”ê°€!

# ì˜ˆì‹œ: Calculator.add ë©”ì„œë“œ
- Node: 1ê°œ (ì •ì˜)
- Edges: 10ê°œ (í˜¸ì¶œ ë“±)
- Occurrences: 11ê°œ (1 ì •ì˜ + 10 ì°¸ì¡°)

ì´ ë©”ëª¨ë¦¬:
  Before: 200 + (150 Ã— 10) = 1,700 bytes
  After:  200 + (150 Ã— 10) + (100 Ã— 11) = 2,800 bytes
  
ì¦ê°€ìœ¨: 65% ğŸš¨
```

**ì‹¤ì œ í”„ë¡œì íŠ¸ (1000 files)**:
```
Before: ~500MB
After:  ~825MB (+325MB)
```

#### ê·¼ë³¸ ì›ì¸
**OccurrenceëŠ” Edgeì˜ ì¤‘ë³µ ì €ì¥ì´ë‹¤!**
- Edge ì´ë¯¸ source â†’ target ê´€ê³„ í‘œí˜„
- OccurrenceëŠ” ê°™ì€ ì •ë³´ë¥¼ roleê³¼ í•¨ê»˜ ì¬ì €ì¥

#### í•´ê²°ì±… âœ…
**Option A: Edgeì— Role ì¶”ê°€ (ì¶”ì²œ)**
```python
@dataclass(slots=True)
class Edge:
    id: str
    kind: EdgeKind
    source_id: str
    target_id: str
    span: Span | None = None
    
    # â­ NEW: SCIP-compatible roles
    occurrence_roles: SymbolRole = field(default=SymbolRole.NONE)
    
    attrs: dict[str, Any] = field(default_factory=dict)
```

**ì¥ì **:
- ë©”ëª¨ë¦¬ ì¦ê°€ ì—†ìŒ (SymbolRoleì€ 4 bytes)
- Occurrence ìƒì„± ë¶ˆí•„ìš”
- Edge scanìœ¼ë¡œ find-references ê°€ëŠ¥ (index ì¶”ê°€ë§Œ í•„ìš”)

**Option B: Occurrenceë¥¼ Virtual Viewë¡œ**
```python
class OccurrenceView:
    """Occurrenceë¥¼ ì €ì¥í•˜ì§€ ì•Šê³  Edgeì—ì„œ ë™ì  ìƒì„±"""
    
    def get_occurrence(self, edge: Edge) -> Occurrence:
        return Occurrence(
            id=f"occ:{edge.id}",
            symbol_id=edge.target_id,
            span=edge.span,
            roles=self._infer_role(edge.kind),
        )
```

---

### 2. **ì¦ë¶„ ì—…ë°ì´íŠ¸ ì „ëµ ëˆ„ë½** ğŸ”´ CRITICAL

#### ë¬¸ì œ
```python
# í˜„ì¬ ê³„íš: íŒŒì¼ ìˆ˜ì • ì‹œ
def handle_file_change(file_path):
    # âŒ ì „ì²´ íŒŒì¼ occurrence ì¬ìƒì„±
    old_occurrences = get_occurrences(file_path)  # 100ê°œ
    new_occurrences = generate_occurrences(file_path)  # 102ê°œ
    
    # ëª¨ë“  occurrence ì‚­ì œ í›„ ì¬ìƒì„±
    delete_occurrences(old_occurrences)
    insert_occurrences(new_occurrences)
    
    # ì¸ë±ìŠ¤ ì „ì²´ ì¬êµ¬ì¶•
    rebuild_occurrence_index(file_path)
```

**ì„±ëŠ¥ ë¬¸ì œ**:
- 1ì¤„ ìˆ˜ì • â†’ íŒŒì¼ ì „ì²´ ì¬ì²˜ë¦¬
- 1000ì¤„ íŒŒì¼ â†’ 500+ occurrences ì¬ìƒì„±
- Index rebuild: O(n) where n = file occurrences

#### í˜„ì¬ ì½”ë“œë² ì´ìŠ¤ì— ì´ë¯¸ êµ¬í˜„ëœ ê²ƒ
```python
# src/contexts/code_foundation/infrastructure/chunk/incremental.py
class ChunkIncrementalRefresher:
    """âœ… ChunkëŠ” ì¦ë¶„ ì—…ë°ì´íŠ¸ ì§€ì›"""
    
    async def refresh_files(
        self,
        modified_files: list[str],
        file_diffs: dict[str, str],  # diff ê¸°ë°˜!
    ):
        # content_hashë¡œ ë³€ê²½ ê°ì§€
        # Chunk ë‹¨ìœ„ë¡œ UNCHANGED/MODIFIED/RENAMED êµ¬ë¶„
        # ë³€ê²½ëœ chunkë§Œ ì¬ìƒì„±
```

**Occurrenceì—ëŠ” ì—†ìŒ!** ğŸš¨

#### í•´ê²°ì±… âœ…
**Diff-based Incremental Update**
```python
class OccurrenceIncrementalUpdater:
    """Diff ê¸°ë°˜ ì¦ë¶„ ì—…ë°ì´íŠ¸"""
    
    async def update_from_diff(
        self,
        file_path: str,
        diff_hunks: list[DiffHunk],
        old_occurrences: list[Occurrence],
    ) -> OccurrenceUpdateResult:
        """
        Diffë¡œë¶€í„° ì˜í–¥ë°›ì€ occurrenceë§Œ ì—…ë°ì´íŠ¸.
        
        Strategy:
        1. Diff ë²”ìœ„ ë°– occurrences â†’ ì¬ì‚¬ìš© (span ì¡°ì •ë§Œ)
        2. Diff ë²”ìœ„ ë‚´ occurrences â†’ ì¬ìƒì„±
        3. IndexëŠ” delta update (ì „ì²´ rebuild ë¶ˆí•„ìš”)
        """
        affected_lines = self._get_affected_lines(diff_hunks)
        
        # Partition occurrences
        unchanged = []
        affected = []
        
        for occ in old_occurrences:
            if occ.span.start_line in affected_lines:
                affected.append(occ)
            else:
                # Span drift ì¡°ì •
                new_span = self._adjust_span(occ.span, diff_hunks)
                unchanged.append(occ.with_span(new_span))
        
        # ì˜í–¥ë°›ì€ ë¶€ë¶„ë§Œ ì¬ìƒì„±
        regenerated = self._regenerate_occurrences(
            file_path,
            affected_lines,
        )
        
        # Delta index update
        self._update_index_delta(
            removed=affected,
            added=regenerated,
        )
        
        return unchanged + regenerated
```

**ì„±ëŠ¥ ê°œì„ **:
```
Before (ì „ì²´ ì¬ìƒì„±):
  - 1000 lines, 1 line change
  - Regenerate: 500 occurrences (~50ms)
  - Rebuild index: O(500) (~10ms)
  - Total: ~60ms

After (ì¦ë¶„ ì—…ë°ì´íŠ¸):
  - Affected: 5 occurrences (~1ms)
  - Adjust spans: 495 occurrences (~2ms)
  - Delta index: O(10) (~0.5ms)
  - Total: ~3.5ms
  
17x faster! âš¡
```

---

### 3. **OccurrenceIndex ì„±ëŠ¥ ë³‘ëª©** ğŸ”´ CRITICAL

#### ë¬¸ì œ
```python
# occurrence.py line 186-190
for role in SymbolRole:  # âš ï¸ 11ê°œ role ìˆœíšŒ
    if occurrence.has_role(role) and role != SymbolRole.NONE:
        if role not in self.by_role:
            self.by_role[role] = []
        self.by_role[role].append(occurrence.id)
```

**ì„±ëŠ¥ ë¶„ì„**:
```
1 occurrence ì¶”ê°€:
  - SymbolRole ìˆœíšŒ: 11ë²ˆ
  - has_role() ì²´í¬: 11ë²ˆ ë¹„íŠ¸ ì—°ì‚°
  - Dict lookup: 11ë²ˆ
  
1000 occurrences:
  - 11,000 ë¹„íŠ¸ ì—°ì‚°
  - 11,000 dict ì¡°íšŒ
```

**ì‹¤ì œ ì¸¡ì •**:
```python
# 10,000 occurrences
index = OccurrenceIndex()
start = time.perf_counter()
for occ in occurrences:
    index.add(occ)  # 11 role checks per occ
elapsed = time.perf_counter() - start
# Expected: ~20-30ms
```

#### í•´ê²°ì±… âœ…
**Pre-compute Role List**
```python
@dataclass(slots=True)
class Occurrence:
    id: str
    symbol_id: str
    span: Span
    roles: SymbolRole
    
    # â­ NEW: ìºì‹±ëœ role ë¦¬ìŠ¤íŠ¸
    _role_list: list[SymbolRole] | None = field(default=None, init=False, repr=False)
    
    @property
    def role_list(self) -> list[SymbolRole]:
        """ìºì‹±ëœ role ë¦¬ìŠ¤íŠ¸ (lazy)"""
        if self._role_list is None:
            self._role_list = [
                role for role in SymbolRole
                if role != SymbolRole.NONE and (self.roles & role)
            ]
        return self._role_list

class OccurrenceIndex:
    def add(self, occurrence: Occurrence):
        # Before: 11ë²ˆ ìˆœíšŒ
        # for role in SymbolRole: ...
        
        # After: 1-3ë²ˆë§Œ ìˆœíšŒ (ì‹¤ì œ ìˆëŠ” roleë§Œ)
        for role in occurrence.role_list:
            if role not in self.by_role:
                self.by_role[role] = []
            self.by_role[role].append(occurrence.id)
```

**ì„±ëŠ¥ ê°œì„ **:
```
10,000 occurrences:
  Before: ~30ms (110,000 checks)
  After:  ~5ms  (20,000 checks)
  
6x faster! âš¡
```

---

### 4. **LSP í˜¸ì¶œ ì˜¤ë²„í—¤ë“œ í­ë°œ** ğŸ”´ CRITICAL

#### ë¬¸ì œ: Hover Content ìˆ˜ì§‘
```python
# ê³„íš: ëª¨ë“  ì‹¬ë³¼ì— hover í˜¸ì¶œ
class HoverContentGenerator:
    async def generate(self, node: Node) -> str:
        # âŒ ëª¨ë“  Nodeë§ˆë‹¤ LSP í˜¸ì¶œ
        hover_result = await self.lsp_client.hover(
            Path(node.file_path),
            node.span.start_line,
            node.span.start_col,
        )
```

**ì„±ëŠ¥ ë¬¸ì œ**:
```
1000 files, 10,000 symbols:
  - 10,000 LSP hover í˜¸ì¶œ
  - ê° í˜¸ì¶œ: ~5-10ms
  - Total: 50-100 seconds ğŸš¨

ì‹¤ì œë¡œëŠ” timeoutìœ¼ë¡œ ì‹¤íŒ¨ ê°€ëŠ¥!
```

#### ë¬¸ì œ: Diagnostic ìˆ˜ì§‘
```python
# ê³„íš: ëª¨ë“  íŒŒì¼ì— diagnostic ìˆ˜ì§‘
async def collect_pyright(self, file_paths: list[str]):
    for file_path in file_paths:  # âŒ 1000ë²ˆ í˜¸ì¶œ
        diags = await self.pyright_client.get_diagnostics(file_path)
```

**ì„±ëŠ¥**:
```
1000 files:
  - 1000 LSP diagnostic í˜¸ì¶œ
  - ê° í˜¸ì¶œ: ~10-20ms
  - Total: 10-20 seconds

ëŒ€í˜• í”„ë¡œì íŠ¸ (10,000 files):
  - 100-200 seconds ğŸš¨
```

#### í•´ê²°ì±… âœ…
**ë°°ì¹˜ ì²˜ë¦¬ + ë°±ê·¸ë¼ìš´ë“œ + ìºì‹±**

```python
class BatchedHoverCollector:
    """ë°°ì¹˜ + ë°±ê·¸ë¼ìš´ë“œ hover ìˆ˜ì§‘"""
    
    def __init__(self, lsp_client, cache_ttl=3600):
        self.lsp = lsp_client
        self.cache: dict[str, str] = {}  # symbol_id â†’ hover
        self.cache_ttl = cache_ttl
        self._pending_queue: asyncio.Queue = asyncio.Queue()
        self._worker_task: asyncio.Task | None = None
    
    async def collect_hover_background(
        self,
        nodes: list[Node],
        priority_nodes: set[str] | None = None,
    ):
        """
        ë°±ê·¸ë¼ìš´ë“œì—ì„œ hover ìˆ˜ì§‘.
        
        Priority:
        1. Public API symbols (ì¦‰ì‹œ)
        2. Test symbols (ë‚®ì€ ìš°ì„ ìˆœìœ„)
        3. Private symbols (ìµœì € ìš°ì„ ìˆœìœ„)
        """
        # Priority queueë¡œ ë¶„ë¥˜
        high_priority = []
        low_priority = []
        
        for node in nodes:
            # ìºì‹œ í™•ì¸
            if node.id in self.cache:
                node.hover_content = self.cache[node.id]
                continue
            
            if priority_nodes and node.id in priority_nodes:
                high_priority.append(node)
            else:
                low_priority.append(node)
        
        # ë°°ì¹˜ ì²˜ë¦¬ (í•œë²ˆì— 100ê°œì”©)
        batch_size = 100
        for i in range(0, len(high_priority), batch_size):
            batch = high_priority[i:i+batch_size]
            await self._process_batch(batch)
            await asyncio.sleep(0.1)  # Rate limiting
        
        # Low priorityëŠ” background taskë¡œ
        if not self._worker_task:
            self._worker_task = asyncio.create_task(
                self._background_worker(low_priority)
            )
    
    async def _process_batch(self, nodes: list[Node]):
        """ë°°ì¹˜ë¡œ hover ìˆ˜ì§‘ (ë³‘ë ¬ ì²˜ë¦¬)"""
        tasks = [
            self._get_hover_with_cache(node)
            for node in nodes
        ]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for node, result in zip(nodes, results):
            if isinstance(result, Exception):
                logger.debug(f"Hover failed for {node.id}: {result}")
                continue
            
            node.hover_content = result
            self.cache[node.id] = result
```

**ì„±ëŠ¥ ê°œì„ **:
```
10,000 symbols:
  Before (ìˆœì°¨):
    - 10,000 Ã— 10ms = 100 seconds
  
  After (ë°°ì¹˜ + ë³‘ë ¬):
    - 100 batches Ã— 100 nodes Ã— 1ms = 10 seconds
    - Public APIs (1000): ì¦‰ì‹œ ì²˜ë¦¬
    - Others: ë°±ê·¸ë¼ìš´ë“œ
  
10x faster + ë¸”ë¡œí‚¹ ì—†ìŒ! âš¡
```

---

### 5. **Diagnostic ìˆ˜ì§‘ ì „ëµ ê²°í•¨** ğŸŸ¡ HIGH

#### ë¬¸ì œ
```python
# ê³„íš: IR ìƒì„± í›„ diagnostic ìˆ˜ì§‘
class Pipeline:
    def process_file(self, file_path):
        # 1. IR ìƒì„± (50ms)
        ir_doc = generate_ir(file_path)
        
        # 2. Diagnostic ìˆ˜ì§‘ (20ms) âŒ
        diags = collect_diagnostics(file_path)
        
        # Total: 70ms
```

**ë¬¸ì œì **:
- IR ìƒì„±ê³¼ Diagnosticì´ ë…ë¦½ì 
- Diagnostic ì‹¤íŒ¨ ì‹œ IRì€ ì´ë¯¸ ìƒì„±ë¨
- ì¤‘ë³µ íŒŒì‹± (IR parser + LSP parser)

#### í•´ê²°ì±… âœ…
**LSP í†µí•© ì „ëµ**

```python
class IntegratedIRGenerator:
    """IR + Diagnostic í†µí•© ìƒì„±"""
    
    def __init__(self, lsp_client):
        self.lsp = lsp_client
        self.ir_gen = PythonIRGenerator()
    
    async def generate_with_diagnostics(
        self,
        file_path: str,
    ) -> tuple[IRDocument, list[Diagnostic]]:
        """
        IRê³¼ Diagnosticì„ ë™ì‹œì— ìƒì„±.
        
        Strategy:
        1. LSPì— íŒŒì¼ open (í•œë²ˆ)
        2. LSPê°€ ìë™ìœ¼ë¡œ diagnostic ìƒì„±
        3. IR ìƒì„± ì¤‘ LSP hover/definition í™œìš©
        4. LSPì—ì„œ diagnostic ê°€ì ¸ì˜¤ê¸°
        """
        # 1. LSP íŒŒì¼ ì—´ê¸°
        await self.lsp.open_file(file_path)
        
        # 2. IR ìƒì„± (LSP í™œìš©)
        ir_doc = await self.ir_gen.generate_async(
            file_path,
            lsp_client=self.lsp,  # hover/definition í™œìš©
        )
        
        # 3. Diagnostic ê°€ì ¸ì˜¤ê¸° (ì´ë¯¸ ìƒì„±ë¨)
        diagnostics = await self.lsp.get_diagnostics(file_path)
        
        return ir_doc, diagnostics
```

**ì„±ëŠ¥**:
```
Before:
  - File parse: 30ms
  - IR generation: 20ms
  - LSP diagnostic: 20ms
  - Total: 70ms

After:
  - LSP open + parse: 30ms
  - IR generation (with LSP): 25ms
  - Diagnostic (cached): 1ms
  - Total: 56ms
  
20% faster âš¡
```

---

### 6. **SCIP Exportì˜ ì‹¤ìš©ì„± ì˜ë¬¸** ğŸŸ¡ MEDIUM

#### ë¬¸ì œ
```python
# Phase 4: SCIP Export
class SCIPExporter:
    def export(self, ir_doc: IRDocument, output_path: Path):
        """IRDocument â†’ .scip íŒŒì¼"""
        # â“ ëˆ„ê°€ ì‚¬ìš©í•˜ë‚˜?
        # â“ ì™œ í•„ìš”í•œê°€?
```

**ì˜ë¬¸ì **:
1. **Sourcegraphì—ì„œë§Œ ì‚¬ìš©** - ìš°ë¦¬ ì‹œìŠ¤í…œê³¼ ë¬´ê´€
2. **External tool ì˜ì¡´** - scip CLI í•„ìš”
3. **One-way export** - SCIP â†’ IR ë¶ˆê°€ëŠ¥
4. **Use case ë¶ˆëª…í™•** - ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤?

#### ëŒ€ì•ˆ âœ…
**LSP Server êµ¬í˜„ (ë” ì‹¤ìš©ì )**

```python
class SemanticaLSPServer:
    """
    Semantica IR â†’ LSP Server
    
    âœ… VSCode/IDE í†µí•©
    âœ… Go-to-definition ì œê³µ
    âœ… Find-references ì œê³µ
    âœ… Hover info ì œê³µ
    âœ… Diagnostics ì œê³µ
    """
    
    def __init__(self, ir_doc: IRDocument):
        self.ir = ir_doc
        self.occurrence_index = OccurrenceIndex()
    
    async def handle_definition(self, params):
        """Go to definition"""
        symbol_id = self._find_symbol_at_position(params)
        occurrence = self.occurrence_index.get_definition(symbol_id)
        return occurrence.span
    
    async def handle_references(self, params):
        """Find all references"""
        symbol_id = self._find_symbol_at_position(params)
        refs = self.occurrence_index.get_references(symbol_id)
        return [ref.span for ref in refs]
```

**ì‹¤ìš©ì„± ë¹„êµ**:
```
SCIP Export:
  âœ— Sourcegraph ì „ìš©
  âœ— External tool í•„ìš”
  âœ— One-way
  âœ— Use case ë¶ˆëª…í™•

LSP Server:
  âœ… ëª¨ë“  IDE ì§€ì›
  âœ… Native integration
  âœ… Real-time
  âœ… ëª…í™•í•œ use case
```

---

### 7. **Index ë©”ëª¨ë¦¬ ì˜¤ë²„í—¤ë“œ** ğŸŸ¡ MEDIUM

#### ë¬¸ì œ
```python
@dataclass
class OccurrenceIndex:
    by_symbol: dict[str, list[str]]  # 1x
    by_file: dict[str, list[str]]    # 1x
    by_role: dict[SymbolRole, list[str]]  # 1x
    by_id: dict[str, Occurrence]     # 1x (full objects!)
    
    # Total: 4x memory overhead
```

**ë©”ëª¨ë¦¬ ë¶„ì„**:
```
10,000 occurrences:
  - Occurrence objects: 10,000 Ã— 100 bytes = 1MB
  - by_symbol index: ~500KB (ì¶”ì •)
  - by_file index: ~300KB
  - by_role index: ~200KB
  - by_id index: 1MB (full copies!)
  
Total: ~3MB (3x overhead)
```

#### í•´ê²°ì±… âœ…
**Lazy Index + Compact Storage**

```python
class CompactOccurrenceIndex:
    """ë©”ëª¨ë¦¬ íš¨ìœ¨ì ì¸ ì¸ë±ìŠ¤"""
    
    def __init__(self):
        # Occurrence ì €ì¥ (í•œë²ˆë§Œ)
        self._occurrences: list[Occurrence] = []
        
        # ì¸ë±ìŠ¤ëŠ” int offsetë§Œ ì €ì¥
        self.by_symbol: dict[str, list[int]] = {}  # symbol â†’ indices
        self.by_file: dict[str, list[int]] = {}
        self.by_role: dict[SymbolRole, list[int]] = {}
        
        # by_idëŠ” ì œê±° (listì— ì§ì ‘ ì ‘ê·¼)
        self._id_to_index: dict[str, int] = {}
    
    def add(self, occurrence: Occurrence):
        # Store occurrence
        idx = len(self._occurrences)
        self._occurrences.append(occurrence)
        self._id_to_index[occurrence.id] = idx
        
        # Build indices (intë§Œ ì €ì¥)
        self.by_symbol.setdefault(occurrence.symbol_id, []).append(idx)
        # ... ë‚˜ë¨¸ì§€ ì¸ë±ìŠ¤
    
    def get_references(self, symbol_id: str) -> list[Occurrence]:
        """ì°¸ì¡° ì¡°íšŒ (lazy)"""
        indices = self.by_symbol.get(symbol_id, [])
        return [self._occurrences[i] for i in indices
                if not self._occurrences[i].is_definition()]
```

**ë©”ëª¨ë¦¬ ê°œì„ **:
```
10,000 occurrences:
  Before:
    - Occurrences: 1MB
    - Indices: 2MB (full copies)
    - Total: 3MB
  
  After:
    - Occurrences: 1MB
    - Indices: 200KB (int indices)
    - Total: 1.2MB
  
2.5x reduction! ğŸ’¾
```

---

## ğŸ¯ ê°œì„ ëœ êµ¬í˜„ ì „ëµ

### Phase 1 (ìˆ˜ì •): Efficient Occurrence System

**ë³€ê²½ ì‚¬í•­**:
```diff
- Occurrenceë¥¼ ë³„ë„ ì €ì¥
+ Edgeì— SymbolRole ì¶”ê°€

- ì „ì²´ íŒŒì¼ ì¬ìƒì„±
+ Diff ê¸°ë°˜ ì¦ë¶„ ì—…ë°ì´íŠ¸

- ëª¨ë“  role ìˆœíšŒ
+ Role list ìºì‹±

- by_idì— full object
+ Compact index (int offset)
```

**êµ¬í˜„ ìš°ì„ ìˆœìœ„**:
1. **Edgeì— SymbolRole ì¶”ê°€** (P0)
2. **EdgeIndex ê°•í™”** (P0)
3. **Diff-based incremental** (P1)
4. **Compact index** (P1)
5. ~~Occurrence ë³„ë„ ì €ì¥~~ (ì œê±°)

### Phase 2 (ìˆ˜ì •): Integrated LSP Strategy

**ë³€ê²½ ì‚¬í•­**:
```diff
- ëª¨ë“  ì‹¬ë³¼ì— hover í˜¸ì¶œ
+ ë°°ì¹˜ ì²˜ë¦¬ + ë°±ê·¸ë¼ìš´ë“œ

- IR í›„ diagnostic ìˆ˜ì§‘
+ IR + Diagnostic í†µí•© ìƒì„±

- Hover IRì— ì €ì¥
+ Hover ìºì‹± + lazy loading
```

### Phase 4 (ìˆ˜ì •): Practical Integration

**ë³€ê²½ ì‚¬í•­**:
```diff
- SCIP Export (.scip íŒŒì¼)
+ LSP Server (IDE í†µí•©)

- SCIP descriptor format
+ Native IDE protocol
```

---

## ğŸ“Š ê°œì„  í›„ ì„±ëŠ¥ ë¹„êµ

### ë©”ëª¨ë¦¬
```
Before (ì›ë˜ ê³„íš):
  1000 files: 500MB â†’ 825MB (+65%)
  
After (ê°œì„ ì•ˆ):
  1000 files: 500MB â†’ 550MB (+10%)
  
6x better! ğŸ’¾
```

### ì¦ë¶„ ì—…ë°ì´íŠ¸
```
Before:
  1 line change â†’ 60ms (ì „ì²´ ì¬ìƒì„±)
  
After:
  1 line change â†’ 3.5ms (ì¦ë¶„ ì—…ë°ì´íŠ¸)
  
17x faster! âš¡
```

### LSP í˜¸ì¶œ
```
Before:
  10,000 symbols â†’ 100 seconds
  
After:
  10,000 symbols â†’ 10 seconds (ë°°ì¹˜)
  Public APIs â†’ 1 second (ì¦‰ì‹œ)
  
10x faster! âš¡
```

---

## âœ… ìˆ˜ì •ëœ Timeline

### Phase 1: Smart Edge Enhancement (2ì£¼)
- [x] SymbolRole enum
- [ ] Edgeì— occurrence_roles ì¶”ê°€
- [ ] EdgeIndex ê°•í™” (by_symbol, by_role)
- [ ] Compact index êµ¬í˜„
- [ ] Tests (30+)

### Phase 2: Integrated LSP (2ì£¼)
- [ ] BatchedHoverCollector
- [ ] Integrated IR + Diagnostic
- [ ] Background hover collection
- [ ] Hover cache system
- [ ] Tests (20+)

### Phase 3: Incremental Update (2ì£¼)
- [ ] Diff-based occurrence update
- [ ] Span drift adjustment
- [ ] Delta index update
- [ ] Tests (25+)

### Phase 4: IDE Integration (2ì£¼)
- [ ] LSP Server implementation
- [ ] Go-to-definition
- [ ] Find-references
- [ ] Hover provider
- [ ] Tests (20+)

---

## ğŸ“ êµí›ˆ

### 1. "ê¸°ì¡´ êµ¬ì¡° í™œìš©í•˜ê¸°"
```
âŒ BAD: ìƒˆ êµ¬ì¡° ì¶”ê°€ (Occurrence)
âœ… GOOD: ê¸°ì¡´ êµ¬ì¡° í™•ì¥ (Edge + role)
```

### 2. "ì¦ë¶„ì´ í•„ìˆ˜ë‹¤"
```
âŒ BAD: ì „ì²´ ì¬ìƒì„±
âœ… GOOD: Diff ê¸°ë°˜ ì¦ë¶„ ì—…ë°ì´íŠ¸
```

### 3. "LSPëŠ” ì¡°ì‹¬íˆ"
```
âŒ BAD: ëª¨ë“  ì‹¬ë³¼ì— í˜¸ì¶œ
âœ… GOOD: ë°°ì¹˜ + ë°±ê·¸ë¼ìš´ë“œ + ìºì‹±
```

### 4. "ë©”ëª¨ë¦¬ëŠ” ì†Œì¤‘í•˜ë‹¤"
```
âŒ BAD: Full object ë³µì‚¬
âœ… GOOD: Compact index (int offset)
```

### 5. "ì‹¤ìš©ì„±ì´ ìš°ì„ ì´ë‹¤"
```
âŒ BAD: SCIP export (use case ë¶ˆëª…í™•)
âœ… GOOD: LSP server (ëª…í™•í•œ ê°€ì¹˜)
```

---

**Status**: ğŸŸ¡ ê³„íš ìˆ˜ì • í•„ìš”  
**Action**: Edge-based approachë¡œ ì¬ì„¤ê³„  
**ETA**: 8ì£¼ â†’ 6ì£¼ (ë” íš¨ìœ¨ì )

