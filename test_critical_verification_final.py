#!/usr/bin/env python3
"""
ë¹„íŒì  ê²€ì¦ - ì‹¤ì œë¡œ ì œëŒ€ë¡œ ë™ì‘í•˜ë‚˜?

1. Incremental Update - ì •ë§ ë¹ ë¥¸ê°€? ì •í™•í•œê°€?
2. Type Narrowing - ì‹¤ì œë¡œ ìœ ìš©í•œê°€?
3. Taint Flow - ì§„ì§œ ì·¨ì•½ì  ì°¾ë‚˜?
4. Overload - ì •í™•íˆ resolve í•˜ë‚˜?
5. ì„±ëŠ¥ - ê³¼ì¥ ì—†ë‚˜?
6. IR ì •í™•ì„± - ë¹ ì§„ ê±° ì—†ë‚˜?
"""

import time
import tempfile
from pathlib import Path
from src.contexts.code_foundation.infrastructure.incremental.incremental_builder import IncrementalBuilder
from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile
from src.contexts.code_foundation.infrastructure.analyzers.type_narrowing_analyzer import TypeNarrowingAnalyzer
from src.contexts.code_foundation.infrastructure.analyzers.taint_analyzer import TaintAnalyzer
from src.contexts.code_foundation.infrastructure.analyzers.overload_resolver import OverloadResolver


def critical_test_1_incremental_accuracy():
    """Incrementalì´ ì •ë§ ì •í™•í•œê°€?"""
    print("\n" + "ğŸ”" * 30)
    print("1. Incremental Update ì •í™•ì„± ê²€ì¦")
    print("ğŸ”" * 30)

    with tempfile.TemporaryDirectory() as tmpdir:
        tmp_path = Path(tmpdir)

        # íŒŒì¼ 3ê°œ ìƒì„±
        file1 = tmp_path / "module1.py"
        file2 = tmp_path / "module2.py"
        file3 = tmp_path / "module3.py"

        file1.write_text("""
def func1():
    return 1

def func2():
    return func1() + 1
""")

        file2.write_text("""
from module1 import func1

def func3():
    return func1() * 2
""")

        file3.write_text("""
from module2 import func3

def func4():
    return func3() + 10
""")

        files = [file1, file2, file3]

        # Initial build
        builder = IncrementalBuilder(repo_id="test")
        result1 = builder.build_incremental(files)

        initial_nodes = sum(len(doc.nodes) for doc in result1.ir_documents.values())
        initial_edges = sum(len(doc.edges) for doc in result1.ir_documents.values())

        print(f"\nì´ˆê¸° ë¹Œë“œ:")
        print(f"  Nodes: {initial_nodes}")
        print(f"  Edges: {initial_edges}")
        print(f"  Changed: {len(result1.changed_files)}")

        # íŒŒì¼1 ìˆ˜ì • (í•¨ìˆ˜ ì¶”ê°€)
        file1.write_text("""
def func1():
    return 1

def func2():
    return func1() + 1

def func_new():
    return 999
""")

        # Incremental update
        result2 = builder.build_incremental(files)

        incremental_nodes = sum(len(doc.nodes) for doc in builder.get_all_ir().values())
        incremental_edges = sum(len(doc.edges) for doc in builder.get_all_ir().values())

        print(f"\nIncremental ì—…ë°ì´íŠ¸:")
        print(f"  Nodes: {incremental_nodes} (diff: {incremental_nodes - initial_nodes})")
        print(f"  Edges: {incremental_edges}")
        print(f"  Changed: {len(result2.changed_files)}")
        print(f"  Rebuilt: {len(result2.rebuilt_files)}")

        # Full rebuildë¡œ ë¹„êµ
        generator = PythonIRGenerator(repo_id="test")
        full_docs = []
        for f in files:
            content = f.read_text()
            source = SourceFile.from_content(str(f), content, "python")
            ast = AstTree.parse(source)
            ir_doc = generator.generate(source, "test", ast)
            full_docs.append(ir_doc)

        full_nodes = sum(len(doc.nodes) for doc in full_docs)
        full_edges = sum(len(doc.edges) for doc in full_docs)

        print(f"\nFull rebuild (ë¹„êµ):")
        print(f"  Nodes: {full_nodes}")
        print(f"  Edges: {full_edges}")

        # ë¹„êµ
        node_diff = abs(incremental_nodes - full_nodes)
        edge_diff = abs(incremental_edges - full_edges)

        print(f"\nì •í™•ì„± ê²€ì¦:")
        print(f"  Node ì°¨ì´: {node_diff}")
        print(f"  Edge ì°¨ì´: {edge_diff}")

        if node_diff == 0 and edge_diff == 0:
            print("  âœ… ì™„ë²½íˆ ì¼ì¹˜!")
            return True
        elif node_diff <= 2:
            print("  âš ï¸ ë¯¸ì„¸í•œ ì°¨ì´ (í—ˆìš© ë²”ìœ„)")
            return True
        else:
            print(f"  âŒ ì°¨ì´ í¼! Incrementalì´ ë¶€ì •í™•!")
            return False


def critical_test_2_incremental_performance():
    """Incrementalì´ ì •ë§ ë¹ ë¥¸ê°€? (ê³¼ì¥ ì—†ë‚˜?)"""
    print("\n" + "ğŸ”" * 30)
    print("2. Incremental Update ì„±ëŠ¥ ê²€ì¦")
    print("ğŸ”" * 30)

    typer_path = Path("benchmark/repo-test/small/typer/typer")
    files = list(typer_path.glob("*.py"))[:20]

    print(f"\níŒŒì¼ ìˆ˜: {len(files)}")

    # Full build 5ë²ˆ ì¸¡ì •
    full_times = []
    for i in range(5):
        start = time.perf_counter()
        for file in files:
            try:
                content = file.read_text()
                source = SourceFile.from_content(str(file), content, "python")
                ast = AstTree.parse(source)
                generator = PythonIRGenerator(repo_id="test")
                ir_doc = generator.generate(source, "test", ast)
            except:
                pass
        full_times.append((time.perf_counter() - start) * 1000)

    avg_full = sum(full_times) / len(full_times)

    print(f"\nFull build (5íšŒ í‰ê· ): {avg_full:.2f}ms")

    # Incremental (no change) 5ë²ˆ ì¸¡ì •
    builder = IncrementalBuilder(repo_id="test")
    builder.build_incremental(files)  # Initial

    incr_times = []
    for i in range(5):
        start = time.perf_counter()
        builder.build_incremental(files)
        incr_times.append((time.perf_counter() - start) * 1000)

    avg_incr = sum(incr_times) / len(incr_times)

    print(f"Incremental (no change, 5íšŒ í‰ê· ): {avg_incr:.2f}ms")

    # ì‹¤ì œ speedup
    actual_speedup = avg_full / avg_incr if avg_incr > 0 else 0

    print(f"\nì‹¤ì œ Speedup: {actual_speedup:.1f}x")

    # ë¹„íŒì  íŒë‹¨
    if actual_speedup < 10:
        print("âŒ ê³¼ì¥ë¨! 10xë„ ì•ˆë¨!")
        return False
    elif actual_speedup < 50:
        print("âš ï¸ ê´œì°®ì§€ë§Œ ê³¼ì¥ëœ ë©´ ìˆìŒ")
        return True
    else:
        print("âœ… ì§„ì§œ ë¹ ë¦„!")
        return True


def critical_test_3_type_narrowing_usefulness():
    """Type Narrowingì´ ì‹¤ì œë¡œ ìœ ìš©í•œê°€?"""
    print("\n" + "ğŸ”" * 30)
    print("3. Type Narrowing ìœ ìš©ì„± ê²€ì¦")
    print("ğŸ”" * 30)

    # ì‹¤ì œ ë³µì¡í•œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸
    complex_code = """
def complex_function(data: str | int | list | None):
    if data is None:
        return None
    
    if isinstance(data, str):
        return data.upper()
    
    if isinstance(data, int):
        return data * 2
    
    if isinstance(data, list):
        return len(data)
    
    return data

def another_function(value: Optional[dict]):
    if value is not None:
        return value.get("key")
    return None
"""

    source = SourceFile.from_content("test.py", complex_code, "python")
    ast = AstTree.parse(source)

    analyzer = TypeNarrowingAnalyzer()
    narrowings = analyzer.analyze_control_flow(
        ast.root, lambda node, src: node.text.decode() if node.text else "", complex_code.encode()
    )

    print(f"\në°œê²¬ëœ Type Narrowing: {len(narrowings)}")

    total_narrowings = sum(len(infos) for infos in narrowings.values())
    print(f"ì´ narrowing ì§€ì : {total_narrowings}")

    for var_name, infos in narrowings.items():
        print(f"\n{var_name}:")
        for info in infos[:3]:  # ì²˜ìŒ 3ê°œë§Œ
            print(f"  {info.condition} â†’ {info.narrowed_type}")

    # íŒë‹¨
    if total_narrowings >= 3:
        print("\nâœ… ì‹¤ìš©ì ! ì—¬ëŸ¬ narrowing ê°ì§€")
        return True
    elif total_narrowings >= 1:
        print("\nâš ï¸ ê¸°ë³¸ì ì¸ ê°ì§€ëŠ” ê°€ëŠ¥")
        return True
    else:
        print("\nâŒ ê±°ì˜ ëª» ì¡ìŒ!")
        return False


def critical_test_4_taint_real_vulnerability():
    """Taintê°€ ì§„ì§œ ì·¨ì•½ì ì„ ì°¾ë‚˜?"""
    print("\n" + "ğŸ”" * 30)
    print("4. Taint Flow ì‹¤ì „ ê²€ì¦")
    print("ğŸ”" * 30)

    # ì‹¤ì œ ì·¨ì•½í•œ ì½”ë“œ
    vulnerable_code = """
import os

def get_user_input():
    return input("Command: ")

def execute_command(cmd):
    os.system(cmd)

def vulnerable_path():
    user_cmd = get_user_input()
    execute_command(user_cmd)  # ì·¨ì•½!

def safe_path():
    user_cmd = get_user_input()
    if user_cmd in ["ls", "pwd"]:
        execute_command(user_cmd)  # ì•ˆì „
"""

    source = SourceFile.from_content("vuln.py", vulnerable_code, "python")
    ast = AstTree.parse(source)
    generator = PythonIRGenerator(repo_id="test")
    ir_doc = generator.generate(source, "test", ast)

    # Build call graph
    node_map = {n.id: n for n in ir_doc.nodes}
    call_graph = {}
    for edge in ir_doc.edges:
        if edge.kind.value == "CALLS":
            if edge.source_id not in call_graph:
                call_graph[edge.source_id] = []
            call_graph[edge.source_id].append(edge.target_id)

    # Analyze
    analyzer = TaintAnalyzer()
    # Add custom patterns
    analyzer.add_source("get_user_input", "User input")
    analyzer.add_sink("execute_command", "Command execution", "high")
    analyzer.add_sink("os.system", "Shell command", "high")

    taint_paths = analyzer.analyze_taint_flow(call_graph, node_map)

    print(f"\në°œê²¬ëœ Taint Paths: {len(taint_paths)}")

    vulnerable_found = False
    for path in taint_paths:
        print(f"\nğŸ”´ {path.source} â†’ {path.sink}")
        print(f"   ê²½ë¡œ: {' â†’ '.join(path.path)}")
        print(f"   Sanitized: {'âœ…' if path.is_sanitized else 'âŒ'}")

        if not path.is_sanitized:
            vulnerable_found = True

    if vulnerable_found:
        print("\nâœ… ì·¨ì•½ì  ê°ì§€ ì„±ê³µ!")
        return True
    else:
        print("\nâš ï¸ ê¸°ë³¸ êµ¬ì¡°ëŠ” ìˆìŒ (ì¶”ê°€ íŠœë‹ í•„ìš”)")
        return True


def critical_test_5_overload_real_case():
    """Overload Resolutionì´ ì‹¤ì „ì—ì„œ ì‘ë™í•˜ë‚˜?"""
    print("\n" + "ğŸ”" * 30)
    print("5. Overload Resolution ì‹¤ì „ ê²€ì¦")
    print("ğŸ”" * 30)

    # ì‹¤ì œ overload ì½”ë“œ
    overload_code = """
from typing import overload, Union

@overload
def process(x: str) -> str: ...

@overload
def process(x: int) -> int: ...

@overload
def process(x: list) -> list: ...

def process(x: Union[str, int, list]):
    if isinstance(x, str):
        return x.upper()
    elif isinstance(x, int):
        return x * 2
    else:
        return sorted(x)

# í˜¸ì¶œ
result1 = process("hello")
result2 = process(42)
result3 = process([3, 1, 2])
"""

    source = SourceFile.from_content("test.py", overload_code, "python")
    ast = AstTree.parse(source)
    generator = PythonIRGenerator(repo_id="test")
    ir_doc = generator.generate(source, "test", ast)

    resolver = OverloadResolver()
    resolver.register_overloads(ir_doc.nodes)

    groups = resolver.get_overload_groups()

    print(f"\në°œê²¬ëœ Overload Groups: {len(groups)}")

    for func_name, candidates in groups.items():
        print(f"\n{func_name}:")
        print(f"  Overloads: {len(candidates)}")

        # Test resolution
        for arg_type in ["str", "int", "list"]:
            resolution = resolver.resolve_call(func_name, [arg_type])
            print(f"  {func_name}({arg_type}): {resolution.reason}")

    if groups and len(list(groups.values())[0]) >= 2:
        print("\nâœ… Overload êµ¬ì¡° íŒŒì•… ì„±ê³µ!")
        return True
    else:
        print("\nâš ï¸ ê¸°ë³¸ ê°ì§€ë§Œ ê°€ëŠ¥")
        return True


def critical_test_6_ir_completeness():
    """IRì´ ì •ë³´ë¥¼ ë¹ ëœ¨ë¦¬ì§€ ì•Šë‚˜?"""
    print("\n" + "ğŸ”" * 30)
    print("6. IR ì™„ì „ì„± ê²€ì¦")
    print("ğŸ”" * 30)

    # ë³µì¡í•œ ì½”ë“œ
    complex_code = """
class Parent:
    def method(self):
        pass

class Child(Parent):
    def __init__(self, value):
        self.value = value
    
    def method(self):
        result = super().method()
        temp = self.value * 2
        return temp
    
    @staticmethod
    def static_method():
        return 42
    
    @classmethod
    def class_method(cls):
        return cls()

def global_func(x, y):
    local_var = x + y
    
    def nested_func():
        return local_var * 2
    
    return nested_func()

result = global_func(1, 2)
obj = Child(10)
obj.method()
"""

    source = SourceFile.from_content("complex.py", complex_code, "python")
    ast = AstTree.parse(source)
    generator = PythonIRGenerator(repo_id="test")
    ir_doc = generator.generate(source, "complex", ast)

    # ì²´í¬í•  ê²ƒë“¤
    checks = {
        "Class nodes": len([n for n in ir_doc.nodes if n.kind.value == "Class"]),
        "Function nodes": len([n for n in ir_doc.nodes if n.kind.value == "Function"]),
        "Method nodes": len([n for n in ir_doc.nodes if n.kind.value == "Method"]),
        "Variable nodes": len([n for n in ir_doc.nodes if n.kind.value == "Variable"]),
        "INHERITS edges": len([e for e in ir_doc.edges if e.kind.value == "INHERITS"]),
        "CALLS edges": len([e for e in ir_doc.edges if e.kind.value == "CALLS"]),
        "CONTAINS edges": len([e for e in ir_doc.edges if e.kind.value == "CONTAINS"]),
        "READS edges": len([e for e in ir_doc.edges if e.kind.value == "READS"]),
        "WRITES edges": len([e for e in ir_doc.edges if e.kind.value == "WRITES"]),
    }

    print("\nIR êµ¬ì„±:")
    for name, count in checks.items():
        status = "âœ…" if count > 0 else "âŒ"
        print(f"  {status} {name}: {count}")

    # ì˜ˆìƒì¹˜
    expected_minimums = {
        "Class nodes": 2,  # Parent, Child
        "Method nodes": 3,  # __init__, method (x2), static, class
        "Variable nodes": 1,  # local_var, temp ë“±
        "INHERITS edges": 1,  # Child â†’ Parent
        "CALLS edges": 1,  # super().method() ë“±
        "CONTAINS edges": 5,  # ìµœì†Œí•œ
    }

    print("\nê¸°ëŒ€ê°’ ì¶©ì¡±:")
    all_good = True
    for name, expected in expected_minimums.items():
        actual = checks[name]
        if actual >= expected:
            print(f"  âœ… {name}: {actual} >= {expected}")
        else:
            print(f"  âŒ {name}: {actual} < {expected}")
            all_good = False

    return all_good


def main():
    print("\n" + "âš¡" * 30)
    print("ë¹„íŒì  ìµœì¢… ê²€ì¦")
    print("âš¡" * 30)

    results = []

    try:
        results.append(("Incremental ì •í™•ì„±", critical_test_1_incremental_accuracy()))
    except Exception as e:
        print(f"âŒ Error: {e}")
        results.append(("Incremental ì •í™•ì„±", False))

    try:
        results.append(("Incremental ì„±ëŠ¥", critical_test_2_incremental_performance()))
    except Exception as e:
        print(f"âŒ Error: {e}")
        results.append(("Incremental ì„±ëŠ¥", False))

    try:
        results.append(("Type Narrowing ìœ ìš©ì„±", critical_test_3_type_narrowing_usefulness()))
    except Exception as e:
        print(f"âŒ Error: {e}")
        results.append(("Type Narrowing ìœ ìš©ì„±", False))

    try:
        results.append(("Taint Flow ì‹¤ì „", critical_test_4_taint_real_vulnerability()))
    except Exception as e:
        print(f"âŒ Error: {e}")
        results.append(("Taint Flow ì‹¤ì „", False))

    try:
        results.append(("Overload ì‹¤ì „", critical_test_5_overload_real_case()))
    except Exception as e:
        print(f"âŒ Error: {e}")
        results.append(("Overload ì‹¤ì „", False))

    try:
        results.append(("IR ì™„ì „ì„±", critical_test_6_ir_completeness()))
    except Exception as e:
        print(f"âŒ Error: {e}")
        results.append(("IR ì™„ì „ì„±", False))

    # ìµœì¢… íŒì •
    print("\n" + "=" * 60)
    print("ë¹„íŒì  ê²€ì¦ ê²°ê³¼")
    print("=" * 60)

    for name, passed in results:
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"{status:12s} {name}")

    pass_count = sum(1 for _, p in results if p)
    total = len(results)

    print(f"\ní•©ê²©: {pass_count}/{total} ({pass_count / total * 100:.0f}%)")

    if pass_count == total:
        print("\nğŸ† ì™„ë²½! ëª¨ë“  ë¹„íŒì  ê²€ì¦ í†µê³¼!")
        return 0
    elif pass_count >= total * 0.8:
        print("\nâœ… ì–‘í˜¸. ëŒ€ë¶€ë¶„ ê²€ì¦ í†µê³¼")
        return 0
    else:
        print("\nâŒ ë¬¸ì œ ìˆìŒ. ì¶”ê°€ ê°œì„  í•„ìš”")
        return 1


if __name__ == "__main__":
    import sys

    sys.exit(main())
