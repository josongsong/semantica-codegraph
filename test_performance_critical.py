#!/usr/bin/env python3
"""
ì„±ëŠ¥ ë¹„íŒì  ê²€ì¦

ì‹¤ì œë¡œ ë¹ ë¥¸ì§€ í™•ì¸:
1. ëŒ€ê·œëª¨ íŒŒì¼ ì²˜ë¦¬ ì‹œê°„
2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
3. ë³‘ëª© êµ¬ê°„ ì‹ë³„
"""

import time
import psutil
import os
from pathlib import Path
from src.contexts.code_foundation.infrastructure.generators.python_generator import PythonIRGenerator
from src.contexts.code_foundation.infrastructure.parsing import AstTree, SourceFile


def measure_memory():
    """í˜„ì¬ í”„ë¡œì„¸ìŠ¤ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)"""
    process = psutil.Process(os.getpid())
    return process.memory_info().rss / 1024 / 1024


def test_single_file_performance():
    """ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì„±ëŠ¥"""
    print("\n" + "=" * 60)
    print("1. ë‹¨ì¼ íŒŒì¼ ì„±ëŠ¥ (typer/main.py)")
    print("=" * 60)

    file_path = Path("benchmark/repo-test/small/typer/typer/main.py")
    content = file_path.read_text()

    print(f"íŒŒì¼ í¬ê¸°: {len(content):,} bytes ({len(content.splitlines())} lines)")

    # íŒŒì‹± ì‹œê°„
    start = time.perf_counter()
    source = SourceFile.from_content(str(file_path), content, "python")
    ast = AstTree.parse(source)
    parse_time = (time.perf_counter() - start) * 1000

    print(f"âœ… Parsing: {parse_time:.2f}ms")

    # IR ìƒì„± ì‹œê°„
    mem_before = measure_memory()
    start = time.perf_counter()
    generator = PythonIRGenerator(repo_id="typer")
    ir_doc = generator.generate(source, "typer", ast)
    ir_time = (time.perf_counter() - start) * 1000
    mem_after = measure_memory()

    print(f"âœ… IR Generation: {ir_time:.2f}ms")
    print(f"âœ… Memory: {mem_after - mem_before:.2f}MB")
    print(f"âœ… Nodes: {len(ir_doc.nodes)}")
    print(f"âœ… Edges: {len(ir_doc.edges)}")

    # ì²˜ë¦¬ëŸ‰
    throughput = len(content) / (ir_time / 1000) / 1024
    print(f"âœ… Throughput: {throughput:.2f} KB/s")

    return ir_time


def test_batch_performance():
    """ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥"""
    print("\n" + "=" * 60)
    print("2. ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ (16 files)")
    print("=" * 60)

    typer_path = Path("benchmark/repo-test/small/typer/typer")
    files = list(typer_path.glob("*.py"))[:16]

    total_size = sum(f.stat().st_size for f in files)
    total_lines = 0

    print(f"íŒŒì¼ ìˆ˜: {len(files)}")
    print(f"ì´ í¬ê¸°: {total_size:,} bytes")

    # ë°°ì¹˜ ì²˜ë¦¬
    mem_before = measure_memory()
    start = time.perf_counter()

    all_docs = []
    for file in files:
        try:
            content = file.read_text()
            total_lines += len(content.splitlines())
            source = SourceFile.from_content(str(file), content, "python")
            ast = AstTree.parse(source)
            generator = PythonIRGenerator(repo_id="typer")
            ir_doc = generator.generate(source, "typer", ast)
            all_docs.append(ir_doc)
        except:
            pass

    total_time = (time.perf_counter() - start) * 1000
    mem_after = measure_memory()

    print(f"ì´ ë¼ì¸: {total_lines:,} lines")
    print(f"âœ… Total Time: {total_time:.2f}ms")
    print(f"âœ… Avg per file: {total_time / len(files):.2f}ms")
    print(f"âœ… Memory: {mem_after - mem_before:.2f}MB")

    # í†µê³„
    total_nodes = sum(len(doc.nodes) for doc in all_docs)
    total_edges = sum(len(doc.edges) for doc in all_docs)

    print(f"âœ… Total Nodes: {total_nodes:,}")
    print(f"âœ… Total Edges: {total_edges:,}")
    print(f"âœ… Throughput: {total_size / 1024 / (total_time / 1000):.2f} KB/s")
    print(f"âœ… Lines/sec: {total_lines / (total_time / 1000):,.0f}")

    return total_time, len(files)


def test_large_file_performance():
    """ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ (worst case)"""
    print("\n" + "=" * 60)
    print("3. ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ (synthetic)")
    print("=" * 60)

    # í° íŒŒì¼ ìƒì„±
    large_code = []
    for i in range(100):
        large_code.append(f"""
class TestClass{i}:
    def __init__(self):
        self.value = {i}
    
    def method_{i}(self, x: int) -> int:
        result = x + self.value
        temp = result * 2
        return temp
    
    def method_{i}_b(self, y: str) -> str:
        return f"{{y}}_{i}"
""")

    content = "\n".join(large_code)

    print(f"ìƒì„± í¬ê¸°: {len(content):,} bytes ({len(content.splitlines())} lines)")

    # ì²˜ë¦¬
    mem_before = measure_memory()
    start = time.perf_counter()

    source = SourceFile.from_content("large.py", content, "python")
    ast = AstTree.parse(source)
    generator = PythonIRGenerator(repo_id="test")
    ir_doc = generator.generate(source, "test", ast)

    total_time = (time.perf_counter() - start) * 1000
    mem_after = measure_memory()

    print(f"âœ… Total Time: {total_time:.2f}ms")
    print(f"âœ… Memory: {mem_after - mem_before:.2f}MB")
    print(f"âœ… Nodes: {len(ir_doc.nodes):,}")
    print(f"âœ… Edges: {len(ir_doc.edges):,}")
    print(f"âœ… Throughput: {len(content) / 1024 / (total_time / 1000):.2f} KB/s")

    return total_time


def test_scalability():
    """í™•ì¥ì„± í…ŒìŠ¤íŠ¸"""
    print("\n" + "=" * 60)
    print("4. í™•ì¥ì„± í…ŒìŠ¤íŠ¸ (1, 5, 10, 20 files)")
    print("=" * 60)

    typer_path = Path("benchmark/repo-test/small/typer/typer")
    all_files = list(typer_path.glob("*.py"))

    results = []

    for count in [1, 5, 10, 20]:
        files = all_files[: min(count, len(all_files))]

        start = time.perf_counter()
        processed = 0

        for file in files:
            try:
                content = file.read_text()
                source = SourceFile.from_content(str(file), content, "python")
                ast = AstTree.parse(source)
                generator = PythonIRGenerator(repo_id="typer")
                ir_doc = generator.generate(source, "typer", ast)
                processed += 1
            except:
                pass

        total_time = (time.perf_counter() - start) * 1000
        avg_time = total_time / processed if processed > 0 else 0

        results.append((count, total_time, avg_time))
        print(f"  {count:2d} files: {total_time:7.2f}ms total, {avg_time:6.2f}ms avg")

    # ì„ í˜•ì„± ì²´í¬
    print("\ní™•ì¥ì„± ë¶„ì„:")
    if len(results) >= 2:
        ratio_10_5 = results[2][1] / results[1][1] if results[1][1] > 0 else 0
        ratio_20_10 = results[3][1] / results[2][1] if results[2][1] > 0 else 0

        print(f"  10 files / 5 files: {ratio_10_5:.2f}x")
        print(f"  20 files / 10 files: {ratio_20_10:.2f}x")

        if ratio_10_5 < 2.5 and ratio_20_10 < 2.5:
            print("  âœ… ì„ í˜• í™•ì¥ì„± ì–‘í˜¸")
        else:
            print("  âš ï¸ ë¹„ì„ í˜• í™•ì¥ (ë³‘ëª© ì¡´ì¬)")


def test_bottleneck_analysis():
    """ë³‘ëª© êµ¬ê°„ ë¶„ì„"""
    print("\n" + "=" * 60)
    print("5. ë³‘ëª© êµ¬ê°„ ë¶„ì„")
    print("=" * 60)

    file_path = Path("benchmark/repo-test/small/typer/typer/main.py")
    content = file_path.read_text()

    # Step by step timing
    timings = {}

    # 1. File I/O
    start = time.perf_counter()
    _ = file_path.read_text()
    timings["file_io"] = (time.perf_counter() - start) * 1000

    # 2. Source creation
    start = time.perf_counter()
    source = SourceFile.from_content(str(file_path), content, "python")
    timings["source_creation"] = (time.perf_counter() - start) * 1000

    # 3. Parsing (tree-sitter)
    start = time.perf_counter()
    ast = AstTree.parse(source)
    timings["parsing"] = (time.perf_counter() - start) * 1000

    # 4. IR Generation
    start = time.perf_counter()
    generator = PythonIRGenerator(repo_id="typer")
    ir_doc = generator.generate(source, "typer", ast)
    timings["ir_generation"] = (time.perf_counter() - start) * 1000

    # 5. Graph building (edges)
    # Already included in IR generation

    total = sum(timings.values())

    print("\nì‹œê°„ ë¶„í¬:")
    for name, time_ms in sorted(timings.items(), key=lambda x: -x[1]):
        pct = time_ms / total * 100
        bar = "â–ˆ" * int(pct / 2)
        print(f"  {name:20s}: {time_ms:7.2f}ms ({pct:5.1f}%) {bar}")

    print(f"\nì´ ì‹œê°„: {total:.2f}ms")

    # ë³‘ëª© íŒì •
    max_name, max_time = max(timings.items(), key=lambda x: x[1])
    if max_time / total > 0.5:
        print(f"âš ï¸ ë³‘ëª©: {max_name} ({max_time / total * 100:.1f}%)")
    else:
        print("âœ… ê· í˜•ì¡íŒ ì²˜ë¦¬ ì‹œê°„")


def main():
    print("\n" + "ğŸ”" * 30)
    print("ì„±ëŠ¥ ë¹„íŒì  ê²€ì¦")
    print("ğŸ”" * 30)

    # Run tests
    single_time = test_single_file_performance()
    batch_time, file_count = test_batch_performance()
    large_time = test_large_file_performance()
    test_scalability()
    test_bottleneck_analysis()

    # Final verdict
    print("\n" + "=" * 60)
    print("ìµœì¢… íŒì •")
    print("=" * 60)

    print(f"\në‹¨ì¼ íŒŒì¼: {single_time:.2f}ms")
    print(f"ë°°ì¹˜ ì²˜ë¦¬: {batch_time:.2f}ms ({file_count} files, {batch_time / file_count:.2f}ms avg)")
    print(f"ëŒ€ìš©ëŸ‰ íŒŒì¼: {large_time:.2f}ms")

    # ê¸°ì¤€
    ACCEPTABLE_SINGLE = 100  # 100ms
    ACCEPTABLE_BATCH_AVG = 20  # 20ms per file

    verdict = []

    if single_time < ACCEPTABLE_SINGLE:
        verdict.append("âœ… ë‹¨ì¼ íŒŒì¼ ì„±ëŠ¥ ì–‘í˜¸")
    else:
        verdict.append(f"âš ï¸ ë‹¨ì¼ íŒŒì¼ ëŠë¦¼ ({single_time:.0f}ms > {ACCEPTABLE_SINGLE}ms)")

    if batch_time / file_count < ACCEPTABLE_BATCH_AVG:
        verdict.append("âœ… ë°°ì¹˜ ì²˜ë¦¬ ì„±ëŠ¥ ì–‘í˜¸")
    else:
        verdict.append(f"âš ï¸ ë°°ì¹˜ ì²˜ë¦¬ ëŠë¦¼ ({batch_time / file_count:.0f}ms > {ACCEPTABLE_BATCH_AVG}ms)")

    print("\n" + "\n".join(verdict))

    # Incremental update í•„ìš”ì„± íŒë‹¨
    print("\n" + "=" * 60)
    print("Incremental Update í•„ìš”ì„±")
    print("=" * 60)

    avg_time = batch_time / file_count

    if avg_time < 10:
        print(f"âœ… í˜„ì¬ ì„±ëŠ¥ ì¶©ë¶„ ({avg_time:.1f}ms/file)")
        print("âš ï¸ Incremental UpdateëŠ” ì„ íƒ ì‚¬í•­")
    elif avg_time < 50:
        print(f"âš ï¸ ì„±ëŠ¥ ê°œì„  ê¶Œì¥ ({avg_time:.1f}ms/file)")
        print("ğŸ’¡ Incremental Update êµ¬í˜„ ì¶”ì²œ")
    else:
        print(f"âŒ ì„±ëŠ¥ ë¬¸ì œ ({avg_time:.1f}ms/file)")
        print("ğŸš¨ Incremental Update í•„ìˆ˜!")

    return 0


if __name__ == "__main__":
    import sys

    sys.exit(main())
