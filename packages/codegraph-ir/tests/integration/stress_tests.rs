//! Stress tests - Extreme conditions and performance limits
//!
//! Tests system behavior under heavy load, large inputs, and resource constraints.

#[path = "../common/mod.rs"]
mod common;
use common::fixtures::*;
use codegraph_ir::pipeline::process_python_file;

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Volume Tests
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore] // Slow - only run with --ignored
fn stress_10000_functions() {
    let source = fixture_n_functions(10000);
    let result = process_python_file(&source, "repo", "extreme.py", "extreme");

    assert!(result.metadata.errors.is_empty());
    let (nodes, ..) = &result.outputs;
    assert!(nodes.len() >= 10000, "Should handle 10k functions");
}

#[test]
#[ignore]
fn stress_1000_classes_with_100_methods_each() {
    let mut source = String::new();
    for i in 0..1000 {
        source.push_str(&fixture_simple_class(&format!("Class{}", i), 100));
        source.push('\n');
    }

    let result = process_python_file(&source, "repo", "huge.py", "huge");
    assert!(result.metadata.errors.is_empty());

    let (nodes, ..) = &result.outputs;
    // 1000 classes + 100,000 methods = 101,000 nodes
    assert!(nodes.len() >= 100000);
}

#[test]
#[ignore]
fn stress_100000_line_file() {
    let source = fixture_large_python_file(1000, 100); // 1000 functions * 100 lines
    let result = process_python_file(&source, "repo", "massive.py", "massive");

    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_deeply_nested_500_levels() {
    let mut source = String::new();
    for i in 0..500 {
        source.push_str(&format!("{}class Level{}:\n", "    ".repeat(i), i));
    }
    source.push_str(&format!("{}pass\n", "    ".repeat(500)));

    let result = process_python_file(&source, "repo", "deep.py", "deep");
    // May hit recursion limits - that's ok, we just verify it doesn't crash
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Memory Tests
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_very_long_string_literal() {
    let huge_string = "x".repeat(1_000_000); // 1 MB string
    let source = format!(r#"text = "{}""#, huge_string);

    let result = process_python_file(&source, "repo", "big_string.py", "big_string");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_many_string_literals() {
    let mut source = String::new();
    for i in 0..10000 {
        source.push_str(&format!("str{} = \"string number {}\"\n", i, i));
    }

    let result = process_python_file(&source, "repo", "many_strings.py", "many_strings");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_massive_list_literal() {
    let items: Vec<String> = (0..100000).map(|i| i.to_string()).collect();
    let source = format!("numbers = [{}]", items.join(", "));

    let result = process_python_file(&source, "repo", "big_list.py", "big_list");
    assert!(result.metadata.errors.is_empty());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Complexity Tests
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_complex_nested_comprehensions() {
    let source = r#"
result = [
    [
        [
            x * y * z
            for z in range(w)
            if z % 2 == 0
        ]
        for y in range(w)
        if y % 3 == 0
    ]
    for x in range(w)
    if x % 5 == 0
    for w in range(x + 1)
]
"#;
    let result = process_python_file(source, "repo", "complex_comp.py", "complex_comp");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_deeply_nested_dicts() {
    let mut source = String::from("data = ");
    for _ in 0..100 {
        source.push_str("{'nested': ");
    }
    source.push_str("'value'");
    for _ in 0..100 {
        source.push('}');
    }

    let result = process_python_file(&source, "repo", "nested_dict.py", "nested_dict");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_many_decorators() {
    let mut source = String::new();
    for i in 0..1000 {
        source.push_str(&format!("@decorator{}\n", i));
    }
    source.push_str("def func(): pass\n");

    let result = process_python_file(&source, "repo", "many_dec.py", "many_dec");
    assert!(result.metadata.errors.is_empty());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Import Graph Complexity
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_1000_imports() {
    let mut source = String::new();
    for i in 0..1000 {
        source.push_str(&format!("import module{}\n", i));
    }
    source.push_str("def main(): pass\n");

    let result = process_python_file(&source, "repo", "many_imports.py", "many_imports");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_complex_from_imports() {
    let mut source = String::new();
    for i in 0..500 {
        source.push_str(&format!(
            "from package{}.subpackage{} import Class{}, Function{}\n",
            i, i, i, i
        ));
    }

    let result = process_python_file(&source, "repo", "complex_imports.py", "complex_imports");
    assert!(result.metadata.errors.is_empty());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Edge Cases - Pathological Inputs
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
fn stress_all_ascii_characters() {
    // Test with all printable ASCII characters in strings
    let mut chars = String::new();
    for c in 32u8..127 {
        chars.push(c as char);
    }
    let source = format!(r#"text = "{}""#, chars);

    let result = process_python_file(&source, "repo", "ascii.py", "ascii");
    assert!(result.metadata.errors.is_empty());
}

#[test]
fn stress_unicode_emoji_overload() {
    let source = r#"
# ğŸš€ğŸ”¥ğŸ’»ğŸ‰âœ¨ğŸŒŸâ­ï¸ğŸ¯ğŸ†ğŸŠ
def celebrate():
    return "ğŸ‰" * 1000

class Emoji:
    """ğŸŒˆ A colorful class ğŸ¦„"""
    def __init__(self):
        self.status = "âœ…" * 100
"#;
    let result = process_python_file(source, "repo", "emoji_heavy.py", "emoji_heavy");
    assert!(result.metadata.errors.is_empty());
}

#[test]
fn stress_mixed_encoding_comments() {
    let source = r#"
# English comment
# í•œê¸€ ì£¼ì„
# ä¸­æ–‡æ³¨é‡Š
# æ—¥æœ¬èªã‚³ãƒ¡ãƒ³ãƒˆ
# Ğ ÑƒÑÑĞºĞ¸Ğ¹ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹
# Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ØªØ¹Ù„ÙŠÙ‚

def multilingual():
    """
    Docstring with multiple languages:
    English, í•œêµ­ì–´, ä¸­æ–‡, æ—¥æœ¬èª, Ğ ÑƒÑÑĞºĞ¸Ğ¹, Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
    """
    pass
"#;
    let result = process_python_file(source, "repo", "multilingual.py", "multilingual");
    assert!(result.metadata.errors.is_empty());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Pathological Name Patterns
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
fn stress_single_letter_names() {
    let source = r#"
def a(): pass
def b(): pass
def c(): pass

class A: pass
class B: pass
class C: pass

x = 1
y = 2
z = 3
"#;
    let result = process_python_file(source, "repo", "single_letter.py", "single_letter");
    assert!(result.metadata.errors.is_empty());
}

#[test]
fn stress_similar_names() {
    let source = r#"
def func(): pass
def func_(): pass
def func__(): pass
def _func(): pass
def __func__(): pass

class Class: pass
class Class_: pass
class _Class: pass
"#;
    let result = process_python_file(source, "repo", "similar.py", "similar");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_many_underscore_variations() {
    let mut source = String::new();
    for i in 0..100 {
        let underscores = "_".repeat(i);
        source.push_str(&format!("def {}func{}(): pass\n", underscores, underscores));
    }

    let result = process_python_file(&source, "repo", "underscores.py", "underscores");
    assert!(result.metadata.errors.is_empty());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Real-World Stress Scenarios
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_django_megamodel() {
    // Simulate a very large Django model with 1000 fields
    let source = fixture_django_model("MegaModel", 1000);
    let result = process_python_file(&source, "repo", "megamodel.py", "megamodel");

    assert!(result.metadata.errors.is_empty());
    let (nodes, ..) = &result.outputs;
    assert!(nodes.len() >= 1000);
}

#[test]
#[ignore]
fn stress_django_app_full_stack() {
    let source = r#"
from django.db import models
from django.views.generic import ListView, DetailView
from rest_framework import serializers, viewsets

# Models (10 models)
"#
    .to_string()
        + &(0..10)
            .map(|i| fixture_django_model(&format!("Model{}", i), 20))
            .collect::<Vec<_>>()
            .join("\n")
        + r#"

# Serializers (10 serializers)
"#
        + &(0..10)
            .map(|i| {
                format!(
                    r#"
class Model{}Serializer(serializers.ModelSerializer):
    class Meta:
        model = Model{}
        fields = '__all__'
"#,
                    i, i
                )
            })
            .collect::<Vec<_>>()
            .join("\n")
        + r#"

# ViewSets (10 viewsets)
"#
        + &(0..10)
            .map(|i| {
                format!(
                    r#"
class Model{}ViewSet(viewsets.ModelViewSet):
    queryset = Model{}.objects.all()
    serializer_class = Model{}Serializer
"#,
                    i, i, i
                )
            })
            .collect::<Vec<_>>()
            .join("\n");

    let result = process_python_file(&source, "repo", "django_full.py", "django_full");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_microservice_with_many_endpoints() {
    let mut source = r#"
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()
"#
    .to_string();

    // Add 1000 API endpoints
    for i in 0..1000 {
        source.push_str(&format!(
            r#"
@app.get("/endpoint{}")
async def endpoint_{}():
    return {{"id": {}}}
"#,
            i, i, i
        ));
    }

    let result = process_python_file(&source, "repo", "microservice.py", "microservice");
    assert!(result.metadata.errors.is_empty());
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Concurrent Parsing Simulation
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_rapid_sequential_parsing() {
    // Simulate rapid sequential parsing (like watch mode)
    for i in 0..1000 {
        let source = fixture_simple_function(&format!("func{}", i));
        let result = process_python_file(&source, "repo", "rapid.py", "rapid");
        assert!(result.metadata.errors.is_empty());
    }
}

#[test]
#[ignore]
fn stress_varying_file_sizes() {
    // Parse files of varying sizes sequentially
    let sizes = vec![1, 10, 100, 1000, 10, 1, 500, 50, 5];

    for (idx, size) in sizes.iter().enumerate() {
        let source = fixture_n_functions(*size);
        let result = process_python_file(&source, "repo", &format!("file{}.py", idx), "test");
        assert!(result.metadata.errors.is_empty());
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Memory Leak Detection
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_repeated_parsing_same_file() {
    let source = fixture_simple_class("TestClass", 50);

    // Parse the same file 10,000 times
    // If there's a memory leak, this will catch it
    for _ in 0..10000 {
        let result = process_python_file(&source, "repo", "repeated.py", "repeated");
        assert!(result.metadata.errors.is_empty());

        // Drop result explicitly to ensure cleanup
        drop(result);
    }
}

#[test]
#[ignore]
fn stress_parse_and_discard() {
    // Parse many files and immediately discard results
    for i in 0..1000 {
        let source = fixture_n_functions(100);
        let _result = process_python_file(&source, "repo", &format!("discard{}.py", i), "test");
        // Result drops here
    }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Error Recovery Stress
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
fn stress_alternating_valid_invalid() {
    // Mix valid and invalid syntax
    let source = r#"
def valid1(): pass
def invalid(:
def valid2(): pass
class Invalid
class Valid: pass
"#;
    let result = process_python_file(source, "repo", "mixed.py", "mixed");

    // Should parse what it can, report errors for the rest
    let (nodes, ..) = &result.outputs;
    assert!(nodes.len() >= 2, "Should parse valid portions");
}

#[test]
#[ignore]
fn stress_many_syntax_errors() {
    let mut source = String::new();
    for i in 0..1000 {
        if i % 2 == 0 {
            source.push_str(&format!("def func{}(): pass\n", i));
        } else {
            source.push_str(&format!("def invalid{}(: pass\n", i));
        }
    }

    let result = process_python_file(&source, "repo", "many_errors.py", "many_errors");

    // Should handle errors gracefully
    let (nodes, ..) = &result.outputs;
    assert!(nodes.len() >= 500, "Should parse valid functions");
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// EXTREME: Performance Benchmarking Scenarios
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

#[test]
#[ignore]
fn stress_realistic_django_project() {
    // Simulate a realistic Django project structure
    let models = fixture_django_model("User", 20)
        + "\n"
        + &fixture_django_model("Post", 15)
        + "\n"
        + &fixture_django_model("Comment", 10);

    let result = process_python_file(&models, "repo", "models.py", "models");
    assert!(result.metadata.errors.is_empty());
}

#[test]
#[ignore]
fn stress_data_science_notebook_conversion() {
    // Simulate converting a Jupyter notebook with many cells
    let mut source = String::new();
    for i in 0..100 {
        source.push_str(&format!(
            r#"
# Cell {}
import numpy as np
import pandas as pd

def analyze_cell_{}(data):
    df = pd.DataFrame(data)
    return df.describe()

result_{} = analyze_cell_{}(some_data)
"#,
            i, i, i, i
        ));
    }

    let result = process_python_file(&source, "repo", "notebook.py", "notebook");
    assert!(result.metadata.errors.is_empty());
}
