//! SOTA-Level SQLite ChunkStore Stress Tests
//!
//! Comprehensive edge case, corner case, and complex scenario testing:
//! 1. Concurrent access (multi-threaded writes/reads)
//! 2. Large-scale data (10K+ chunks)
//! 3. Deep transitive dependencies (100+ levels)
//! 4. Unicode/special characters in content
//! 5. NULL handling and empty values
//! 6. Transaction integrity
//! 7. File metadata consistency
//! 8. Soft delete edge cases
//! 9. Cross-repository isolation
//! 10. Performance benchmarks

use codegraph_ir::features::storage::{
    Chunk, ChunkStore, Dependency, DependencyType, Repository, Snapshot, SqliteChunkStore,
};
use chrono::Utc;
use std::collections::HashMap;
use std::sync::Arc;
use tokio::task::JoinSet;

// Test 1: Concurrent Multi-threaded Access
#[tokio::test]
async fn test_concurrent_writes_reads() {
    let store = Arc::new(SqliteChunkStore::in_memory().unwrap());
    let mut tasks = JoinSet::new();

    // Setup repository
    let repo = Repository {
        repo_id: "concurrent-test".to_string(),
        name: "Concurrent Test Repo".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-1".to_string(),
        repo_id: "concurrent-test".to_string(),
        commit_hash: Some("abc123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Spawn 50 concurrent writers
    for i in 0..50 {
        let store_clone = store.clone();
        tasks.spawn(async move {
            let chunk = Chunk {
                chunk_id: format!("chunk-{}", i),
                repo_id: "concurrent-test".to_string(),
                snapshot_id: "snap-1".to_string(),
                file_path: format!("src/file_{}.rs", i),
                start_line: 1,
                end_line: 10,
                kind: "function".to_string(),
                fqn: Some(format!("test::func_{}", i)),
                language: "rust".to_string(),
                symbol_visibility: Some("public".to_string()),
                content: format!("fn func_{}() {{ println!(\"Hello {}\"); }}", i, i),
                content_hash: format!("hash_{}", i),
                summary: Some(format!("Function {}", i)),
                importance: 0.5,
                is_deleted: false,
                attrs: HashMap::new(),
                created_at: Utc::now(),
                updated_at: Utc::now(),
            };
            store_clone.save_chunk(&chunk).await.unwrap();
        });
    }

    // Spawn 50 concurrent readers
    for _i in 0..50 {
        let store_clone = store.clone();
        tasks.spawn(async move {
            let chunks = store_clone
                .get_chunks("concurrent-test", "snap-1")
                .await
                .unwrap();
            assert!(chunks.len() <= 50);
        });
    }

    // Wait for all tasks
    while tasks.join_next().await.is_some() {}

    // Verify all chunks saved
    let final_chunks = store.get_chunks("concurrent-test", "snap-1").await.unwrap();
    assert_eq!(final_chunks.len(), 50);
    println!("âœ… Concurrent access: 50 writers + 50 readers passed");
}

// Test 2: Large-scale Data (10K chunks)
#[tokio::test]
async fn test_large_scale_10k_chunks() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "large-repo".to_string(),
        name: "Large Repo".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-large".to_string(),
        repo_id: "large-repo".to_string(),
        commit_hash: Some("large123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Create 10K chunks
    let mut chunks = Vec::new();
    for i in 0..10_000 {
        chunks.push(Chunk {
            chunk_id: format!("chunk-large-{}", i),
            repo_id: "large-repo".to_string(),
            snapshot_id: "snap-large".to_string(),
            file_path: format!("src/module_{}/file_{}.rs", i / 100, i % 100),
            start_line: i % 1000,
            end_line: (i % 1000) + 10,
            kind: if i % 3 == 0 {
                "function"
            } else if i % 3 == 1 {
                "class"
            } else {
                "variable"
            }
            .to_string(),
            fqn: Some(format!("large::module_{}::item_{}", i / 100, i)),
            language: "rust".to_string(),
            symbol_visibility: Some(if i % 2 == 0 { "public" } else { "private" }.to_string()),
            content: format!("// Content for item {}\nfn item_{}() {{}}", i, i),
            content_hash: format!("hash_large_{}", i),
            summary: Some(format!("Item {}", i)),
            importance: (i as f32 / 10_000.0),
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        });
    }

    // Batch save
    let start = std::time::Instant::now();
    store.save_chunks(&chunks).await.unwrap();
    let duration = start.elapsed();

    println!(
        "âœ… Large-scale: 10K chunks saved in {:?} ({:.2} chunks/sec)",
        duration,
        10_000.0 / duration.as_secs_f64()
    );

    // Verify count
    let count = store.count_chunks("large-repo", "snap-large").await.unwrap();
    assert_eq!(count, 10_000);

    // Test query by kind
    let functions = store
        .get_chunks_by_kind("large-repo", "snap-large", "function")
        .await
        .unwrap();
    assert_eq!(functions.len(), 3334); // 10000 / 3 rounded up
}

// Test 3: Deep Transitive Dependencies (100+ levels)
#[tokio::test]
async fn test_deep_transitive_dependencies() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "deep-dep".to_string(),
        name: "Deep Dep".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-deep".to_string(),
        repo_id: "deep-dep".to_string(),
        commit_hash: Some("deep123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Create 150 chunks in a chain
    let mut chunks = Vec::new();
    for i in 0..150 {
        chunks.push(Chunk {
            chunk_id: format!("deep-chunk-{}", i),
            repo_id: "deep-dep".to_string(),
            snapshot_id: "snap-deep".to_string(),
            file_path: format!("src/level_{}.rs", i),
            start_line: 1,
            end_line: 10,
            kind: "function".to_string(),
            fqn: Some(format!("deep::level_{}", i)),
            language: "rust".to_string(),
            symbol_visibility: Some("public".to_string()),
            content: format!("fn level_{}() {{ level_{}(); }}", i, i + 1),
            content_hash: format!("hash_deep_{}", i),
            summary: Some(format!("Level {}", i)),
            importance: 0.5,
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        });
    }
    store.save_chunks(&chunks).await.unwrap();

    // Create chain dependencies: 0 -> 1 -> 2 -> ... -> 149
    let mut deps = Vec::new();
    for i in 0..149 {
        deps.push(Dependency {
            id: format!("dep-{}", i),
            from_chunk_id: format!("deep-chunk-{}", i),
            to_chunk_id: format!("deep-chunk-{}", i + 1),
            relationship: DependencyType::Calls,
            confidence: 1.0,
            created_at: Utc::now(),
        });
    }
    store.save_dependencies(&deps).await.unwrap();

    // Test transitive dependencies at depth 50
    let transitive = store
        .get_transitive_dependencies("deep-chunk-0", 50)
        .await
        .unwrap();
    assert_eq!(transitive.len(), 50);

    // Test transitive dependencies at depth 100
    let transitive_100 = store
        .get_transitive_dependencies("deep-chunk-0", 100)
        .await
        .unwrap();
    assert_eq!(transitive_100.len(), 100);

    // Test from middle of chain
    let from_middle = store
        .get_transitive_dependencies("deep-chunk-75", 50)
        .await
        .unwrap();
    assert_eq!(from_middle.len(), 50);

    println!("âœ… Deep transitive: 150-level dependency chain tested");
}

// Test 4: Unicode and Special Characters
#[tokio::test]
async fn test_unicode_special_characters() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "unicode-repo".to_string(),
        name: "Unicode Test ðŸ¦€".to_string(),
        remote_url: Some("https://github.com/æµ‹è¯•/repo".to_string()),
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-unicode".to_string(),
        repo_id: "unicode-repo".to_string(),
        commit_hash: Some("unicode123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    let very_long_line = "a".repeat(10_000);
    let test_cases = vec![
        ("í•œê¸€", "fn í•œê¸€í•¨ìˆ˜() {}"),
        ("æ—¥æœ¬èªž", "fn æ—¥æœ¬èªžé–¢æ•°() {}"),
        ("emoji", "fn test() { println!(\"ðŸ¦€ðŸ”¥ðŸ’¯\"); }"),
        ("special_chars", "fn test() { let x = \"<>&'\\\";\"; }"),
        ("sql_injection", "fn test() { let x = \"'; DROP TABLE chunks; --\"; }"),
        ("null_bytes", "fn test() { let x = \"test\\x00null\"; }"),
        ("very_long_line", very_long_line.as_str()),
    ];

    for (i, (name, content)) in test_cases.iter().enumerate() {
        let chunk = Chunk {
            chunk_id: format!("unicode-{}", i),
            repo_id: "unicode-repo".to_string(),
            snapshot_id: "snap-unicode".to_string(),
            file_path: format!("src/{}.rs", name),
            start_line: 1,
            end_line: 10,
            kind: "function".to_string(),
            fqn: Some(format!("test::{}", name)),
            language: "rust".to_string(),
            symbol_visibility: Some("public".to_string()),
            content: content.to_string(),
            content_hash: format!("hash_{}", i),
            summary: Some(format!("Test {}", name)),
            importance: 0.5,
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };
        store.save_chunk(&chunk).await.unwrap();

        // Verify retrieval
        let retrieved = store.get_chunk(&format!("unicode-{}", i)).await.unwrap();
        assert!(retrieved.is_some());
        assert_eq!(retrieved.unwrap().content, *content);
    }

    println!("âœ… Unicode/special chars: All edge cases passed");
}

// Test 5: NULL Handling and Empty Values
#[tokio::test]
async fn test_null_empty_values() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "null-test".to_string(),
        name: "Null Test".to_string(),
        remote_url: None, // NULL
        local_path: None, // NULL
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-null".to_string(),
        repo_id: "null-test".to_string(),
        commit_hash: None, // NULL
        branch_name: None, // NULL
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    let chunk = Chunk {
        chunk_id: "null-chunk".to_string(),
        repo_id: "null-test".to_string(),
        snapshot_id: "snap-null".to_string(),
        file_path: "".to_string(), // Empty string
        start_line: 0,
        end_line: 0,
        kind: "".to_string(), // Empty string
        fqn: None,            // NULL
        language: "rust".to_string(),
        symbol_visibility: None, // NULL
        content: "".to_string(),     // Empty content
        content_hash: "".to_string(),
        summary: None, // NULL
        importance: 0.0,
        is_deleted: false,
        attrs: HashMap::new(), // Empty map
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_chunk(&chunk).await.unwrap();

    // Verify retrieval
    let retrieved = store.get_chunk("null-chunk").await.unwrap();
    assert!(retrieved.is_some());
    let r = retrieved.unwrap();
    assert_eq!(r.file_path, "");
    assert_eq!(r.content, "");
    assert_eq!(r.fqn, None);
    assert_eq!(r.summary, None);

    println!("âœ… NULL/empty values: All cases handled correctly");
}

// Test 6: File Metadata Consistency
#[tokio::test]
async fn test_file_metadata_consistency() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "meta-test".to_string(),
        name: "Meta Test".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-meta".to_string(),
        repo_id: "meta-test".to_string(),
        commit_hash: Some("meta123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Test 1: Initial metadata
    store
        .update_file_metadata("meta-test", "snap-meta", "src/test.rs", "hash1".to_string())
        .await
        .unwrap();

    let hash = store
        .get_file_hash("meta-test", "snap-meta", "src/test.rs")
        .await
        .unwrap();
    assert_eq!(hash, Some("hash1".to_string()));

    // Test 2: Update metadata (should REPLACE)
    store
        .update_file_metadata("meta-test", "snap-meta", "src/test.rs", "hash2".to_string())
        .await
        .unwrap();

    let hash2 = store
        .get_file_hash("meta-test", "snap-meta", "src/test.rs")
        .await
        .unwrap();
    assert_eq!(hash2, Some("hash2".to_string()));

    // Test 3: Multiple files
    for i in 0..100 {
        store
            .update_file_metadata(
                "meta-test",
                "snap-meta",
                &format!("src/file_{}.rs", i),
                format!("hash_{}", i),
            )
            .await
            .unwrap();
    }

    // Verify all hashes
    for i in 0..100 {
        let hash = store
            .get_file_hash("meta-test", "snap-meta", &format!("src/file_{}.rs", i))
            .await
            .unwrap();
        assert_eq!(hash, Some(format!("hash_{}", i)));
    }

    // Test 4: Non-existent file
    let missing = store
        .get_file_hash("meta-test", "snap-meta", "nonexistent.rs")
        .await
        .unwrap();
    assert_eq!(missing, None);

    println!("âœ… File metadata: Consistency tests passed");
}

// Test 7: Soft Delete Edge Cases
#[tokio::test]
async fn test_soft_delete_edge_cases() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "delete-test".to_string(),
        name: "Delete Test".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-delete".to_string(),
        repo_id: "delete-test".to_string(),
        commit_hash: Some("delete123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Create chunks in same file
    for i in 0..10 {
        let chunk = Chunk {
            chunk_id: format!("del-chunk-{}", i),
            repo_id: "delete-test".to_string(),
            snapshot_id: "snap-delete".to_string(),
            file_path: "src/test.rs".to_string(),
            start_line: i * 10,
            end_line: (i * 10) + 10,
            kind: "function".to_string(),
            fqn: Some(format!("test::func_{}", i)),
            language: "rust".to_string(),
            symbol_visibility: Some("public".to_string()),
            content: format!("fn func_{}() {{}}", i),
            content_hash: format!("hash_{}", i),
            summary: Some(format!("Func {}", i)),
            importance: 0.5,
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };
        store.save_chunk(&chunk).await.unwrap();
    }

    // Verify all visible
    let before = store.get_chunks("delete-test", "snap-delete").await.unwrap();
    assert_eq!(before.len(), 10);

    // Soft delete file
    store
        .soft_delete_file_chunks("delete-test", "snap-delete", "src/test.rs")
        .await
        .unwrap();

    // Verify all deleted
    let after = store.get_chunks("delete-test", "snap-delete").await.unwrap();
    assert_eq!(after.len(), 0);

    // But chunks still exist (not hard deleted)
    let deleted_chunk = store.get_chunk("del-chunk-0").await.unwrap();
    assert!(deleted_chunk.is_some());
    assert!(deleted_chunk.unwrap().is_deleted);

    // Test: Re-add same file (should work)
    let new_chunk = Chunk {
        chunk_id: "del-chunk-new".to_string(),
        repo_id: "delete-test".to_string(),
        snapshot_id: "snap-delete".to_string(),
        file_path: "src/test.rs".to_string(),
        start_line: 1,
        end_line: 10,
        kind: "function".to_string(),
        fqn: Some("test::new_func".to_string()),
        language: "rust".to_string(),
        symbol_visibility: Some("public".to_string()),
        content: "fn new_func() {}".to_string(),
        content_hash: "hash_new".to_string(),
        summary: Some("New func".to_string()),
        importance: 0.5,
        is_deleted: false,
        attrs: HashMap::new(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_chunk(&new_chunk).await.unwrap();

    // Should see only new chunk
    let final_chunks = store.get_chunks("delete-test", "snap-delete").await.unwrap();
    assert_eq!(final_chunks.len(), 1);
    assert_eq!(final_chunks[0].chunk_id, "del-chunk-new");

    println!("âœ… Soft delete: All edge cases passed");
}

// Test 8: Cross-Repository Isolation
#[tokio::test]
async fn test_cross_repository_isolation() {
    let store = SqliteChunkStore::in_memory().unwrap();

    // Create 10 repositories with identical snapshot IDs
    for repo_idx in 0..10 {
        let repo = Repository {
            repo_id: format!("repo-{}", repo_idx),
            name: format!("Repo {}", repo_idx),
            remote_url: None,
            local_path: None,
            default_branch: "main".to_string(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };
        store.save_repository(&repo).await.unwrap();

        let snapshot = Snapshot {
            snapshot_id: format!("snap-{}", repo_idx),
            repo_id: format!("repo-{}", repo_idx),
            commit_hash: Some(format!("commit-{}", repo_idx)),
            branch_name: Some("main".to_string()),
            created_at: Utc::now(),
        };
        store.save_snapshot(&snapshot).await.unwrap();

        // Create chunks with same IDs across repos
        for chunk_idx in 0..10 {
            let chunk = Chunk {
                chunk_id: format!("repo-{}-chunk-{}", repo_idx, chunk_idx),
                repo_id: format!("repo-{}", repo_idx),
                snapshot_id: format!("snap-{}", repo_idx),
                file_path: format!("src/file_{}.rs", chunk_idx),
                start_line: 1,
                end_line: 10,
                kind: "function".to_string(),
                fqn: Some(format!("repo_{}::func_{}", repo_idx, chunk_idx)),
                language: "rust".to_string(),
                symbol_visibility: Some("public".to_string()),
                content: format!("fn func_{}() {{}}", chunk_idx),
                content_hash: format!("hash_{}_{}", repo_idx, chunk_idx),
                summary: Some(format!("Func {}", chunk_idx)),
                importance: 0.5,
                is_deleted: false,
                attrs: HashMap::new(),
                created_at: Utc::now(),
                updated_at: Utc::now(),
            };
            store.save_chunk(&chunk).await.unwrap();
        }
    }

    // Verify isolation
    for repo_idx in 0..10 {
        let chunks = store
            .get_chunks(&format!("repo-{}", repo_idx), &format!("snap-{}", repo_idx))
            .await
            .unwrap();
        assert_eq!(chunks.len(), 10);

        // Verify all chunks belong to correct repo
        for chunk in chunks {
            assert_eq!(chunk.repo_id, format!("repo-{}", repo_idx));
            assert!(chunk.chunk_id.starts_with(&format!("repo-{}-", repo_idx)));
        }
    }

    // Verify total
    let stats = store.get_stats().await.unwrap();
    assert_eq!(stats.total_repos, 10);
    assert_eq!(stats.total_snapshots, 10);
    assert_eq!(stats.total_chunks, 100); // 10 repos Ã— 10 chunks

    println!("âœ… Cross-repo isolation: All repositories properly isolated");
}

// Test 9: Complex Dependency Graph
#[tokio::test]
async fn test_complex_dependency_graph() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "graph-test".to_string(),
        name: "Graph Test".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-graph".to_string(),
        repo_id: "graph-test".to_string(),
        commit_hash: Some("graph123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Create 20 chunks
    for i in 0..20 {
        let chunk = Chunk {
            chunk_id: format!("graph-chunk-{}", i),
            repo_id: "graph-test".to_string(),
            snapshot_id: "snap-graph".to_string(),
            file_path: format!("src/module_{}.rs", i),
            start_line: 1,
            end_line: 10,
            kind: "function".to_string(),
            fqn: Some(format!("graph::func_{}", i)),
            language: "rust".to_string(),
            symbol_visibility: Some("public".to_string()),
            content: format!("fn func_{}() {{}}", i),
            content_hash: format!("hash_{}", i),
            summary: Some(format!("Func {}", i)),
            importance: 0.5,
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };
        store.save_chunk(&chunk).await.unwrap();
    }

    // Create complex graph:
    // - Diamond: 0 -> 1,2 -> 3
    // - Cycle: 5 -> 6 -> 7 -> 5
    // - Fan-out: 10 -> 11,12,13,14,15
    // - Fan-in: 16,17,18,19 -> 0
    let deps = vec![
        // Diamond
        ("0", "1", DependencyType::Calls),
        ("0", "2", DependencyType::Calls),
        ("1", "3", DependencyType::Calls),
        ("2", "3", DependencyType::Calls),
        // Cycle
        ("5", "6", DependencyType::Calls),
        ("6", "7", DependencyType::Calls),
        ("7", "5", DependencyType::Calls),
        // Fan-out
        ("10", "11", DependencyType::Calls),
        ("10", "12", DependencyType::Calls),
        ("10", "13", DependencyType::Calls),
        ("10", "14", DependencyType::Calls),
        ("10", "15", DependencyType::Calls),
        // Fan-in
        ("16", "0", DependencyType::Calls),
        ("17", "0", DependencyType::Calls),
        ("18", "0", DependencyType::Calls),
        ("19", "0", DependencyType::Calls),
        // Mixed types
        ("0", "4", DependencyType::Imports),
        ("4", "8", DependencyType::Extends),
        ("8", "9", DependencyType::Implements),
    ];

    for (i, (from, to, rel)) in deps.iter().enumerate() {
        let dep = Dependency {
            id: format!("dep-{}", i),
            from_chunk_id: format!("graph-chunk-{}", from),
            to_chunk_id: format!("graph-chunk-{}", to),
            relationship: rel.clone(),
            confidence: 1.0,
            created_at: Utc::now(),
        };
        store.save_dependency(&dep).await.unwrap();
    }

    // Test: Diamond pattern
    let from_0 = store.get_dependencies_from("graph-chunk-0").await.unwrap();
    assert_eq!(from_0.len(), 3); // Calls to 1,2 + Imports to 4

    let to_3 = store.get_dependencies_to("graph-chunk-3").await.unwrap();
    assert_eq!(to_3.len(), 2); // From 1,2

    // Test: Cycle detection
    let from_5 = store.get_dependencies_from("graph-chunk-5").await.unwrap();
    assert_eq!(from_5.len(), 1);

    // Test: Fan-out
    let from_10 = store.get_dependencies_from("graph-chunk-10").await.unwrap();
    assert_eq!(from_10.len(), 5);

    // Test: Fan-in
    let to_0 = store.get_dependencies_to("graph-chunk-0").await.unwrap();
    assert_eq!(to_0.len(), 4);

    println!("âœ… Complex dependency graph: All patterns verified");
}

// Test 10: Performance Benchmark
#[tokio::test]
async fn test_performance_benchmark() {
    let store = SqliteChunkStore::in_memory().unwrap();

    let repo = Repository {
        repo_id: "perf-test".to_string(),
        name: "Perf Test".to_string(),
        remote_url: None,
        local_path: None,
        default_branch: "main".to_string(),
        created_at: Utc::now(),
        updated_at: Utc::now(),
    };
    store.save_repository(&repo).await.unwrap();

    let snapshot = Snapshot {
        snapshot_id: "snap-perf".to_string(),
        repo_id: "perf-test".to_string(),
        commit_hash: Some("perf123".to_string()),
        branch_name: Some("main".to_string()),
        created_at: Utc::now(),
    };
    store.save_snapshot(&snapshot).await.unwrap();

    // Benchmark 1: Single inserts (1K chunks)
    let start = std::time::Instant::now();
    for i in 0..1_000 {
        let chunk = Chunk {
            chunk_id: format!("perf-single-{}", i),
            repo_id: "perf-test".to_string(),
            snapshot_id: "snap-perf".to_string(),
            file_path: format!("src/file_{}.rs", i),
            start_line: 1,
            end_line: 10,
            kind: "function".to_string(),
            fqn: Some(format!("perf::func_{}", i)),
            language: "rust".to_string(),
            symbol_visibility: Some("public".to_string()),
            content: format!("fn func_{}() {{}}", i),
            content_hash: format!("hash_{}", i),
            summary: Some(format!("Func {}", i)),
            importance: 0.5,
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        };
        store.save_chunk(&chunk).await.unwrap();
    }
    let single_duration = start.elapsed();
    println!(
        "ðŸ“Š Single inserts: 1K chunks in {:?} ({:.2} chunks/sec)",
        single_duration,
        1_000.0 / single_duration.as_secs_f64()
    );

    // Benchmark 2: Batch inserts (5K chunks)
    let mut batch_chunks = Vec::new();
    for i in 0..5_000 {
        batch_chunks.push(Chunk {
            chunk_id: format!("perf-batch-{}", i),
            repo_id: "perf-test".to_string(),
            snapshot_id: "snap-perf".to_string(),
            file_path: format!("src/batch_{}.rs", i),
            start_line: 1,
            end_line: 10,
            kind: "function".to_string(),
            fqn: Some(format!("perf::batch_{}", i)),
            language: "rust".to_string(),
            symbol_visibility: Some("public".to_string()),
            content: format!("fn batch_{}() {{}}", i),
            content_hash: format!("hash_batch_{}", i),
            summary: Some(format!("Batch {}", i)),
            importance: 0.5,
            is_deleted: false,
            attrs: HashMap::new(),
            created_at: Utc::now(),
            updated_at: Utc::now(),
        });
    }

    let start = std::time::Instant::now();
    store.save_chunks(&batch_chunks).await.unwrap();
    let batch_duration = start.elapsed();
    println!(
        "ðŸ“Š Batch inserts: 5K chunks in {:?} ({:.2} chunks/sec)",
        batch_duration,
        5_000.0 / batch_duration.as_secs_f64()
    );

    // Benchmark 3: Query performance (1K queries)
    let start = std::time::Instant::now();
    for i in 0..1_000 {
        let _ = store
            .get_chunk(&format!("perf-single-{}", i))
            .await
            .unwrap();
    }
    let query_duration = start.elapsed();
    println!(
        "ðŸ“Š Point queries: 1K queries in {:?} ({:.2} queries/sec)",
        query_duration,
        1_000.0 / query_duration.as_secs_f64()
    );

    // Benchmark 4: Bulk query
    let start = std::time::Instant::now();
    let all_chunks = store.get_chunks("perf-test", "snap-perf").await.unwrap();
    let bulk_duration = start.elapsed();
    println!(
        "ðŸ“Š Bulk query: {} chunks in {:?}",
        all_chunks.len(),
        bulk_duration
    );

    // Verify count
    assert_eq!(all_chunks.len(), 6_000);

    println!("\nâœ… Performance benchmark completed");
}
