"""
Unified IR Build Configuration (SOTA)

Single configuration object that replaces:
- SemanticIrBuildMode (QUICK/PR/FULL)
- IRBuildStrategy (Default/Incremental/Parallel/etc.)
- IRBuildContext layer toggles

Design Principles:
1. Single source of truth for all build options
2. Preset factory methods for common use cases
3. Fine-grained control when needed
4. No Strategy/Mode confusion

RFC-036: 3-Tier Semantic IR Model
- BASE: CFG + Calls (90% use)
- EXTENDED: + DFG + Expression (9% use)
- FULL: + SSA + PDG (1% use)

Usage:
    # Simple: Use presets (RFC-036)
    config = BuildConfig.for_editor()       # BASE tier
    config = BuildConfig.for_refactoring()  # EXTENDED tier
    config = BuildConfig.for_analysis()     # FULL tier

    # Legacy: Still works
    config = BuildConfig.for_pr_review()
    result = await builder.build(files, config)
"""

from __future__ import annotations

import os
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import TYPE_CHECKING, Any

# PyrightModeëŠ” AnalysisModeì˜ alias (RFC-021: ì¤‘ë³µ ENUM ì œê±°)
# shared_kernelì—ì„œ ë‹¨ì¼ ì •ì˜, ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„± ìœ ì§€
from codegraph_shared.kernel.contracts.modes import AnalysisMode

PyrightMode = AnalysisMode


class SemanticTier(str, Enum):
    """
    RFC-036: Semantic IR tiers.

    3-tier model based on usage patterns (90/9/1).
    """

    BASE = "base"  # CFG + Calls (90% AI tasks)
    EXTENDED = "extended"  # + DFG + Expression (9% AI tasks)
    FULL = "full"  # + SSA + PDG (1% AI tasks)


if TYPE_CHECKING:
    from codegraph_engine.code_foundation.infrastructure.ir.models.document import IRDocument


def _default_parallel_workers() -> int:
    """
    Calculate default parallel workers based on CPU cores.

    Returns:
        cpu_count // 2 (minimum 1, maximum 8)

    Rationale:
        - Half of CPU cores leaves room for other processes
        - Capped at 8 to avoid diminishing returns from process overhead
        - ProcessPoolExecutor has overhead per process (~10-50ms spawn time)
    """
    cpu_count = os.cpu_count() or 4
    return max(1, min(cpu_count // 2, 8))


def _max_parallel_workers() -> int:
    """
    Calculate maximum parallel workers for heavy workloads (CI, indexing).

    Returns:
        cpu_count (minimum 4, maximum 16)

    Used by: for_ci(), for_initial_index(), LayeredIRBuilder ProcessPool
    """
    cpu_count = os.cpu_count() or 8
    return max(4, min(cpu_count, 16))


def get_cpu_limit() -> int:
    """
    Get CPU core count with fallback.

    Returns:
        os.cpu_count() or 8 (default for systems without info)

    Used by: LayeredIRBuilder._build_structural_ir_parallel()
    """
    return os.cpu_count() or 8


@dataclass
class BuildConfig:
    """
    Unified IR build configuration.

    Replaces the separate Mode + Strategy pattern with a single config object.

    Categories:
    1. Analysis Depth (what to generate)
    2. Build Strategy (how to build)
    3. Performance Tuning
    4. Caching & Incremental
    """

    # ================================================================
    # 1. Analysis Depth (What to generate)
    # ================================================================

    # Layer 1: Structural IR (always on)
    # - AST nodes, edges, basic structure

    # Layer 2: Occurrences (SCIP-compatible)
    occurrences: bool = True

    # Layer 3: LSP Type Enrichment
    lsp_enrichment: bool = True

    # Layer 4: Cross-file Resolution
    cross_file: bool = True

    # Layer 5: Semantic IR (RFC-036: 3-Tier Model)
    semantic_tier: SemanticTier = SemanticTier.EXTENDED  # ğŸ†• Source of Truth (default: EXTENDED for compat)

    # Derived flags (set by __post_init__ based on semantic_tier)
    # SOTA: semantic_tier is Source of Truth, these are derived
    cfg: bool = field(default=True, init=False)  # Derived from tier
    dfg: bool = field(default=True, init=False)  # Derived from tier
    dfg_function_loc_threshold: int = 500  # ğŸ†• RFC-036: Skip huge functions
    ssa: bool = field(default=False, init=False)  # Derived from tier
    bfg: bool = True  # Basic Block Flow Graph
    expressions: bool = field(default=True, init=False)  # Derived from tier
    generic_inference: bool = field(default=True, init=False)  # Derived from tier

    # Layer 6: Analysis Indexes (build indexes only, not run analysis)
    heap_analysis: bool = False  # PDG/Taint/Slicing indexes (analysis runs separately)
    taint_analysis: bool = False  # Run taint analysis during build (deprecated, use separate analysis)

    # Layer 7: Retrieval Indexes
    retrieval_index: bool = True

    # Layer 8: Diagnostics
    diagnostics: bool = True

    # Layer 9: Package Analysis
    packages: bool = True

    # ================================================================
    # 2. Build Strategy (How to build)
    # ================================================================

    # Parallelization (default: cpu_count // 2, see _default_parallel_workers)
    parallel_workers: int = field(default_factory=_default_parallel_workers)

    # Incremental build
    incremental: bool = False  # Only rebuild changed files
    changed_files: set[str] = field(default_factory=set)  # For incremental

    # v2: Language Plugin Architecture (Feature Flag)
    use_plugin_registry: bool = False  # Enable language plugin registry (default: False for gradual migration)

    # ================================================================
    # 3. Performance Tuning
    # ================================================================

    max_concurrent_files: int = 50  # Concurrency limit
    timeout_seconds: float = 300.0  # Build timeout
    batch_size: int = 100  # Files per batch
    cache_generators: bool = True  # Cache IR generators across builds (memory vs speed tradeoff)

    # ================================================================
    # 3.1 ProcessPool Configuration (SOTA: ì¤‘ì•™í™”ëœ ë³‘ë ¬ ì²˜ë¦¬ ì„¤ì •)
    # ================================================================

    # ProcessPoolì„ ì‚¬ìš©í•  ìµœì†Œ íŒŒì¼ ìˆ˜ (ì˜¤ë²„í—¤ë“œ vs ì´ë“ ê· í˜•ì )
    # ê³„ì‚°: íŒŒì¼ë‹¹ ~10ms íŒŒì‹± ê¸°ì¤€, 200 íŒŒì¼ = 2000ms ìˆœì°¨ vs ~300ms ë³‘ë ¬(8ì½”ì–´)
    #       500ms prewarm + 300ms ë³‘ë ¬ = 800ms < 2000ms ìˆœì°¨ â†’ ì´ë“
    process_pool_threshold: int = 200

    # Semantic IR ProcessPool ì„ê³„ê°’ (í˜„ì¬ëŠ” Layer 1ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€)
    # ì›ë˜ ê³„íš: ìˆœì°¨+ASTì¬ì‚¬ìš©ìœ¼ë¡œ í”¼í´ë§ ë¹„ìš© íšŒí”¼
    # ì‹¤ì œ: ìˆœì°¨ ê²½ë¡œê°€ 70ë°° ëŠë¦¼(Pyright ì§ë ¬ í˜¸ì¶œ ë“±)
    # TODO: ì›Œì»¤ì— AST ì „ë‹¬ ë˜ëŠ” ë°°ì¹˜ ì²˜ë¦¬ë¡œ ê°œì„  í›„ ì„ê³„ê°’ ìƒí–¥
    semantic_pool_threshold: int = 200

    # ProcessPool ì›Œì»¤ ì‚¬ì „ ì˜ˆì—´ ì—¬ë¶€
    # True: Bootstrap ë‹¨ê³„ì—ì„œ ë¯¸ë¦¬ fork (Layer 1,5ì—ì„œ ì¬ì‚¬ìš©)
    # False: ì²« ì‚¬ìš© ì‹œ fork (ì§€ì—° ì´ˆê¸°í™”)
    process_pool_prewarm: bool = True

    # ProcessPool ì‚¬ìš© ì—¬ë¶€ (Falseë©´ í•­ìƒ ìˆœì°¨ ì²˜ë¦¬)
    use_process_pool: bool = True

    # ------------------------------------------------
    # Semantic IR ì „ìš© ProcessPool ì„¤ì • (SOTA: ë™ì  ì„ê³„ê°’)
    # ------------------------------------------------
    # SOTA: Work-based threshold (íŒŒì¼ ìˆ˜ê°€ ì•„ë‹Œ ì˜ˆìƒ ì‘ì—…ëŸ‰ ê¸°ë°˜)
    #
    # ê¸°ì¡´ ë¬¸ì œ:
    # - ê³ ì • ì„ê³„ê°’(500)ì€ íŒŒì¼ë‹¹ ë³µì¡ë„ë¥¼ ë¬´ì‹œí•¨
    # - httpx(180 files, 6.9k functions) vs simple(500 files, 1k functions)
    #   â†’ httpxê°€ í›¨ì”¬ ë¬´ê±°ìš´ë° sequentialë¡œ ì²˜ë¦¬ë¨
    #
    # SOTA ì ‘ê·¼:
    # - ì˜ˆìƒ ì‘ì—…ëŸ‰ = files * avg_complexity_factor
    # - Complexity indicators: LOC/file, functions/file, expressions/file
    # - ì†ìµë¶„ê¸°ì : ì˜ˆìƒ ì‘ì—…ëŸ‰ì´ ì¶©ë¶„íˆ í¬ë©´ ë³‘ë ¬ (pickle ë¹„ìš© < ë³‘ë ¬ ì´ë“)
    #
    # Calibration (empirical):
    # - Prewarm overhead: ~500ms
    # - Pickle overhead per file: ~2ms (Semantic IR ê°ì²´ í¬ê¸° ì˜ì¡´)
    # - Sequential processing: ~70ms/file (CFG+DFG+Expression)
    # - Parallel speedup: ~8x (16 cores, 50% efficiency)
    # - Break-even: 500ms / (70ms - 70ms/8) â‰ˆ 8 files (ì´ë¡ )
    #   ì‹¤ì œë¡œëŠ” pickle ë¹„ìš© + IPCë¡œ ~50 files
    semantic_process_pool_threshold: int = 50  # ë³´ìˆ˜ì  ìµœì†Œê°’
    use_process_pool_semantic: bool = True

    # SOTA: ë™ì  ì„ê³„ê°’ íŒŒë¼ë¯¸í„°
    # ì˜ˆìƒ ì‘ì—…ëŸ‰ = file_count * work_factor
    # work_factorëŠ” ëŸ°íƒ€ì„ì— LOC, í•¨ìˆ˜ ìˆ˜ ë“±ìœ¼ë¡œ ì¶”ì •
    semantic_work_threshold: int = 5000  # ì˜ˆìƒ ì‘ì—…ëŸ‰ (í•¨ìˆ˜ ìˆ˜ ê¸°ì¤€)

    # ================================================================
    # 3.2 ThreadPool Configuration (SOTA: CPU-bound ìˆœì°¨ ì‘ì—… ë³‘ë ¬í™”)
    # ================================================================

    # ThreadPoolì„ ì‚¬ìš©í•  ìµœì†Œ í•¨ìˆ˜ ìˆ˜ (SSA/Dominator ë¹Œë“œìš©)
    # ê³„ì‚°: í•¨ìˆ˜ë‹¹ ~0.03ms SSA ë¹Œë“œ, 1000í•¨ìˆ˜ = 30ms ìˆœì°¨ vs ~5ms ë³‘ë ¬(8ìŠ¤ë ˆë“œ)
    #       ThreadPool ìƒì„± ì˜¤ë²„í—¤ë“œ: ~2ms (ProcessPoolë³´ë‹¤ í›¨ì”¬ ê°€ë²¼ì›€)
    #       ì†ìµë¶„ê¸°ì : 100 í•¨ìˆ˜ ì´ìƒ
    ssa_thread_pool_threshold: int = 100

    # SSA/Dominator ë³‘ë ¬ ë¹Œë“œ ì—¬ë¶€
    # NOTE: ThreadPoolì€ GIL ë•Œë¬¸ì— CPU-bound SSA ë¹Œë“œì— ë¹„íš¨ìœ¨ì 
    # í…ŒìŠ¤íŠ¸ ê²°ê³¼: ThreadPool 10.5s vs ìˆœì°¨ 1.7s (ìˆœì°¨ê°€ 6x ë¹ ë¦„)
    # ìˆœì°¨ ì²˜ë¦¬ê°€ ë” ë¹ ë¥´ë¯€ë¡œ ê¸°ë³¸ ë¹„í™œì„±í™”
    use_ssa_parallel: bool = False

    # ================================================================
    # 4. Incremental Build State
    # ================================================================

    # Existing IR for incremental builds (passed to strategies)
    existing_irs: dict[str, IRDocument] = field(default_factory=dict)

    # ================================================================
    # 5. Pyright Configuration
    # ================================================================

    # Pyright analysis mode (uses PyrightMode enum)
    pyright_mode: PyrightMode = PyrightMode.BALANCED

    # ================================================================
    # 6. Context (runtime state, not config)
    # ================================================================

    project_root: Path | None = None
    repo_id: str = "default"
    extra: dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        """
        RFC-036: Derive flags from semantic_tier.

        SOTA: semantic_tier is Source of Truth.
        Prevents tier/flag mismatch bugs.
        """
        # Derive flags from tier
        if self.semantic_tier == SemanticTier.BASE:
            # BASE: CFG + Calls only
            object.__setattr__(self, "cfg", True)
            object.__setattr__(self, "dfg", False)
            object.__setattr__(self, "ssa", False)
            object.__setattr__(self, "expressions", False)
            object.__setattr__(self, "generic_inference", False)

        elif self.semantic_tier == SemanticTier.EXTENDED:
            # EXTENDED: + DFG + Expression
            object.__setattr__(self, "cfg", True)
            object.__setattr__(self, "dfg", True)
            object.__setattr__(self, "ssa", False)
            object.__setattr__(self, "expressions", True)
            object.__setattr__(self, "generic_inference", True)

        elif self.semantic_tier == SemanticTier.FULL:
            # FULL: All
            object.__setattr__(self, "cfg", True)
            object.__setattr__(self, "dfg", True)
            object.__setattr__(self, "ssa", True)
            object.__setattr__(self, "expressions", True)
            object.__setattr__(self, "generic_inference", True)

        # Validation
        if self.dfg_function_loc_threshold <= 0:
            raise ValueError("dfg_function_loc_threshold must be > 0")

    # ================================================================
    # Preset Factory Methods (RFC-036 Updated)
    # ================================================================

    @classmethod
    def for_editor(cls) -> BuildConfig:
        """
        Editor/LSP mode - fastest response for real-time feedback.

        Use for: Autocomplete, hover, syntax highlighting
        Speed: ~10ms/file
        """
        return cls(
            # RFC-036: BASE tier (cfg/dfg/ssa derived in __post_init__)
            semantic_tier=SemanticTier.BASE,
            occurrences=True,
            lsp_enrichment=False,  # BASE tier doesn't need LSP
            cross_file=False,
            # cfg/dfg/ssa/expressions/generic_inference: derived from tier
            heap_analysis=False,
            taint_analysis=False,
            retrieval_index=False,
            diagnostics=False,
            packages=False,
            parallel_workers=4,
            incremental=False,
            pyright_mode=PyrightMode.FAST,
        )

    @classmethod
    def for_pr_review(
        cls,
        changed_files: set[str] | None = None,
    ) -> BuildConfig:
        """
        PR review mode - security analysis on changed files.

        Use for: PR checks, code review, incremental security scan
        Speed: ~50ms/file
        """
        return cls(
            # RFC-036: Use EXTENDED tier (DFG but no SSA for speed)
            semantic_tier=SemanticTier.EXTENDED,
            # Taint-capable analysis (CFG + DFG + Expression)
            occurrences=True,
            lsp_enrichment=True,  # Pyright íƒ€ì… ì •ë³´ (ì˜¤ë²„í—¤ë“œ ~20%)
            cross_file=True,
            bfg=False,  # Not needed for taint
            heap_analysis=False,
            taint_analysis=True,  # Run taint on changed files
            retrieval_index=True,
            diagnostics=True,
            packages=False,  # Skip for speed
            # Incremental (half CPU for PR review)
            parallel_workers=_default_parallel_workers(),
            incremental=True,
            changed_files=changed_files or set(),
            # Pyright: balanced for PR (good accuracy without full depth)
            pyright_mode=PyrightMode.BALANCED,
        )

    @classmethod
    def for_ci(cls) -> BuildConfig:
        """
        CI/CD mode - full analysis for pipeline.

        Use for: CI security checks, build verification
        Speed: ~90ms/file
        """
        return cls(
            # RFC-036: Use FULL tier
            semantic_tier=SemanticTier.FULL,
            # Full analysis
            occurrences=True,
            lsp_enrichment=True,  # Pyright íƒ€ì… ì •ë³´ (ì˜¤ë²„í—¤ë“œ ~20%)
            cross_file=True,
            bfg=True,
            heap_analysis=True,
            taint_analysis=True,
            retrieval_index=True,
            diagnostics=True,
            packages=True,
            # Parallel for speed (max CPU for CI)
            parallel_workers=_max_parallel_workers(),
            incremental=False,  # Full build in CI
            # Pyright: deep for CI (maximum accuracy)
            pyright_mode=PyrightMode.DEEP,
        )

    @classmethod
    def for_initial_index(cls) -> BuildConfig:
        """
        Initial indexing mode - complete analysis for first-time setup.

        Use for: First-time repo indexing, full reindex
        Speed: ~90ms/file (but comprehensive)
        """
        return cls(
            # RFC-036: Use FULL tier
            semantic_tier=SemanticTier.FULL,
            # Everything
            occurrences=True,
            lsp_enrichment=True,  # Pyright íƒ€ì… ì •ë³´ (ì˜¤ë²„í—¤ë“œ ~20%)
            cross_file=True,
            bfg=True,
            heap_analysis=True,
            taint_analysis=False,  # Run separately after indexing
            retrieval_index=True,
            diagnostics=True,
            packages=True,
            # Max parallelism (full CPU for initial index)
            parallel_workers=_max_parallel_workers(),
            incremental=False,
            # Pyright: bootstrap for initial indexing (fast startup)
            pyright_mode=PyrightMode.BOOTSTRAP,
        )

    @classmethod
    def for_security_audit(cls) -> BuildConfig:
        """
        Deep security audit mode - maximum analysis depth.

        Use for: Security review, vulnerability assessment
        Speed: Slowest but most thorough
        """
        return cls(
            # RFC-036: Use FULL tier
            semantic_tier=SemanticTier.FULL,
            # Maximum analysis
            occurrences=True,
            lsp_enrichment=True,  # Pyright íƒ€ì… ì •ë³´ (ì˜¤ë²„í—¤ë“œ ~20%)
            cross_file=True,
            bfg=True,
            heap_analysis=True,
            taint_analysis=True,
            retrieval_index=True,
            diagnostics=True,
            packages=True,
            # Thorough but slower (half CPU for audit)
            parallel_workers=_default_parallel_workers(),
            incremental=False,
            # Pyright: deep for security audit (maximum accuracy)
            pyright_mode=PyrightMode.DEEP,
        )

    # ================================================================
    # Convenience Methods
    # ================================================================

    def get_pyright_config(self):
        """
        Get PyrightConfig for this build configuration.

        Returns:
            PyrightConfig instance matching the pyright_mode

        Usage:
            config = BuildConfig.for_ci()
            pyright_cfg = config.get_pyright_config()
            # pyright_cfg.type_checking_mode == "basic"
            # pyright_cfg.use_library_code_for_types == True
        """
        from codegraph_engine.code_foundation.infrastructure.config import PyrightConfig

        return PyrightConfig.for_mode(self.pyright_mode)

    def supports_taint(self) -> bool:
        """Whether this config supports taint analysis."""
        return self.cfg and self.dfg and self.expressions

    def is_incremental(self) -> bool:
        """Whether this is an incremental build."""
        return self.incremental and len(self.changed_files) > 0

    def is_parallel(self) -> bool:
        """Whether this uses parallel processing."""
        return self.parallel_workers > 1

    def with_project(self, project_root: Path, repo_id: str = "default") -> BuildConfig:
        """Return a copy with project info set."""
        import copy

        new = copy.copy(self)
        new.project_root = project_root
        new.repo_id = repo_id
        return new

    def with_changed_files(self, files: set[str]) -> BuildConfig:
        """Return a copy with changed files for incremental build."""
        import copy

        new = copy.copy(self)
        new.changed_files = files
        new.incremental = True
        return new

    # ================================================================
    # Internal: Legacy Compatibility (used by LayeredIRBuilder)
    # ================================================================

    def to_semantic_mode(self) -> str:
        """
        Convert to legacy SemanticIrBuildMode string.

        Internal use only - LayeredIRBuilder uses this to call _build_layers().

        RFC-036: Map semantic_tier to SemanticIrBuildMode:
        - BASE â†’ "quick" (CFG only, no DFG/Expression)
        - EXTENDED â†’ "pr" (CFG + DFG + Expression)
        - FULL â†’ "full" (All)
        """
        if self.semantic_tier == SemanticTier.BASE:
            return "quick"
        elif self.semantic_tier == SemanticTier.EXTENDED:
            return "pr"
        else:  # FULL
            return "full"

    # ================================================================
    # ProcessPool Decision Helper (SOTA: ì¤‘ì•™í™”ëœ ë¡œì§)
    # ================================================================

    def should_use_process_pool(self, file_count: int) -> bool:
        """
        ProcessPool ì‚¬ìš© ì—¬ë¶€ ê²°ì • (ì¤‘ì•™í™”ëœ ë¡œì§).

        Args:
            file_count: ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜

        Returns:
            True if ProcessPool should be used

        Rationale:
            - ProcessPool prewarm ì˜¤ë²„í—¤ë“œ: ~500ms
            - íŒŒì¼ë‹¹ íŒŒì‹± ì‹œê°„: ~10ms
            - ì†ìµë¶„ê¸°ì : 200 íŒŒì¼ (ë³‘ë ¬í™” ì´ë“ > prewarm ë¹„ìš©)
        """
        return self.use_process_pool and self.parallel_workers > 1 and file_count >= self.process_pool_threshold

    def should_use_semantic_pool(
        self,
        file_count: int,
        estimated_functions: int | None = None,
        estimated_loc: int | None = None,
    ) -> bool:
        """
        Semantic IRì—ì„œ ProcessPool ì‚¬ìš© ì—¬ë¶€ (SOTA: ë™ì  ì„ê³„ê°’).

        Args:
            file_count: ì²˜ë¦¬í•  íŒŒì¼ ìˆ˜
            estimated_functions: ì˜ˆìƒ í•¨ìˆ˜ ìˆ˜ (ì„ íƒ, ë” ì •í™•í•œ íŒë‹¨)
            estimated_loc: ì˜ˆìƒ LOC (ì„ íƒ, complexity ì¶”ì •)

        Returns:
            True if ProcessPool should be used for Semantic IR

        SOTA Rationale:
            Work-based threshold (íŒŒì¼ ìˆ˜ê°€ ì•„ë‹Œ ì‘ì—…ëŸ‰ ê¸°ë°˜)

            1. ê¸°ë³¸ ì„ê³„ê°’ (íŒŒì¼ ìˆ˜ë§Œ ìˆì„ ë•Œ):
               - 50+ íŒŒì¼ì´ë©´ ë³‘ë ¬ ì‹œë„ (ë³´ìˆ˜ì )

            2. ì‘ì—…ëŸ‰ ê¸°ë°˜ (í•¨ìˆ˜ ìˆ˜ ìˆì„ ë•Œ):
               - ì˜ˆìƒ ì‘ì—…ëŸ‰ = file_count * (estimated_functions / file_count)
               - 5000+ í•¨ìˆ˜ë©´ ë³‘ë ¬ í™•ì • (httpx: 6.9k â†’ ë³‘ë ¬)
               - ì´ìœ : í•¨ìˆ˜ë‹¹ CFG/DFG ë¹Œë“œ ë¹„ìš©ì´ ì§€ë°°ì 

            3. ë³µì¡ë„ ê¸°ë°˜ (LOC ìˆì„ ë•Œ):
               - LOC/file > 500 â†’ ë³µì¡í•œ íŒŒì¼ â†’ ë³‘ë ¬ ì´ë“ í¼
               - LOC/file < 100 â†’ ë‹¨ìˆœí•œ íŒŒì¼ â†’ pickle ë¹„ìš© ìš°ì„¸

            Break-even analysis:
            - Prewarm: 500ms (1íšŒ)
            - Pickle: 2ms/file * N
            - Sequential: 70ms/file * N
            - Parallel: 70ms/file * N / 8 (cores)
            - Break-even: 500 + 2N < 70N - 70N/8
            - Solve: N > 8 files (ì´ë¡ ), ì‹¤ì œ ~50 files (IPC ì˜¤ë²„í—¤ë“œ)
        """
        if not self.use_process_pool or self.parallel_workers <= 1:
            return False

        # Strategy 1: íŒŒì¼ ìˆ˜ ê¸°ë°˜ (ê¸°ë³¸)
        if file_count >= self.semantic_process_pool_threshold:
            return True

        # Strategy 2: ì‘ì—…ëŸ‰ ê¸°ë°˜ (í•¨ìˆ˜ ìˆ˜)
        if estimated_functions is not None:
            if estimated_functions >= self.semantic_work_threshold:
                return True
            # íŒŒì¼ë‹¹ í‰ê·  í•¨ìˆ˜ ìˆ˜ê°€ ë§ìœ¼ë©´ (ë³µì¡í•œ íŒŒì¼)
            avg_functions_per_file = estimated_functions / max(file_count, 1)
            if avg_functions_per_file > 30 and file_count >= 20:
                # ë³µì¡í•œ íŒŒì¼ 20ê°œ ì´ìƒì´ë©´ ë³‘ë ¬ ì´ë“
                return True

        # Strategy 3: ë³µì¡ë„ ê¸°ë°˜ (LOC)
        if estimated_loc is not None and file_count > 0:
            avg_loc_per_file = estimated_loc / file_count
            if avg_loc_per_file > 500 and file_count >= 30:
                # í° íŒŒì¼ 30ê°œ ì´ìƒì´ë©´ ë³‘ë ¬ ì´ë“
                return True

        return False

    def should_use_process_pool_semantic(self, file_count: int) -> bool:
        """
        Semantic IR ì „ìš© ProcessPool ì‚¬ìš© ì—¬ë¶€ ê²°ì •.

        Semantic IRì€ êµ¬ì¡°ìƒ (í˜„ì¬) ì›Œì»¤ì—ì„œ AST ì¬íŒŒì‹± + ëŒ€ìš©ëŸ‰ ê²°ê³¼ pickle ì™•ë³µì´ ë°œìƒí•˜ë¯€ë¡œ,
        íŒŒì¼ ìˆ˜ê°€ ì¶©ë¶„íˆ ì»¤ì„œ ë³‘ë ¬í™” ì´ë“ì´ í™•ì‹¤í•  ë•Œë§Œ ProcessPoolì„ ì‚¬ìš©í•œë‹¤.
        """
        return (
            self.use_process_pool
            and self.use_process_pool_semantic
            and self.parallel_workers > 1
            and file_count >= self.semantic_process_pool_threshold
        )

    # ================================================================
    # ThreadPool Decision Helper (SOTA: SSA/Dominator ë³‘ë ¬í™”)
    # ================================================================

    def should_use_ssa_parallel(self, function_count: int) -> bool:
        """
        SSA/Dominator ë³‘ë ¬ ë¹Œë“œ ì—¬ë¶€ ê²°ì •.

        Args:
            function_count: ì²˜ë¦¬í•  í•¨ìˆ˜ ìˆ˜

        Returns:
            True if ThreadPool should be used for SSA/Dominator

        Rationale:
            - ThreadPool ìƒì„± ì˜¤ë²„í—¤ë“œ: ~2ms (ProcessPoolë³´ë‹¤ í›¨ì”¬ ê°€ë²¼ì›€)
            - í•¨ìˆ˜ë‹¹ SSA ë¹Œë“œ: ~0.03ms
            - ì†ìµë¶„ê¸°ì : 100 í•¨ìˆ˜ (ë³‘ë ¬í™” ì´ë“ > ì˜¤ë²„í—¤ë“œ)
        """
        return self.use_ssa_parallel and self.parallel_workers > 1 and function_count >= self.ssa_thread_pool_threshold

    # ================================================================
    # RFC-036: New Presets (3-Tier Model)
    # ================================================================

    @classmethod
    def for_refactoring(cls) -> "BuildConfig":
        """
        RFC-036: Refactoring mode (EXTENDED tier).

        Tier: EXTENDED
        Layers: BASE + DFG + Expression
        Use: Extract method, inline, rename with flow (9% AI tasks)
        Perf: ~2.0s (45% of full)
        Memory: ~250MB

        Returns:
            BuildConfig with EXTENDED tier
        """
        return cls(
            semantic_tier=SemanticTier.EXTENDED,
            occurrences=True,
            lsp_enrichment=False,
            cross_file=False,
            dfg_function_loc_threshold=500,
            retrieval_index=False,
            diagnostics=False,
            packages=False,
            parallel_workers=4,
        )

    @classmethod
    def for_analysis(cls) -> "BuildConfig":
        """
        RFC-036: Analysis mode (FULL tier).

        Tier: FULL
        Layers: All (CFG + DFG + SSA + PDG)
        Use: Path-sensitive, slicing, taint (1% AI tasks)
        Perf: ~4.4s (100%)
        Memory: ~400MB

        Returns:
            BuildConfig with FULL tier
        """
        return cls(
            semantic_tier=SemanticTier.FULL,
            occurrences=True,
            lsp_enrichment=True,
            cross_file=True,
            heap_analysis=True,
            taint_analysis=False,
            retrieval_index=True,
            diagnostics=True,
            packages=True,
            parallel_workers=8,
        )


__all__ = ["BuildConfig", "PyrightMode", "SemanticTier"]
