"""
Parser Configuration Models

Defines configuration schemas for parsing behavior.
"""

from pydantic import BaseModel, Field


class GeneratedFileDetectorConfig(BaseModel):
    """Configuration for detecting generated files."""

    # Pattern-based detection
    path_patterns: list[str] = Field(
        default_factory=lambda: [
            "**/node_modules/**",
            "**/dist/**",
            "**/build/**",
            "**/.venv/**",
            "**/vendor/**",
            "**/*.min.js",
            "**/*.min.css",
            "**/*-min.js",
            "**/*-min.css",
            "**/*.bundle.js",
        ]
    )

    # Comment markers
    comment_markers: list[str] = Field(
        default_factory=lambda: [
            "@generated",
            "DO NOT EDIT",
            "Auto-generated",
            "Code generated",
            "AUTOGENERATED",
        ]
    )

    # Size/entropy thresholds
    max_file_size_kb: int = 512  # Skip files larger than this
    min_entropy_threshold: float = 3.0  # Minified files have low entropy


class ParserConfig(BaseModel):
    """
    Parser layer configuration.

    Controls parsing behavior, file filtering, and experimental features.
    """

    # Language support
    enabled_languages: list[str] = Field(
        default_factory=lambda: [
            "python",
            "typescript",
            "javascript",
        ]
    )

    # File size limits
    max_file_size_kb: int = 512
    max_nodes_per_file: int = 5000

    # File filtering
    ignore_globs: list[str] = Field(
        default_factory=lambda: [
            "**/dist/**",
            "**/build/**",
            "**/.venv/**",
            "**/node_modules/**",
            "**/*.min.js",
            "**/*.min.css",
            "**/__pycache__/**",
            "**/.git/**",
            "**/.pytest_cache/**",
        ]
    )

    # Generated file detection
    generated_file_detectors: GeneratedFileDetectorConfig = Field(
        default_factory=GeneratedFileDetectorConfig
    )

    # Experimental features
    experimental_features: dict[str, bool] = Field(
        default_factory=lambda: {
            "name_resolution_v2": False,
            "framework_tagging": False,
            "incremental_parsing": False,
            "embedded_languages": False,
        }
    )

    # Performance
    enable_parallel_parsing: bool = True
    max_parallel_workers: int = 4

    # Attributes extraction control
    extract_decorators: bool = True
    extract_docstrings: bool = True
    extract_comments: bool = True
    extract_type_hints: bool = True

    # Schema version
    schema_version: str = "v2.0"


class RepoParserConfig(BaseModel):
    """
    Repository-specific parser configuration.

    Allows overriding global ParserConfig for specific repositories.
    """

    repo_id: str

    # Override global settings
    enabled_languages: list[str] | None = None
    max_file_size_kb: int | None = None
    ignore_globs: list[str] | None = None
    experimental_features: dict[str, bool] | None = None

    # Monorepo/workspace support
    workspace_roots: list[str] = Field(default_factory=list)
    package_boundaries: list[str] = Field(default_factory=list)

    def merge_with_global(self, global_config: ParserConfig) -> ParserConfig:
        """
        Merge repo-specific config with global config.

        Args:
            global_config: Global parser configuration

        Returns:
            Merged configuration with repo overrides applied
        """
        config_dict = global_config.model_dump()

        if self.enabled_languages is not None:
            config_dict["enabled_languages"] = self.enabled_languages
        if self.max_file_size_kb is not None:
            config_dict["max_file_size_kb"] = self.max_file_size_kb
        if self.ignore_globs is not None:
            config_dict["ignore_globs"] = self.ignore_globs
        if self.experimental_features is not None:
            config_dict["experimental_features"].update(self.experimental_features)

        return ParserConfig(**config_dict)
